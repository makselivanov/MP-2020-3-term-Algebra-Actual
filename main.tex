\documentclass[10pt,a4paper,oneside]{book}
\usepackage[a4paper,includeheadfoot,top=10mm,bottom=10mm,left=10mm,right=10mm]{geometry}
\usepackage{cmap} % Поддержка поиска русских слов в PDF (pdflatex)
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{fancyhdr} % колонтитулы
\usepackage{hyperref} % гиперссылки
\usepackage{comment} % многострочное комментирование 
%\usepackage{pdfsync} % синхронизация


\frenchspacing % Пробелы после конца предложения
\righthyphenmin=2 % минимальная длина фрагмента при переносе слова
\usepackage{misccorr} % российская полиграфия
\usepackage{indentfirst}% Красная строка в первом абзаце
\usepackage{ccaption} % Заголовки таблиц и рисунков
\captiondelim{. } % точки в подписи рисунка




\usepackage{rotating} % Поворот текста
\usepackage{graphicx} % Вставка изображений
\graphicspath{ {./} } % относительно main.tex
\usepackage{xcolor} % настройка цвета
\usepackage{pgf}
\usepackage{tikz}
\usepackage{tikz-cd}
\usetikzlibrary{arrows,backgrounds,patterns,matrix,shapes,fit,calc,shadows,plotmarks}

\usepackage{amsmath,amsthm,amssymb,amscd,array}
\usepackage{latexsym}
\usepackage{stmaryrd} % Для знака нормальной подгруппы
\usepackage{arydshln} % штрихованные линии в массивах
\usepackage{mathtools} % выравнивание в матрицах
\usepackage{multirow} % слияние в столбце
\usepackage{multicol} % нумерация в нескольких колонках


\hypersetup{
    colorlinks,
    linkcolor={blue!50!black},
    citecolor={blue!50!black},
    urlcolor={red!80!black}
} % цвета для ссылок




\newtheorem{uprz}{\color{violet!100!black} Упражнение}
\newtheorem{predl}{\color{blue!50!black} Предложение}
\newtheorem{komment}{\color{green!50!blue} Комментарий}
\newtheorem{conj}{Гипотеза}
\newtheorem{notation}{\color{yellow!30!red} Обозначение}


\theoremstyle{definition}
\newtheorem{kit}{Кит}
\newtheorem*{rem}{\color{green!50!blue}Замечание}
\newtheorem{zad}{\color{violet!100!black}Задача}
\newtheorem*{defn}{\color{yellow!30!red} Определение}
\newtheorem*{fact}{Факт}
\newtheorem{thm}{\color{red!40!black}Теорема}
\newtheorem*{thmm}{\color{red!40!black} Теорема}
\newtheorem{lem}{\color{green!50!black}Лемма}
\newtheorem{cor}{\color{green!45!black}Следствие}
\newtheorem{utvr}{\color{blue!50!black}Утверждение}


\newcommand\tikznode[3][]%
   {\tikz[remember picture,baseline=(#2.base)]
      \node[minimum size=0pt,outer sep=0pt,#1](#2){#3};%
   }
\tikzset{>=stealth}


\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother


\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\renewcommand{\proofname}{Доказательство}
\renewcommand{\mod}{\,\operatorname{mod}\,}
\renewcommand{\Re}{\operatorname{Re}}
\newcommand{\mf}[1]{\mathfrak{#1}}
\newcommand{\mcal}[1]{\mathcal{#1}}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\tbf}[1]{\textbf{#1}}
\newcommand{\ovl}{\overline}
\newcommand{\Spec}{\operatorname{Spec}}
\newcommand{\K}{\operatorname{K_0}}
\newcommand{\witt}{\operatorname{W}}
\newcommand{\gw}{\operatorname{GW}}
\newcommand{\coh}{\operatorname{H}}
\newcommand{\dist}{\operatorname{dist}}
\newcommand{\cl}{\operatorname{Cl}}
\newcommand{\Vol}{\operatorname{Vol}}
\newcommand\tgg{\mathop{\rm tg}\nolimits}
\newcommand\ccup{\mathop{\cup}}
\newcommand{\id}{\operatorname{id}}
\newcommand{\lcm}{\operatorname{lcm}}
\newcommand{\chr}{\operatorname{char}}
\newcommand{\rk}{\operatorname{rk}}
\DeclareMathOperator{\Coker}{Coker}
\DeclareMathOperator{\Ker}{Ker}
\newcommand{\im}{\operatorname{Im}}
\renewcommand{\Im}{\operatorname{Im}}
\newcommand{\Tr}{\operatorname{Tr}}
\newcommand{\re}{\operatorname{Re}}
\newcommand{\tr}{\operatorname{Tr}}
\newcommand{\ord}{\operatorname{ord}}
\newcommand{\Stab}{\operatorname{Stab}}
\newcommand{\orb}{\operatorname{\mathcal O}}
\newcommand{\Fix}{\operatorname{Fix}}
\newcommand{\Hom}{\operatorname{Hom}}
\newcommand{\End}{\operatorname{End}}
\newcommand{\Aut}{\operatorname{Aut}}
\newcommand{\Inn}{\operatorname{Inn}}
\newcommand{\Out}{\operatorname{Out}}
\newcommand{\GL}{\operatorname{GL}}
\newcommand{\SL}{\operatorname{SL}}
\newcommand{\SO}{\operatorname{SO}}
\renewcommand{\O}{\operatorname{O}}
\renewcommand{\U}{\operatorname{U}}
\newcommand{\Sym}{\operatorname{Sym}}
\newcommand{\Adj}{\operatorname{Adj}}
\newcommand{\Disc}{\operatorname{Disc}}
\newcommand{\cnt}{\operatorname{cont}}
\newcommand{\Frob}{\operatorname{Frob}}
\newcommand{\Iso}{\operatorname{Iso}}
\newcommand{\Isom}{\operatorname{Isom}}
\newcommand{\supp}{\operatorname{supp}}
\newcommand{\di}{\mathop{\,\scalebox{0.85}{\raisebox{-1.2pt}[0.5\height]{\vdots}}\,}}
\newcommand{\ndi}{\mathop{\not\scalebox{0.85}{\raisebox{-1.2pt}[0.5\height]{\vdots}}\,}}
\newcommand{\nequiv}{\not \equiv}
\newcommand{\Nod}{\operatorname{\text{НОД}}}
\newcommand{\Nok}{\operatorname{\text{НОК}}}
\newcommand{\sgn}{\operatorname{sgn}}
\newcommand{\codim}{\operatorname{codim}}
\newcommand{\Aff}{\operatorname{Aff}}
\newcommand{\AGL}{\operatorname{AGL}}
\newcommand{\PSL}{\operatorname{PSL}}
\newcommand{\Volume}{\operatorname{Volume}}


\def\llq{\textquotedblleft} 
\def\rrq{\textquotedblright} 
\def\exm{\noindent {\bf Примеры:}}
\def\Cb{\ovl{C}}
\def\ffi{\varphi}
\def\pa{\partial}
\def\V{\bf V}
\def\La{\Lambda}
\def\eps{\varepsilon}
\def\del{\delta}
\def\Del{\Delta}
\def\A{\EuScript{A}}
\def\lan{\left\langle }
\def\ran{\right\rangle}
\def\bar{\begin{array}}
\def\ear{\end{array}}
\def\beq{\begin{equation}}
\def\eeq{\end{equation}}
\def\thrm{\begin{thm}}
\def\ethrm{\end{thm}}
\def\dfn{\begin{defn}}
\def\edfn{\end{defn}}
\def\lm{\begin{lem}}
\def\elm{\end{lem}}
\def\zd{\begin{zad}}
\def\ezd{\end{zad}}
\def\prdl{\begin{predl}}
\def\eprdl{\end{predl}}
\def\crl{\begin{cor}}
\def\ecrl{\end{cor}}
\def\rm{\begin{rem}}
\def\erm{\end{rem}}
\def\fct{\begin{fact}}
\def\efct{\end{fact}}
\def\enm{\begin{enumerate}}
\def\eenm{\end{enumerate}}
\def\pmat{\begin{pmatrix}}
\def\epmat{\end{pmatrix}}
\def\utv{\begin{utvr}}
\def\eutv{\end{utvr}}
\def\upr{\begin{uprz}}
\def\eupr{\end{uprz}}
\def\nrml{\trianglelefteqslant}




\title{Современное программирование \\ 
Конспект по алгебре, 3 семестр}
\date{}


\begin{document}

\tableofcontents

\chapter{Линейная алгебра}

\section{Кватернионы}


Наша цель сейчас рассказать про геометрию трехмерного пространства используя при этом определённые алгебраические конструкции. А именно, ещё в XIX веке Уильям Роуэн Гамильтон стал искать аналогичную комплексным числам алгебраическую систему на трёхмерном пространстве.  
Однако, подходящий аналог удалось найти только в четырёхмерной ситуации.


Рассмотрим вещественное подпространство в алгебре матриц $M_2(\mb C)$ вида
$$\mb H = \left\{\pmat \alpha & \beta \\ -\ovl{\beta} & \ovl{\alpha} \epmat \right\}.$$
Базис этого пространства, как вещественного векторного пространства, состоит из матриц 
$$ 1=\pmat 1 & 0 \\ 0& 1 \epmat, i= \pmat i & 0 \\ 0& -i \epmat, j=\pmat 0& 1 \\ -1 & 0 \epmat, k=\pmat 0 & i \\ i & 0\epmat. $$ 
Покажем, что это вещественная подалгебра в $M_2(\mb C)$ и следовательно ассоциативное кольцо. 
Для этого достаточно показать, что произведение базисных снова лежит в $\mb H$. Имеем $$i^2=j^2=k^2=-1 \text{ и } ij=k=-ji,$$ откуда $$ik= iij=-j=jii=-ki \text{ и } jk=-jji=i=-kj.$$ Таким образом $\mb H$ образует ассоциативную алгебру размерности 4 над $\mb R$.
 
\dfn[Алгебра кватернионов] $\mb H$ называется алгеброй кватернионов. 
\edfn
Мы больше не будем думать (кроме одного нюанса) про кватернионы как про матрицы, а будем записывать их через $i,j,k$. Именно так обычно кватернионы и вводят -- как формальный суммы $a+bi+cj+dk$, для произведения которых выполнены тождества $i^2=j^2=k^2=-1$ и $ij=-ji=k$. Посмотрев на кватернионы как на матрицы мы сэкономили на доказательстве ассоциативности умножения.

\zd Алгебра кватернионов не снабжается структурой $\mb C$-алгебры.
\ezd






\dfn[Векторная и скалярная часть, сопряжённый кватернион] Пусть $x= a+bi+cj+dk$ кватернион. Определим вещественную или скалярную часть $\Re x=a$ и векторную часть $v= bi+cj+dk$ кватерниона. Сопряжённым кватернионом называется $\ovl{x}= a-bi-cj-dk= \Re x - \Im x =a-v$. 
\edfn



Посмотрим, как перемножаются кватернионы. Если оба кватерниона  $x$, $y$ разделить на скалярную и векторную части $x=a+v$, $y=b+u$ то $xy=ab+au+bv+ vu$. Нам осталось разобраться с умножением векторных частей. 

Рассмотрим произведение двух чисто мнимых кватернионов $uv=-\lan u,v\ran+[u,v]$. Его вещественная часть совпадает с минус скалярным произведением векторов. Про мнимую часть мы поговорим отдельно.

\dfn[Векторное произведение] Пусть $u,v \in \mb R^3$ два вектора. Тогда их векторным произведением называется вектор $[u,v]$.
\edfn

Если расписать в координатах $u=x_1i+x_2j+x_3k$ и  $v=y_1i+y_2j+y_3k$, то векторное произведение задаётся формулой

$$[u,v]= (x_2y_3-x_3y_2)i + (x_3y_1-x_1y_3)j + (x_1y_2- x_2y_1)k= \begin{vmatrix} i& j&k \\ x_1 & x_2 & x_3 \\ y_1 & y_2 & y_3 \end{vmatrix} $$

\rm Операция $(u,v) \to [u,v]$ является билинейной и антисимметричной, то есть $[u,u]=0$ и, следовательно, $[u,v]=-[v,u]$.
\erm

Последнее замечание позволяет нам легко вычислить $x \ovl{x}= a^2+ \lan v,v \ran$. Это приводит нас к определению:

\dfn[Норма кватерниона] Определим норму кватерниона как $$\|x\|=\sqrt{x\ovl{x}}=\sqrt{ a^2+b^2+c^2+d^2}=\sqrt{\ovl{x}x}.$$
\edfn 


Норма кватерниона, как и модуль комплексного числа всегда положительны для ненулевых элементов. Это позволяет заметить, что

\dfn[Обратный кватернион] Если $0\neq x \in \mb H$, то $x^{-1}=\frac{\ovl{x}}{\|x\|^2}$. 
\edfn

Таким образом мы получили первый (и для нас единственный) пример некоммутативного кольца с делением. Такие кольца называются телами. Напоминаю, что алгебра для нас ассоциативна и с единицей. Неассоциативные алгебры представляют интерес. Например, можно взять $\mb R^3$, где в качестве умножения взято векторное произведение. Это пример неассоциативной алгебры или, точнее, алгебры Ли. В этом курсе мы не  обсуждаем неассоциативные алгебры в связи с тем, что им обычно находится применение либо внутри физических дисциплин, либо внутри самой математики и редко где ещё. 

Какие ещё свойства есть у отображения нормы? Если следовать параллели с комплексными числами, то стоит посмотреть, что происходит с нормой произведения. Для того, чтобы не обременяться вычислениями сделаем небольшой трюк и на секунду вспомним матричное представление кватернионов. Заметим, что на матричном языке, норма -- это $\|x\|=\sqrt{\det x}$, откуда получаем

\lm[Норма мультипликативна] $\|xy\|=\|x\|\|y\|$. В частности, $\|x^{-1}\|=\|x\|^{-1}$.
\proof Вспомним в последний раз, что кватернионы задаются матрицами из $M_2(\mb C)$. Пусть 
$$x=\pmat \alpha & \beta \\ -\ovl{\beta} & \ovl{\alpha}\epmat.$$
Тогда $$\|x\|^2=|\alpha|^2+|\beta|^2=\det \pmat \alpha & \beta \\ -\ovl{\beta} & \ovl{\alpha}\epmat,$$
а определитель мультипликативен.
\endproof
\elm



Продолжим. Используя мультипликативность нормы легко доказать 
\lm Отображение $x \to \ovl{x}$ является антиизоморфизмом алгебр, то есть $\ovl{ab}=\ovl{b}\ovl{a}$.
\proof Линейной ясна. Пусть $x,y \neq 0$. Тогда $$\frac{\ovl{y}\,\ovl{x}}{\|y\|^2\|x\|^2}=y^{-1}x^{-1}=(xy)^{-1}=\frac{\ovl{xy}}{\|xy\|^2}.$$
\elm

На самом деле и здесь можно было воспользоваться матричным представлением. А именно, можно заметить, что операция сопряжения кватернионов совпадает на этом языке с транспонированием и сопряжением соответствующей комплексной матрицы. Вернёмся теперь к векторному произведению.





\lm[Свойства векторного произведения] Верны следующие свойства\\
1) Для любых $u,v \in \mb R^3$ верно $u\bot [u,v]$. Точнее $$u[u,v]= -\|u\|^2v+ \lan u,v\ran u$$
2) $\| [u,v]\|= \|u\|\|v\| \cdot |\sin \ffi |$, где $\ffi$ --  это угол между $u$ и $v$.
\elm
\proof Для того, чтобы посчитать скалярное произведение $\lan u, [u,v]\ran$ необходимо посчитать скалярную часть $u[u,v]$. 
$$u[u,v]= u (uv+ \lan u,v \ran)= u^2 v+ \lan u,v \ran u= -\|u\|^2 v+ \lan u,v \ran u$$
Последнее выражение, очевидно, чисто векторное.
Теперь
\begin{align*}
&\|[u,v]\|^2= -[u,v][u,v]= (uv + \lan u,v\ran)(vu + \lan u,v\ran)=\\
&=\|u\|^2\|v\|^2+ \lan u,v\ran^2 + \lan u,v\ran (uv+vu)=\|u\|^2\|v\|^2 - \lan u,v\ran^2= \|u\|^2\|v\|^2(1-\cos^2 \ffi)
\end{align*}
\endproof

\dfn Обозначим за $\mb H_{1}$ группу кватернионов, по норме равных единице.
\edfn

\thrm Отображение $\mb H_{1}\to \GL_3(\mb R)$ заданное по правилу $x\to (y \to xyx^{-1})$ корректно определено и даёт сюръективный  гомоморфизм из группы кватернионов единичной нормы в $\SO_3(\mb R)$. Ядро этого гомоморфизма состоит из $\{\pm 1\}$. Точнее, если единичный кватернион $x$  представим в виде $x=a+bv$, то соответствующее ему вращение есть вращение относительно  оси $\lan v \ran$ на угол $2\ffi$, где $\cos \ffi= a$, $\sin \ffi= b$ или тождественное преобразование в случае $v=\pm 1$.
\ethrm
\proof Рассмотрим преобразование $L_x \colon \mb H \to \mb H$ вида $y \to xyx^{-1}$. Прежде всего покажем, что мы получили ортогональное преобразование $\mb R^4$. Имеем
 $$\|xvx^{-1}\|=\|x\| \|v\| \|x^{-1}\| = \|v\|.$$
Теперь заметим, что преобразование $L_x$ сохраняет на месте вектор 1 и, следовательно, его ортогональное дополнение, то есть $\mb R^3$. Таким образом $L_x$ ограничивается на $\mb R^3$. Далее, очевидно, $L_xL_y= L_{xy}$. Осталось посчитать ядро гомоморфизма и явный вид отображения $L_x$. Заметим, что если $x=a+bv$, то $L_x$ оставляет $v$ на месте. Действительно, при $b\neq 0$ 
$$xbvx^{-1}=x(x-a)x^{-1}= x-a=bv.$$
Вычислим угол поворота. Для этого рассмотрим нормированный вектор  $u\bot v$ и $[u,v]$, которые образуют ортонормированный базис дополнения и посчитаем $xux^{-1}$ и $x[u,v]x^{-1}$. Из условия ортогональности следует, что $uv=[u,v]=-[v,u]=-vu$ и значит $v[u,v]=-[u,v]v=-uv^2=u$. Теперь
\begin{align*}
xux^{-1}&=(a+bv)u(a-bv)= (a+bv)(au-buv)=\\
&=a^2u -ab[u,v]+ab[v,u]- b^2vuv=a^2u-2ab[u,v]-b^2\|v\|^2u=\\ &=(a^2-b^2)u-2ab[u,v]=\cos2\ffi u+ \sin 2\ffi [u,v]
\\
\\
x[u,v]x^{-1}&=(a+bv)[u,v](a-bv)= (a[u,v]+bu)(a-bv)=\\
&=a^2[u,v]+abu-ab[u,v]v-b^2uv=\\
&=(a^2-b^2)[u,v]+2abu=\cos 2\ffi[u,v]+\sin 2\ffi u
\end{align*}

Осталось показать, что только $x=\pm 1$ лежит в ядре этого отображения. Это возможно только тогда, когда $2\ffi \equiv 0 \mod 2\pi$. Значит $\ffi=2 \pi$ или $\ffi= \pi$. Первое соответствует $x=1$. Втораое --  $a=\cos \ffi = -1$, а $b=\sin \ffi = 0$, то есть $x=-1$. 
\endproof


\zd
Покажите, что отображение $(x,y) \to (z \to xzy^{-1})$ задаёт сюръективный гомоморфизм из декартового квадрата группы единичных кватернионов в группу $\SO_4(\mb R)$ с ядром $\{(1,1),(-1,-1)\}$.
\ezd

Обсудим теперь для чего могут понадобится кватернионы. Каждый кватернион, как мы установили кодирует вращение трёхмерного пространства или, что тоже самое -- новую декартову систему координат в $\mb R^3$ с центром в нуле. Такой тип данных встречается в компьютерной графике, если вы хотите зафиксировать ракурс, в котором вы смотрите на 3d-сцену или положение какого-то конкретного объекта в такой сцене.

В такой задаче кватернионы сложно превзойти. Действительно, задание сцены при помощи кватернионов очень экономно -- 4 коэффициента с одним соотношением на них (3 коэффициента, если очень нужно) против 9 коэффициентов у ортогональной матрицы.

А что с эффективностью операций? Тут вопрос состоит в том, про какие операции идёт речь. Если вы хотите сказать, что тот или иной вектор, который был повёрнут на кватернион $q=a+v$ надо повернуть ещё на кватернион $p=b+u$, то вам надо всего лишь вычислить $pq=ab+au+bv+uv$. Такое произведение считается за 16 умножений и 12 сложений. Если брать произведение матриц $3\times 3$, то там получается 27 умножений и 18 сложений (можно обойтись и 23 умножениями, но сильно увеличив число сложений).

Можно конечно использовать углы Эйлера, но тогда придётся использовать для вычислений косинусы и синусы этих углов, которые сами даются не бесплатно.

Если вам даны два ракурса в виде кватернионов, то легко понять, на какой кватернион надо домножить, чтобы из первого получить второй.

Но что если вы хотите просто повернуть при помощи кватерниона какой-то вектор из $\mb R^3$. Тут ситуация несколько хуже. Для этого вам необходимо посчитать $qxq^{-1}$. Предположив, что $q$ нормирован можно заменить обращение на сопряжение. Тем не менее такой подход довольно дорог -- 32 умножения и 24 сложения. Конечно, такой способ не оптимален. Например, не обязательно считать скалярную часть -- она должна стать нулевой. На самом деле, если $q=a+v$, то 
$$qxq^{-1}=x+ 2[v, [v,x]+ ax]$$
что даёт 15 умножений и 15 сложений (если считать умножение на 2 сложением). Это конечно отличается от матриц, где необходимо 9 умножений и 6 сложений.

Впрочем, отличается не сильно. Кроме того у кватернионного представления есть плюс произведение нескольких кватернионов -- это кватернион несмотря на ошибки округления. Что не так для ортогональных матриц.

Наконец, представим себе задачу, что нам нужно плавно перейти от ракурса $q$ к ракурсу $p$. Желательно с "равномерной" скоростью. На языке кватернионов это становится понятно. Для этого заметим, что единичные кватернионы -- это всего лишь точки на трёхмерной сфере в четырёхмерном пространстве. Несложно понять, что их соединяет часть дуги сферы, равномерное движение по которой и приводит к желаемой смене ракурса. Теперь несложно параметризовать равномерное движение по этой дуге. 
$$ \frac{\sin(t\theta)p + \sin ((1-t)\theta) q}{\sin \theta},$$
где $\theta$ -- угол между $p$ и $q$ (острый, не забываем, что представление кватернионами вращений немного не однозначно).





\section{Задачи на максимизацию}

Теперь обратимся к вопросам, связанным с вещественными самосопряжёнными операторами.

Рассмотрим один из вопросов, связанных с такой конструкцией, а именно, рассмотрим задачу о нахождении нормы линейного оператора $L \colon U \to V$ между двумя евклидовыми пространствами. Для того, чтобы найти  норму необходимо найти
$$\max_{x\neq 0}\sqrt{\frac{\lan Lx,Lx\ran}{\|x\|^2}}=\sqrt{\max_{x\neq 0}\frac{\lan L^*Lx,x\ran}{\|x\|^2}}=\sqrt{\max_{\|x\|=1} \lan L^*Lx,x\ran}.$$
Таким образом, нахождение нормы оператора свелось к задаче максимизации некоторой квадратичной формы на единичной сфере. Заметим, что максимум действительно достигается благодаря компактности сферы.

Оказывается, что довольно легко найти максимум или минимум произвольной квадратичной формы на сфере. Для этого мы заметим, что по любому самосопряжённому оператору $A$ на евклидовом пространстве $V$ строится квадратичная форма $q(x)=\lan x, Ax\ran$ и обратно, оператор можно восстановить по этой квадратичной форме. Точнее, если $v_1,\dots,v_n$ -- ортонормированный базис, то матрица $A$ в этом базисе совпадает с матрицей $q$. Теперь докажем теорему.



\thrm Пусть $V$ -- евклидово пространство, $A$ -- самосопряжённый оператор на $V$, а $q(x)=\lan x,Ax\ran$ -- соответствующая квадратичная форма. Тогда 
$$\max_{ x\in V } \frac{q(x)}{||x||^2}=\max_{\substack{ x\in V \\ ||x||=1}} q(x)=\lambda_1,$$
где $\lambda_1$ - наибольшее собственное число оператора $A$ и достигается на собственном векторе $v_1$, соответствующему $\lambda_1$. Аналогично минимум равен минимальному собственному числу $A$. 
\proof
Пусть $v=\sum c_i e_i$, причём $1=||v||^2=\sum c_i^2$. Тогда $\lan Av,v\ran = \sum c^2_i \lambda_i $, что меньше $\lan A e_1,e_1\ran= \lambda_1= \sum \lambda_1 c_i^2$.
\endproof
\ethrm

Эта теорема, кроме, собственно, решения задачи, даёт геометрическую характеризацию первого собственного числа для самосопряжённого оператора. Вопрос: можно ли аналогично охарактеризовать другие собственные числа? Ответ получается не таким простым, но, тем не менее, полезным.

\thrm[Куранта-Фишера] Пусть $q(x)=\lan x, Ax\ran$, где $A$ -- самосопряжённый оператор на евклидовом пространстве. Тогда $k$-ое по убыванию собственное число $\lambda_k$ для $A$ есть 
$$\lambda_k=\max_{\dim L=k} \min_{\substack{ x\in L \\ ||x||=1}} q(x) = \min_{\dim L=n-k+1} \max_{\substack{ x\in L \\ ||x||=1}} q(x).$$
Причем максимум достигается на инвариантном подпространстве, содержащем собственные вектора для $\lambda_1,\dots,\lambda_k$.
\ethrm
\proof Будем доказывать только первое описание. Прежде всего заметим, $\lambda_k$ достигается, если взять $U=\lan v_1,\dots,v_k\ran$. Дейстительно, в этом случае, так как $U$ инвариантно относительно $A$ форме $q|_U$ просто соответствует ограничение $A|_U$, а его максимум уже легко посчитать так как нам известны его собственные числа.

Пусть $U$ --- подпространство на котором достигается максимум, причём допустим, что максимум больше $\lambda_k$. Тогда рассмотрим подпространство $W=\lan v_k,\dots,v_n\ran$, где $v_i$ --- собственный вектор соответствующий $i$-ому по убыванию собственному числу. Заметим, что $\dim U\cap W\geq 1$, из формулы Грассмана. С другой стороны, если мы возьмём вектор $x\in U \cap W$ с нормой $1$, то значение $q(x)$ с одной стороны меньше или равные $\lambda_k$, так как $x\in W$, а с другой стороны строго больше, так как $x\in U$. Полученное противоречие и доказывает теорему.  
\endproof




\crl Пусть $U$ некоторое подпространство размерности $m$ евклидового пространства $V$, а $q(x)=\lan x, Ax\ran$, где $A$ -- самосопряжённый оператор. Пусть собственные числа $A$ --- это $\lambda_i$, а собственные числа оператора, соответствующего $q(x)|_U$ -- это $\mu_i$, упорядоченные по убыванию. Тогда 
$$\lambda_{i+n-m}\leq \mu_i\leq \lambda_i.$$  
\proof Заметим, что
$$\mu_i=\max_{\substack{L\leq U\\ \dim L=i}} \min_{\substack{ x\in L \\ ||x||=1}} q(x),$$
что очевидно меньше, чем 
$$\max_{\substack{L\leq V\\ \dim L=i}} \min_{\substack{ x\in L \\ ||x||=1}} q(x)=\lambda_i.$$
Неравенство в другую сторону получается из второго описания в теореме Куранта-Фишера.
\endproof
\ecrl

В основном это удобно применять для оценки собственных чисел у симметричной подматрицы.

\crl Пусть $A\in M_n(K)$ -- симметричная матрица. Пусть $\Gamma \subseteq \{1,\dots, n\}$ размера $m$. Обозначим за $A^{\Gamma}_{\Gamma}$ матрицу $A$, в которой оставили только элементы из строк и столбцов из $\Gamma$. Пусть $\lambda_i$ -- это собственные числа $A$, а $\mu_i$ -- собственные числа $A^{\Gamma}_{\Gamma}$. Тогда
$$\lambda_{i+n-m}\leq \mu_i\leq \lambda_i.$$
\ecrl 


Введём не совсем стандартное определение:
\dfn
Пусть $q$ -- квадратичная форма на евклидовом пространстве. Рассмотрим ортонормированный базис $u_i$ пространства $V$. Тогда положим 
$$\Tr q= \sum q(u_i).$$ Если в базисе $u_i$ форме $q(x)=x^{\top} Ax $ соответствует симметричная матрица $A$, то $\Tr q(x)=\Tr(A)$.
\edfn

\rm Определение не зависит от выбора ортонормированного базиса. Действительно, если замена координат ортогональна, то матрица $q$ в новой системе координат имеет вид $C^{\top}AC=C^{-1}AC$. Осталось заметить, что след последней матрицы очевидно равен следу $A$.
\erm

\rm Если форме $q$ соответствует самосопряжённый оператор $A$, то $\Tr q=\sum \lambda_i$, где $\lambda_i$ -- собственные числа $A$.
\erm




\crl Пусть $q(x)=x^{\top} Ax$, $U$ --- некоторое подпространство, $\dim U=k$. Пусть собственные числа $A$ --- это $\lambda_i$. Тогда $$\Tr q|_U\leq \sum_{i=1}^k \lambda_i= \Tr q|_{V_k},$$
где $V_k$ подпространство натянутое на первые $k$ собственных векторов $q$.
\proof Нам известны неравенства на собственные числа $\mu_i$, ограничения $q|_U$. А именно, $\mu_i\leq \lambda_i$. Но тогда и $$\sum_{i=1}^k \mu_i \leq \sum_{i=1}^k \lambda_i.$$
\endproof
\ecrl 






\section{Метод главных компонент}

Рассмотрим следующую задачу: имеется массив данных --- набор векторов $x_1,\dots,x_s \in \mb R^n$. Подразумевается, что точек очень много. Предположим, что при идеальных измерениях между координатами этих векторов есть линейные зависимости. Все отклонения от этой погрешности вызваны небольшими погрешностями. Задача состоит в том, чтобы восстановить линейную зависимость. 


Переформулируем задачу геометрически. Пусть наши вектора удовлетворяют линейным условиям $Ax_i=b$ для некоторой матрицы $A$ ранга $n-k$. Это значит, что они лежат в аффинном подпространстве $\Ker A + a_0$ размерности $k$. Если же нам даны вектора с погрешностями, то задачу таким образом можно поставить в виде: найти аффинное подпространство размерности $k$ наиболее близкое к данным точкам $x_1,\dots,x_s$. Понятие <<наиболее близкое>> требует конкретизации. Вообще говоря, тут есть выбор. Мы будем считать, что подходящее пространство $W=U+a_0$ должно давать минимум следующего выражения:
$$\sqrt{\sum_{i=1}^s \rho(x_i,W)^2} \to \min.$$
Совершенно ясно, что корень квадратный тут для красоты, и минимизировать нужно $\sum_{i=1}^s \rho(x_i,W)^2$.

Прежде всего установим, что какой бы <<минимайзер>> $W=U+a_0$ мы не нашли, в $W$ всегда будет лежать среднее $\frac{1}{s}\sum_{i=1}^s x_i$ и, следовательно, в качестве $a_0$ всегда можно взять среднее. Действительно, распишем условие, что сумма 
$$\sum_{i=1}^s \rho(x_i-a_0, U)^2=\sum \|pr_{U^{\bot}} (x_i-a_0)\|^2$$
минимальна.  Продифференцируем по координатам $a_0$. Получим $$\sum -2pr_{U^{\bot}} x_i + 2s \,pr_{U^{\bot}} a_0=0$$
 Это условие означает, что проекции $a_0$ и среднего $\frac{1}{s}\sum x_i$ на подпространство $U^{\bot}$ совпадают. То есть эти две величины отличаются на элемент $U$. Тогда среднее лежит в $W$. 

Итак, вычтя из всех $x_i$ их среднее можно считать $a_0=0$, а все точки $x_i$ удовлетворяют равенству $\sum_{i=1}^s x_i=0$. Замечу, что это равенство нигде в дальнейшем не будет использовано. Благодаря такой замене мы свели задачу к поиску подпространства $U$ размерности $k$, которое минимизирует 
$$\sum_{i=1}^s \rho(x_i, U)^2=\sum_{i=1}^s \|pr_{U^{\bot}} (x_i)\|^2.$$

Воспользуемся тем, что $\|x\|^2=\|pr_U x\|^2+\|pr_{U^{\bot}} x\|^2$ или в другом виде $\|x\|^2-\|pr_U x\|^2=\|pr_{U^{\bot}} x\|^2$. Получаем, что выражение
$$\sum_{i=1}^s \|pr_{U^{\bot}}(x_i)\|^2=\sum_{i=1}^s \|x_i\|^2-\|pr_U x_i\|^2$$
должно быть минимально. Сумма $\|x_i\|^2$ постоянна. Значит  необходимо и достаточно, чтобы выражение $\sum_i \|pr_U x_i\|^2$ было максимально.


Для того чтобы посчитать проекцию на $U$ в каждом слагаемом выберем в $U$ ортонормированный базис $u_1,\dots,u_k$. Перепишем
$$\sum_{i=1}^s \|pr_U x_i\|^2=\sum_{i=1}^s\sum_{j=1}^k \lan x_i,u_j\ran^2=\sum_{j=1}^k \sum_{i=1}^s \lan x_i,u_j\ran^2.$$

Внутренняя сумма теперь есть значение некоторой квадратичной формы на векторе $u_j$. Разберёмся, что это за форма. Рассмотрим матрицу $X$ размера $s\times n$, чьи строки это  вектора $x_i$ $i\in\ovl{1,s}$. Тогда вектор $d_j=Xu_j$ состоит из скалярных произведений  $\lan x_i, u_j\ran$. Значит 
$$\lan d_j,d_j\ran = (Xu_j)^{\top}Xu_j = \sum_{i=1}^s \lan x_i,u_j\ran^2,$$ 
что совпадает со слагаемым нашей суммы. Рассмотрим симметричную матрицу $A=X^{\top}X$ и обозначим соответствующую ей форму за $q$. Тогда нам надо максимизировать выражение

$$\sum_{j=1}^k q(u_j).$$

Таким образом мы ищем максимум $\Tr q|_{U}$ по всем подпространствам $U$ размерности $k$, где форма $q$ соответствует матрице $X^{\top} X$. А его мы искать умеем. Сформулируем  ответ. 


\thrm  Пусть есть набор векторов $x_1,\dots,x_s \in V$. Определим симметричную, положительно полуопределённую матрицу $A$, как $A=X^{\top}X$, где строчки матрицы $X$ -- это вектора $x_i$. Тогда минимум по всем аффинным подпространствам $V$ размерности $k$ выражения $\sum_{i=1}^s \rho(x_i,W)^2$ достигается при $a_0=\frac{1}{s}\sum x_i$  и $U=\lan v_1,\dots,v_k\ran$, где $v_i$ --- собственные вектора $A$, причём соответствующие собственные числа упорядочены по убыванию. 
\ethrm

\rm Стоит немного сказать про вероятностную интерпретацию полученного ответа. Предположим, что точки $x_i\in \mb R^n$ сгенерированы каким-то случайным процессом и подчиняются некоторому общему распределению. Тогда вектор $a_0$ -- это просто оценка на математическое ожидание этого распределения.

После того как мы нашли $a_0$ мы центрируем набор $x_i$ и минимизируем $\sqrt{\sum \rho (x_i, U)^2}$. Представим себе, что $U=\{0\}$. Что значит эта сумма? Это то, что мы назвали бы оценкой дисперсией величины (конечно, надо ещё усреднить). 
А что если $U \neq \{0\}$? Тогда $\sqrt{\sum \rho (x_i, U)^2}$ -- это заготовка для оценки дисперсии проекций случайных величин на $U^\bot$. То есть мы ищем подпространство $U$, так что на ортогональное дополнение приходится минимально возможная дисперсия (а при проекции на само $U$ должен достигаться максимум дисперсии среди всех подпространств той же размерности).

Какой же смысле имеет матрица $X^\top X$, её собственные вектора и собственные числа. Матрица $X^\top X$ -- это с точностью до константы ($1/s-1$) эмпирическая матрица ковариации. Если мы хотим посчитать квадрат дисперсии в направлении $v$, то мы считаем $v\top X^\top X v$. Значит собственные вектора этой матрицы -- это такие вектора, для которых достигается экстремум квадрата дисперсии. А собственные числа -- это собственно квадраты дисперсии.
\erm

\rm Отдельно отметим, что в приложениях принято с самого начала центрировать данные и нормировать каждую компоненту $x_i$ так, чтобы дисперсия вдоль каждого направления была единичной.
\erm



\section{SVD-разложение}

При вычислении с помощью метода главных компонент часто используют несколько другие конструкции. Для того, чтобы в этом разобраться посмотрим на матрицу  $X^{\top}X$  и её собственные числа.  

\dfn Пусть $A$ -- линейное отображение между евклидовыми пространствами $U \to V$. Тогда сингулярными значениями $A$ называются корни из положительных собственных чисел оператора $A^*A$.
\edfn



Теперь обсудим важную конструкцию, проясняющую геометрический смысл сингулярных значений.


\thrm[SVD разложение] Пусть $L$ -- линейное отображение $L\colon U \to V$ между евклидовыми пространствами. Тогда существуют такие ортонормированный базисы $U$ и $V$, что матрица $L$ имеет вид 
$$\Sigma=\pmat \sigma_1 &\dots& 0 & 0\\
 \vdots & \ddots &\vdots & \vdots\\
 0 & \dots & \sigma_r & 0\\
 0 &  \dots & 0 & 0 \epmat,$$
 где $r$ -- ранг $L$. Числа $\sigma_1, \dots, \sigma_r$ на диагонали обязаны быть равными сингулярным значениям $L$.
На языке матриц это означает, что для любой матрицы $A \in M_{m\times n}$ существуют ортогональные матрицы  $P$ -- размера $m$ и $Q$ -- размера $n$,  что
$$A= P \Sigma Q.$$
 
\proof Рассмотрим оператор $B = L^{*}L$. Тогда существуют ортонормированный базис $e_1,\dots,e_n$ в котором оператор $B$ диагонален, с неотрицательными числами на диагонали $d_1\geq\dots\geq d_n\geq 0$. Имеем  $d_i=\sigma_i^2$ для единственного положительного $\sigma_i$. 
Посмотрим на вектора $Le_i \in U$. Они ортогональны. Действительно
$$\lan Le_i, Le_j\ran = \lan L^{*}Le_i,e_j \ran = \lan d_i e_i,e_j\ran,$$
что равно нулю, если $i\neq j$. В случае $i=j$ получаем $\|e_i\|^2=d_i$. Возьмём 
$$f_i=\frac{Le_i}{\sqrt{d_i}}$$
и дополним этот набор до ортонормированного базиса пространства $U$. Итого имеем $e_1,\dots,e_n$ ортонормированный базис $U$ и $f_1,\dots,f_m$ -- ортонормированный базис $V$.
Посмотрим матрицу $A$ в этих базисах. По определению $Le_i=\sqrt{d_i}f_i$. Это и даёт требуемый вид матрице оператора $L$.


Напоследок осталось решить вопрос, как выглядит матрица $Q$. В нашей конструкции матрица $Q$ есть матрица замены координат из стандартного базиса в базис из собственных векторов $e_i$ матрицы $A^{\top}A$. Если за $C$ обозначить матрицу из столбцов $e_i$, то $Q=C^{-1}$, но $C$ ортогональна и поэтому можно написать $Q=C^{T}$, то есть строки $Q$ -- собственные вектора $A^{\top}A$.
\endproof
\ethrm

\upr Получите аналогичное описание для $P$.
\eupr

\dfn Базисные вектора такой системы координат в $U$ называются левыми сингулярными векторами $A$, а базис в $V$ -- правыми.  
\edfn

Наличие SVD-разложения означает, что для всякого линейного отображения можно так выбрать декартову систему координат, что в этой системе координат это отображение будет выглядеть как растяжение вдоль каких-то осей.





SVD-разложение используется в практическом решении задачи из метода главных компонент и позволяет сразу найти не только пространство, но и проекцию начальных точек на него. Формализуется это так: рассмотрим матрицу $X$, чьи строки равны $x_i^{\top}$. Тогда если все её строки заменить на их проекции на оптимальное подпространство $V_k$, то получится матрица ранга $k$ или меньше.

Если составить из этих проекцией матрицу $X^{(k)}$, то $\rho(\{x_i\}, V_k)^2= \|X-X^{(k)}\|_F^2 $, где 
$$\|X\|_F=\sqrt{\sum_{i,j} x_{ij}^2}=\sqrt{\Tr X^{\top}X}$$
есть нормы на пространстве матриц. Эта норма, называется нормой Фробениуса.

Оказывается, что так построенная матрица $X^{(k)}$, является ближайшей матрицей ранга $\leq k$ к матрице $X$
Действительно, рассмотрим матрицу $Y^{(k)}$, которая приближает $X$ не хуже $X^{(k)}$. То есть 
$$\|X -Y^{(k)}\|_F^2 \leq \| X-X^{(k)}\|_F^2= \sum \rho(x_i, V_k)^2.$$
Возьмём $L=\Im Y$ -- подпространство размерности $k$. Тогда матрица ${Y^{(k)}}'$ чьи столбцы есть проекции столбцов $X$ на $L$ ближе к $X$, чем $Y^{(k)}$ и равенство достигается, только если $Y^{(k)}={Y^{(k)}}'$. В этой ситуации оптимальная матрица как раз и приходит из пространства $L$ что нам бы и хотелось. Покажем это равенство.

Заметим по построению $\| X - {Y^{(k)}}'\|_F = \sum \rho (x_i, L)^2$, что обязано быть больше или равно чем $\sum \rho(x_i, V_k)^2$. Значит имеет место равенство. Но тогда и матрицы $Y^{(k)}$ и ${Y^{(k)}}'$ одинаково хорошо приближают $X$. Значит $Y^{(k)}={Y^{(k)}}'$ приходят из оптимального подпространства в методе главных компонент. Почему мы не говорим, что эти матрицы не обязательно равны $X^{(k)}$? Потому что оптимум не единственен (если есть кратные собственные числа у $X^\top X$).


Таким образом, нахождение проекций точек на оптимальное, с точки зрения метода главных компонент подпространство можно переформулировать, как нахождение ближайшей к $X$ матрицы ранга меньше или равного $k$. Это легко сделать, зная SVD-разложение.

Прежде чем использовать SVD-разложение заметим, что в такой формулировке задача может быть поставлена в бескоординатном виде: для данного линейного отображения $L$ между евклидовыми пространствами найти наиболее близкое к нему линейное отображение ранга $k$ относительно нормы $\|L\|=\sqrt{\Tr L^*L}$.

\thrm Пусть $L$ -- линейное отображение между евклидовыми пространствами. Пусть $\Sigma$ -- матрица с сингулярными значениями $L$ на диагонали. Тогда ближайшее к $L$ отображения ранга $k$ имеет матрицу $\Sigma^{(k)}$ в базисах из правых и левых сингулярных векторов. Здесь  на диагонали $\Sigma^{(k)}$ стоят вначале $\sigma_1,\dots,\sigma_{k}$, а остальное -- нули.
\proof Перейдём в базис из правых и левых сингулярных векторов. В этих базисах матрица $A$ -- это $\Sigma$.
Значит теперь мы решаем задачу нахождения ближайшей матрицы к матрице $\Sigma$. Для этого нам надо взять проекции строк $\Sigma$ на подпространство порождённое первыми $k$ собственными векторами $\Sigma^\top \Sigma$. После этого из этих проекций надо составить матрицу. Но первые $k$ собственных векторов $\Sigma^\top \Sigma$ это просто первые $k$ координатных векторов. Значит составленная из проекций матрица -- это $\Sigma^{(k)}$.
\endproof
\ethrm 

\crl Пусть $A$ имеет сингулярное разложение $P\Sigma Q$. Тогда ближайшая к $A$ матрица ранга $k$ (в смысле нормы Фробениуса) имеет вид $A^{(k)}=P\Sigma^{(k)}Q$, где на диагонали $\Sigma^{(k)}$ стоят вначале $\sigma_1,\dots,\sigma_{k}$, а остальные элементы матрицы -- нули.
\ecrl

\upr На самом деле матрица $A^{(k)}$ ближайшая к $A$ среди матриц ранга $k$ и в смысле обычной матричной $l_2$-нормы. 
\eupr



\section{Немного вычислительной линейной алгебры}


Перед нами встаёт вопрос: как аккуратно вычислить те объекты линейной алгебры, которые мы определили. Какие для этого есть методы и чем они отличаются. Совершенно понятно, что это огромный круг вопросов и ответить на них на все невозможно. Поэтому я постараюсь обрисовать основные примеры и основные подходы к ответам.

Рассмотрим прежде всего задачу о решении системы линейных уравнений $Ax=b$ с вещественными коэффициентами. 

Во всех реальных приложениях вектор $b$, а часто и матрица $A$ даны не точно, а с некоторой погрешностью. Кроме того, при вычислениях с плавающей точкой мы создаём ещё больше погрешностей. Посмотрим  пример
$$ \pmat 1 & 1 \\ 1 & 1.0001 \epmat x = \pmat 2\\ 2.0001 \epmat$$
У этой системы есть точное решение $x=(1,1)$. Предположим, однако, что из-за ошибок округления вектор $b$ стал равен 
$$b_{new}=\pmat 2 \\ 2 \epmat$$
Решение для $b_{new}$ равно $x=(2,0)^\top$. Видно, что малые изменения коэффициентов системы могут значительно изменить её решение.

Попробуем разобраться, что происходит с общей системой при малых возмущениях её коэффициентов. Для начала разберёмся с погрешностями в $b$.

Обозначим погрешность в значениях свободного члена за $\Delta b$. То есть на самом деле нам дана система $Ay=b+\Delta b$. Самое лучшее, что мы можем сделать -- это точно решить эту новую систему. Насколько решение $y$ этой приближённой системы может отличаться от решения исходной? Пусть $y=x+\Delta x$. Тогда вычитая одно уравнение из другого получаем
$$A \Delta x= \Delta b.$$
Нас будет интересовать прежде всего не абсолютная, а относительная погрешность $\frac{\|\Delta x\|}{\|x\|}$. Оценим её
$$\frac{\|\Delta x\|}{\|x\|}=\frac{\|A^{-1} \Delta b \|}{\|x\|}=\frac{\|A^{-1} \Delta b \|}{\|b\|} \frac{\|b\|}{\|x\|} \leq \|A\| \|A^{-1}\| \frac{\|\Delta b\|}{\|b\|}.$$
Заметим, что здесь мы пользовались определением нормы матрицы при помощи нормы на исходном пространстве, но сам вид нормы на исходном пространстве нам не важен.

Получается, что чтобы мы не делали, просто из-за изначальных погрешностей в данных мы не можем рассчитывать  на погрешность меньшую $\kappa(A)\frac{\|\Delta b\|}{\|b\|}$
(чуть позже мы увидим, что эта оценка точная). 

\dfn Число $\kappa(A)$ называется числом обусловленности матрицы $A$.
\edfn

Оказывается, что число обусловленности отвечает и за влияние погрешностей в коэффициентах матрицы $A$.

Действительно, если посмотреть на решение возмущённой системы $(A+\Delta A)(x+\Delta x)=b$, то вычитая точную систему получаем
$$\Delta x= -A^{-1}\Delta A (x+\Delta x)$$
Переходя к нормам получаем
$$\frac{\|\Delta x\|}{\|x+\Delta x\|}\leq \|A^{-1}\| \|A\| \frac{\|\Delta A\|}{\|A\|}$$

Как найти $\kappa(A)$? Ответ зависит от выбранной нормы. Нам проще всего понять, как найти $\kappa(A)$ в случае евклидовой нормы на $\mb R^n$. В этой ситуации $$\kappa_2(A)=\frac{\sigma_1}{\sigma_n}.$$
Двойка снизу тут в честь $l_2$-нормы.
Покажем теперь, что оценка погрешности при помощи $\kappa_2(A)$ точная. Для этого перейдём в базисы из сингулярных векторов. Тогда можно считать, что $A=\Sigma$ -- диагональна. Возьмём вектора $x,b,\Delta x$ и $\Delta b$ следующим образом:
$$x=\pmat 1 \\ 0\\ \vdots \\ 0 \epmat,\, b=Ax=\pmat \sigma_1 \\ 0\\ \vdots \\ 0 \epmat, \, \Delta b = \pmat 0 \\ \vdots \\ 0 \\ \eps \epmat, \, \Delta x=  \pmat 0 \\  \vdots \\ 0 \\ \eps/\sigma_n\epmat.$$
Для таких векторов оценка достигается.

Можно ли заранее оценить $\kappa(A)$? Можно. Но это не так просто и мы это обсуждать не будем. Замечу только, что главная сложность состоит в оценке $\|A^{-1}\|$.

\dfn
Говорят, что система $Ax=b$ хорошо обусловлена, если $\kappa(A)$ -- мало.
\edfn

Однако мы пока ничего не сказали про особенности методов, могут ли они существенно добавить к ошибкам? Оказывается, что могут. Рассмотрим систему 
$$\pmat 0.0001 & 1 \\ 1 & 1 \epmat x= \pmat 1 \\ 2 \epmat $$
Допустим мы храним только три значащих цифры. Применяя напрямую метод Гаусса последнее уравнение преобразуется к виду $-9999 x_2=-9998 $. Округление его точного решения есть $x_2=0.9999$ (если округлить до 4-го знака), откуда получаем $x_1=1$ (что тоже будет верным до 4-го знака). Но если мы используем округление для коэффициентов матрицы на первом шаге, то предыдущее равенство принимает вид $10000x_2 = 10000$. Получаем, что $x_2'=1$ и $x_1'=0$. Что значительно отличается от точного решения.

\rm Отметьте, что $\kappa_2(A)$ в этом примере всего лишь $2.61...$.
\erm

\dfn Метод называется устойчивым, если ошибки в ходе вычисления имеют порядок, сравнимый с ошибками от возможных погрешностей в исходных данных.
\edfn

Метод Гаусса не является устойчивым методом решения систем линейных уравнений. Можно его доработать, на каждом шаге переставляя строки матрицы так, чтобы каждый раз выбирать в качестве главного элемента  наибольший элемент в столбце. Однако это всё равно решает не все проблемы (см. Wilkinson).

В качестве альтернативы можно посмотреть различные методы, которые находят $QR$ разложение. Однако и $QR$ разложение может давать побочные эффекты.





Есть другой класс методов, позволяющих довольно легко найти приближённое решение. Речь идёт про  итерационные методы. Разберём самый простой пример. Пусть нам дана система линейных уравнений вида $x=Ax+b$, где $A$ -- квадратная матрица. Заметим, что любая система может быть представлена в таком виде. 

Предположим в дальнейшем, что собственные числа $A$ по модулю меньше $1$. Возьмём начальный вектор $x_0$ и построим последовательность
$$x_i=Ax_{i-1}+b.$$
Покажем, что при указанных условиях, эта последовательность стремится к решению системы. Прежде всего заметим, что матрица $E-A$ обратима, так как $0$ не является её собственным числом, и, следовательно, система имеет единственное решение. Пусть это решение --- $x'$. Обозначим $h_i=x_i-x'$. Для $h_i$ получается соотношение:
$$x'+h_i=Ax'+Ah_{i-1}+b.$$
Откуда получаем, что $h_i=Ah_{i-1}$. Но тогда $h_n=A^n h_0$ стремятся к нулю при $n\to \infty$. Значит $x_n\to x'$.


Можно показать, что этот метод устойчив, если имеет место сходимость. Кроме того, заметим, что каждый шаг итерации вычисляется за $O(n^2)$ или даже меньше, если в матрице $A$ много нулей.

Есть более интересные вариации на тему метода итераций. Например, метод Гаусса-Зейделя. Оказывается, что совершенно не обязательно смотреть на представление системы именно в виде $x=Ax+b$. Пусть матрица $A$ есть сумма $A=L+D+U$ (нижнетреугольная -- диагональная -- верхнетреугольная). Представим систему $Ax=b$ в виде 
$$(L+D)x=-Ux+b$$
Если мы определим последовательность $x_i$ по правилу $(L+D)x_{i+1}=-Ux_i+b$, то за сходимость такой последовательности будут отвечать собственные числа матрицы $-(L+D)^{-1}U$. 

Метод Гаусса-Зейделя чаще сходится и скорость сходимости для него обычно более высокая, чем для простого метода итераций (но не всегда). Кроме того, так как матрица $(L+D)$ нижнетреугольная, то решение системы с такой матрицей требует $O(n^2)$ операций. То есть в итоге, каждый шаг стоит $O(n^2)$ операций как и в методе простых итераций.







\subsection{Нахождение собственных чисел и собственных векторов}

Хотелось бы уметь оценивать размер собственных чисел матрицы $A$. Можно ли это сделать? Оказывается, что можно. 


Пусть $A$ -- вещественная или комплексная квадратная матрица. Рассмотрим строки $A$. Зададим элементы $r_i=\sum_{j\neq i} |a_{ij}|$. Рассмотрим множество замкнутых кругов радиуса $r_i$ с центром в $a_{ii}$ на комплексной плоскости. Эти круги называются кругами Гершгорина. 

\thrm Все собственные числа матрицы $A$ лежат в объединении кругов Гершгорина. 
\ethrm
\proof Пусть $\lambda$ -- собственное число $A$, а $v$ -- соответствующий собственный вектор. Тогда $Av=\lambda v$. Посмотрим на максимальный по модулю элемент $v$ -- $v_i$ и соответсвующую ему строчку. Покажем, что $\lambda$ лежит в круге Гершгорина с номером $i$. Имеем $\sum a_{ij}v_j =\lambda v_i$  и, значит, $\sum_{j\neq i} a_{ij}v_j= (\lambda - a_{ii})v_i $. Имеем неравенство $$|\lambda -a_{ii}||v_i| \leq |v_i|\sum_{j\neq i} |a_{ij}|$$
Сокращая на $v_i$ получаем требуемое. 
\endproof

\rm В частности, это рассуждение даёт критерий невырожденности матрицы -- матрица $A$ невырождена, если сумма модулей её внедиагональных элементов каждой строки меньше модуля диагонального элемента. Такие матрицы называются матрицами с диагональным преобладанием
\erm

\rm
Переходя от матрицы к транспонированной можно получить ещё одну оценку, которая получается из рассмотрения столбцов $A$.
\erm

А можно ли точно сказать, в каком из кругов находится собственное число? Оказывается, что иногда можно. Для того чтобы это показать нам нужна некоторая аналитическая подготовка.

\fct[Корни непрерывно зависят от коэффициентов] Пусть $f(x,t)$ -- комплексный многочлен от двух переменных со старшим коэффициентом $1$ при $x^n$, как многочлена над $\mb C[t]$. Пусть $\lambda_1,\dots,\lambda_n$ -- корни $f(x,0)$, а $\mu_1,\dots, \mu_n$ -- корни $f(x,1)$. Тогда cуществуют такие непрерывные на $[0,1]$ функции $\lambda_i(t)$, что $f(\lambda_i(t),t)=0$ и $\lambda_i(0)=\lambda_i$, а $\lambda_i(1)=\mu_{\sigma(i)}$ (для некоторой перестановки $\sigma \in S_n$).
\efct

\thrm Если $k$ кругов Гершгорина матрицы $A\in M_n(\mb C)$ не пересекаются с остальными, то в них лежат $k$ собственных чисел с учётом кратности.
\ethrm
\proof Рассмотрим матрицу $A_t= D+ tB$, где $D$ -- это матрица из диагональных элементов матрицы $A$, а $B$ -- из внедиагональных. Применим факт для характеристического многочлена матрицы $A_t$. Пусть  $\lambda_1(t),\dots,\lambda_k(t)$ -- непрерывные функции, соответствующие выбранным кругам Гершгорина $B_1,\dots,B_k$. Покажем, что каждая из них не вышла за пределы объединения этих кругов в момент $t=1$. 

Пусть скажем $\lambda_1$ при $t=1$ оказался в другом круге. Круги Гершгорина замкнуты. Пусть 
$$r=\rho(B,\cup_{i=1}^k B_i),$$
где $B$ -- это объединение оставшихся кругов. Рассмотрим функцию $f(t)=\rho(\lambda_1(t),B)$,  Это непрерывная по $t$ функция при этом $f(1)=0$. Значит есть такое $t$, что $0<f(t)<r$. С одной стороны, эта точка должна лежать в кругах Гершгорина, но с другой, из определения $r$ следует, что она должна лежать вне всех кругов.  
\endproof

Как это применить к оценки возмущения собственных чисел? Предположим, что $A$ диагонализуема:
$$A=C\pmat \lambda_1 && \\ & \ddots & \\ && \lambda_n \epmat C^{-1}=CDC^{-1}.$$
Рассмотрим сумму $A+\Delta A$. Как оценить собственные числа этой матрицы, через собственный числа $A$?

Пусть $\| \Delta A\|=\eps$. Рассмотрим матрицу
$$C^{-1}(A+\Delta A) C= D+C^{-1}\Delta A C $$
Надо оценить её собственные числа. Для этого заметим, что позиции  $i,j$ матрицы $C^{-1}\Delta A C$ стоит элемент размера не более $\| C^{-1}\| \|C\| \eps$. По теореме о кругах Гершгорина собственные числа $A+\Delta A$ находятся в кругах радиуса $n \| C^{-1}\| \|C\| \eps $ c центрами в $\lambda_i$. Кроме того, для достаточно маленького $\eps$ пары таких кругов не пересекаются или вложены друг в друга. Отсюда

\crl Для достаточно маленького возмущения $\Delta A$ в круге радиуса  $n \| C^{-1}\| \|C\| \|\Delta A\|$ с центром в с.ч.  $\lambda$ матрицы $A$ находится ровно $k$ собственных чисел $A+\Delta A$, где $k$ -- это кратность $\lambda$ у $A$.
\ecrl

Отсюда видно, что  роль, аналогичную числу обусловленности, в оценке на собственные числа играет число $\|C\|\|C^{-1}\|$. На самом деле для каждого собственного числа можно ввести своё число обусловленности. В любом случае, видно, что оценить это число заранее не находя матрицу $C$ не получится. Тем не менее что-то сделать можно. Для произвольной системы это число уже можно оценить, если мы приближённо вычислили $C$ и $C^{-1}$. Однако, есть матрицы для которых это число и так наилучшее возможное. Что это за матрицы?


Раньше, для того, чтобы найти спектр оператора мы считали характеристический многочлен. Однако, его вычисление довольно трудоёмко. Кроме того, после этого необходимо найти ещё и корни характеристического многочлена.


Однако, есть ряд других методов нахождения собственных чисел. С первой идеей мы уже знакомы -- это вариация метода итераций: рассмотрим случайный вектор $x$. Посмотрим на последовательность $A^kx/\|A^kx\|$ $k\to \infty$. Она стремится к максимальному собственному вектору для почти любого $x$. Легко оценить и собственное число.

Если предположить симметричность матрицы $A$. Заметим, что  для почти любого $x$ 
$$\frac {\lan A^{k+1}x, A^k x \ran}{\lan A^k x, A^k x \ran} \to \lambda, $$
где $\lambda$ -- максимальное собственное число.

Есть ещё множество методов для нахождения собственных чисел. 

Есть и метод нахождения всех одновременно собственных чисел: $QR$-алгоритм. Он заключается в следующем: вначале возьмём $A_0=A$. На $k$-ом шаге для матрицы $A_{k-1}$ строится $QR$-разложение $A_{k-1}=Q_kR_k$, а затем строится матрица $A_k=R_kQ_k$. Оказывается, что этот процесс в случае симметричной $A$ сойдётся к диагональной матрице, чьи диагональные элементы  и есть собственные числа $A$. 

Почему этот алгоритм вообще работает и как до него догадаться.

\lm Имеет место соотношение $A_k=Q_k^\top A_{k-1} Q_k$.
\elm

Определим $Q^{(k)}=Q_1\dots Q_k$ и $R^{(k)}= R_k \dots R_1$. В частности, из предыдущей леммы получаем, что $$A_k=Q_k^\top \dots Q_1^\top A Q_1 \dots Q_k= {Q^{(k)}}^\top A Q^{(k)}.$$

\lm  Имеет место соотношение. 
$$A^k=Q^{(k)}R^{(k)}.$$
\elm
\proof Докажем по индукции. 
$$A^k=A A^{k-1}= Q^{(k)}A_k{Q^{(k)}}^\top Q^{(k-1)}R^{(k-1)} = Q^{(k)}A_k Q_k^\top R^{(k-1)}=Q^{(k)} R^{(k)}$$
\endproof
Для того, чтобы просто сформулировать и доказать результат о сходимости QR-алгоритма мы ограничимся положительно определёнными симметричными матрицами.

\thrm Пусть $A$ -- симметричная матрица с различными положительными собственными числами. Тогда столбцы $Q^{(k)}$ стремятся к собственным векторам $A$, а матрицы $A_k$ -- к диагональной матрице, где на диагонали расположены собственные числа $A$.
\ethrm
\proof  Пусть $u_1,\dots,u_n \in \mb R^n$ -- ортонормированный базис из собственных векторов $A$ упорядоченный по убыванию собственных чисел.
Разложим стандартный базисный вектор $e_j$ по базису $u_i$
$$e_j = \sum_i c_{ij} u_i $$
Применим матрицу $A^k$. 
$$A^k e_j = \sum_i c_{ij} \lambda_i^k u_i.$$
Предположим, что главные миноры матрицы $C$ не равны нулю.
Как мы уже доказали, матрица $Q^{(k)}$ -- есть результат ортогонализации (с точностью до $\pm 1$) столбцов матрицы $A^k$, то есть векторов $A^k e_j$. Обозначим столбцы $Q^{(k)}$ за $q^{(k)}_j$ Посмотрим на первый столбец $A^k$. Исходя из нашего предположения, $c_{11}$ не ноль и
$$q^{(k)}_1=\frac1{\|A^ke_1\|} A^k e_1 = \pm u_1 + o(1),$$
при $k\to \infty$. Меняя при необходимости направление $u_1$ на противоположенное избавимся от $\pm$ в формуле. Посмотрим, что происходит при ортогонализации второго столбца. Вычислим скалярное произведение:
$$\frac{\lan A^k e_2, A^k e_1 \ran}{\lan A^k e_1, A^k e_1 \ran} = \frac{c_{12}}{c_{11}}+ O\left( \lambda_2^{2k}/\lambda_1^{2k}\right)
=\frac{c_{12}}{c_{11}}+ o \left(\left(\lambda_2/\lambda_1 \right)^k\right)  $$
Вычитая получаем
$$ A^k e_2 - \left(\frac{c_{12}}{c_{11}}+ o \left(\left(\lambda_2/\lambda_1\right)^k\right)\right) A^k e_1= o(\lambda_2^k)u_1+ c_{22}\lambda_2^ku_2 - \frac{c_{12}}{c_{11}}c_{21}\lambda_2^k u_2 +o(\lambda_2^k).$$
Коэффициент $c_{22}-\frac{c_{12}}{c_{11}}c_{21}$ по условию не равен $0$. После нормировки этот вектор стремится к $\pm u_2$. Продолжая так далее, получим, что столбцы $Q^{(k)}$ сходятся к собственным векторам $A$ в порядке убывания собственных чисел. Тогда в $i,j$ элементе матрицы $A_k={Q^{(k)}}^\top A Q^{(k)}$  стоит
$$\lan q^{(k)}_i, Aq^{(k)}_j\ran \to \lan u_i, \lambda u_j \ran = \lambda_i \delta_{ij}.$$
Значит, матрица $A_k$ действительно сходится к нужной диагональной матрице.
\endproof



\section{Спектры графов}
С графом $G$ связаны несколько разных матриц. Как свойства этих матриц, их собственные числа отражаются в комбинаторных свойствах графа $G$ и может ли это помочь?
Приведём пример, как знание спектра графа даёт некоторые оценки на сложно вычисляемые величины.

\rm Граф $G$ является $k$-регулярным тогда и только тогда, когда вектор $(1,\dots,1)^\top$ является собственным вектором с собственным числом $k$ для $A(G)$.
\erm

\thrm Пусть $G$ -- $k$-регулярный граф. Тогда размер максимального независимого множества в графе оценивается как
$$\alpha(G)\leq n\frac{-\lambda_n}{k-\lambda_n}.$$
\ethrm
\proof Рассмотрим характеристический вектор $v$ для независимого множества размера $\alpha$. Имеем $v^{\top}Av=0$ и при этом $v^{\top}v=\alpha$. Так как граф $k$-регулярный, то у него есть нормированный собственный вектор $u_1=\frac{1}{\sqrt{n}}(1,\dots,1)$. Тогда $\lan v,u_1\ran = \frac{\alpha}{\sqrt{n}}$. Разложим вектор $v=c_1u_1 + \dots + c_n u_n$ по ортонормированной системе собственных векторов. Тогда из условия независимости получаем
$$0=v^{\top}Av=\sum c_i^2 \lambda_i= \lambda_1\frac{\alpha^2}{n}+ \sum_{i\geq 2} \lambda_i c_i^2\geq \lambda_1\frac{\alpha^2}{n}+ \lambda_n \sum_{i\geq 2} c_i^2.$$
Мы знаем, что $\sum c_i^2=\alpha$, откуда $\sum_{i\geq 2} c_i^2=\alpha - \frac{\alpha^2}{n}$. Итого 
$$0\geq \lambda_1\frac{\alpha^2}{n}+\lambda_n(\alpha- \frac{\alpha^2}{n})$$
Сокращая на $\alpha$ получаем 
$$(\lambda_1-\lambda_n)\frac{\alpha}{n}\leq -\lambda_n,$$
что эквивалентно нужному неравенству.
\endproof




\exm\\
1) Полный граф $K_n$ имеет спектр $n-1,-1,\dots,-1$. В полном соответствии с тем, что размер максимального независимого множества равен $1$.\\
2) Граф Петерсена имеет спектр 3, 1, 1, 1, 1, 1, -2, -2, -2, -2. Размер независимого множества в точности равен $4$.\\
3) Оценка точна в общем виде для графов Кнезера $K(n,r)$.


Из оценки на размер независимого множества можно вывести оценку на хроматическое число.

\zd Покажите, что $\alpha(G) \chi(G) \geq n$. Выведите отсюда, что для регулярного графа $\chi(G)\geq 1+ \frac{\lambda_1}{-\lambda_n}$. Покажите, что для графа Петерсена оценка точная.
\ezd

\rm Удивительно, но ровно та же оценка верна и для нерегулярных графов тоже.
\erm

\zd Покажите, что $\chi(G) \leq [\lambda_1]+1$ для любого графа $G$. (Адаптируйте классическое доказательство с максимальной степенью).
\ezd


\subsection{Дополнительно: ещё трюки и применения}

\thrm Рассмотрим граф $K_{10}$. Тогда его невозможно покрыть тремя копиями графа Петерсена.
\ethrm
\proof Пусть граф $K_{10}$ покрыт тремя графами Петерсена. Тогда его матрица смежности удовлетворяет соотношению 
$$A(K_{10})=P_1+P_2+P_3.$$
Для нашего удобства перепишем это в виде 
$$-A(K_{10})=-P_1-P_2-P_3.$$
Заметим, что вектор $(1,\dots,1)^\top$ -- собственный для всех трёх матриц. Значит мы может ограничить указанное равенство на его ортогональное дополнение $U$.

Мы находимся в 9-тимерном пространстве. Воспользуемся неравенствами на собственные числа суммы (которые мы не доказывали). Тогда $i$-ое собственное число  суммы трёх матриц $A,B,C$ может быть оценено как $\lambda_t +\mu_s+ \nu_r$, где $r+s+t=i+2$. У операторов $-P_i|_U$ собственные числа равны $$2,2,2,2,-1,-1,-1,-1,-1.$$
Возьмём  $r=s=5$ и $t=1$. Получим оценку на $9$-ое собственное число $-A(K_{10})|_U$. Но мы его знаем: это $1$. С другой стороны получается, что оно должно быть меньше $0$. Противоречие! 
\endproof

Кроме оценок на хроматическое число и покрываемость при помощи спектров можно доказать негамильтоновость графа, оценивать его рёберное хроматическое число переходя к рёберному графу и т.д.

\zd Пусть $B$ -- матрица инцидентности графа $G$. Покажите, что $B^\top B - 2 E$ есть матрица смежности для рёберного графа $G$, а $B B^\top$ есть $A(G)+D$, где $D$ -- это матрица со степенями вершин графа $G$ на диагонали. 
\ezd

\zd Покажите, что в рёберном графе графа Петерсена нет индуцированного цикла длины 10 и выведите отсюда, что граф Петерсена негамильтонов.
\ezd

Есть, однако, две темы, связанные с собственными числами графов, которые приводят к непосредственным применениям. К сожалению, как часто бывает, у нас нет шансов внимательно посмотреть результаты этих разделов, поэтому мы ограничимся лишь очерчиванием их границ.




\dfn Для $A$ -- подмножества $V(G)$ определим $\partial A$ как множество всех рёбер ведущих из $A$ в вершины не из $A$. Константа Чигера или константа расширения графа  $G$ это 
$$h(G) := \min \left\{ \left. \frac{| \partial A |}{| A |} \right|   A \subseteq V(G), 0 < | A | \leq \tfrac{1}{2} | V(G)| \right\} .$$
\edfn

Вычислить константу Чигера очень сложно. Однако её можно оценить.

\begin{thmm}[Неравенство Чигера] Пусть $G$ -- $d$-регулярный граф и $\lambda_2$ -- его второе по максимальности собственное число. Тогда
$$\tfrac{1}{2}(d - \lambda_2) \le h(G) \le \sqrt{2d(d - \lambda_2)}.$$
\end{thmm}



\dfn Семейство графов $G_n$ называется $(n,d,\alpha)$ (алгебраическим) экспандером, если $G_n$ -- $d$-регулярный граф на $n$ вершинах с $\lambda=\max(|\lambda_2|,|\lambda_n|)\leq \alpha d$.
\edfn

Где могут применяться такие графы:\\
1) Коды, исправляющие ошибки\\
2) Псевдослучайные генераторы\\
3) Дерандомизация

Несмотря на то, что большая часть регулярных графов степени $d$ обладает указанными свойствами  до некоторого времени не было ни одного явного примера семейства экспандеров. Первый пример семейства экспандеров дал Григорий Маргулис. \\


\exm\\
1) Рассмотрим $\mb Z/n \times \mb Z/n$ и проведём для пары $(x,y)$ ребро в $(x \pm 2y,y), (x \pm (2y+1),y), (x,y \pm 2x), (x,y \pm (2x+1))$. Получается граф-экспандер с $\lambda \leq 5\sqrt{2}$\\
2) Можно подметить, что рёбра экспандеров из предыдущего примера связаны с некоторыми обратимыми преобразованиями, то есть с какой-то группой. Это общее место для конструкции большинства экспандеров.



\dfn Определим Лапласиан графа как $L(G)$ как $D-A(G)$.
\edfn

\zd $L(G)=B B^\top$, где $B$ -- матрица инцидентности произвольным образом ориентированного графа $G$.
\ezd

\zd $L$ -- неотрицательно определена и  $\rk L= \rk B=n-c$, где $c$ -- это количество компонент связности графа $G$.
\ezd



Кроме собственно графов можно рассматривать взвешенные графы. Понятно, как для них определить матрицы $D$, $A(G)=W(G)$ -- матрица весов, $L(G)$. Кроме этих матриц нам понадобится ещё и нормализованная матрица Лапласа.


\dfn Рассмотрим матрицу $D^{-1/2} L(G) D^{-1/2}$. Это нормализованный Лапласиан.
\edfn

На основе нормализованного Лапласиана можно построить алгоритм фрагментации изображений. Как и любая естественная задача она не имеет чёткой формулировки. В 2000 году Jianbo Shi и  Jitendra Malik \href{https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf}{предложили} следующую версию формулировки задачи: по картинке строится взвешенный граф $G$  -- его множество вершин $V$ -- это пиксели, рёбра проводятся, если вершины близки друг к другу и вес зависит от того, насколько пиксели похожи друг на друга.

Теперь рассматриваются все подмножества пикселей $A\subseteq V$ и минимизируется величина разреза, который отрезает $A$ от остального графа.
$$\min_{A} \frac{assoc(A,V\setminus A)}{assoc(A,V)}  + \frac{assoc(A, V\setminus A)}{assoc(V\setminus A,V)}, $$
$$\text{ где } \,\, assoc(A,B)=\sum_{i\in A, j\in B} w_{ij}$$.


Вопрос стоит в выборе оптимального $A$. Сопоставим множеству $A$ вектор $y$, такой что $$y_i = \begin{cases}-b=-\frac{\sum_{v\in A} d_v}{\sum_{v \not\in A} d_v}, \text{ если } i\not\in  A \\
1, i\in A 
\end{cases}$$

Оказывается, что в этом случае задача сводится к минимизации по всем таким $y$ выражения 
$$\frac {y^\top L(G) y} {y^\top D y } \text{ при этом выполнено } y D \bf 1 = 0.$$ 

Здесь $\bf 1$ -- это столбец из единиц. Решить эту дискретную задачу (допустимых $y$-ков конечное число) трудно, поэтому авторы переходят к непрерывной, отбрасывая ограничения на значения $y_i$. Минимум такого выражения достигается на $D^{-1/2}v$, где $v$ -- собственный вектор нормализованного Лапласиана для минимального положительного собственного числа ($D^{-1/2}\bf 1$ -- это собственный вектор для собственного числа $0$).

Теперь, беря $v$ можно разделить точки по признаку положительности и отрицательности (например).

\rm Похожий метод для матрицы Лапласа приводит к оценке связности графа и позволяет приближённо найти минимальный вершинный разрез графа дающий несколько компонент связности. (см. вектор Фидлера).
\erm






\section{Двойственное пространство}

Начнём наше триумфальное возвращение из мира вещественных чисел в мир произвольных полей. В дальнейшем $K$ обозначает произвольное поле. 

\dfn Определим двойственное пространство к пространству $V$ как $V^*=\Hom (V, K)$.
\edfn

\dfn Пусть $e_1,\dots,e_n$ -- базис $V$. Определим $e^1,\dots,e^n$ как базис пространства $V^*$, заданный следующим соотношением: 
$$e^j(e_i)=\delta_{ij}.$$
Иными словами, $e^i$ -- это $i$-ая координатная функция в базисе $e$.
\edfn

\utv Пусть $V$ -- векторное пространство над полем $K$. Тогда имеет место естественный изоморфизм пространств $V\to {V^*}^*$.
\eutv
\proof Построим отображение по правилу $v \to (f \to f(v))$. Это отображение инъективно. Из равенства размерностей следует, что этого и достаточно.
\endproof

Если мы перешли от одного базиса к другому в пространстве $V$, то что произошло в $V^*$? 

\thrm Пусть $e_1,\dots,e_n$ старый базис $V$, а $\hat{e}_1,\dots,\hat{e}_n$ -- новый. Пусть $C$ -- матрица перехода из старого базиса в новый. Тогда матрица перехода из базиса $e^1,\dots,e^n$ в базис $\hat{e}^1,\dots,\hat{e}^n$ есть ${C^{\top}}^{-1}$.
\proof Вспомним нашу конвенцию: матрица перехода $C$ это, столбцы которой составлены из координат нового базиса в старом базисе. Если у нас есть вектор $v$, то это условие означает, что его новый столбец координат $y$ и старый столбец координат связаны уравнением $x=Cy$. Переписывая получаем соотношение 
$$C^{-1}x=y.$$
Но это есть соотношение между координатными функциями в новом базисе и в старом базисе, то есть, между векторами двойственных базисов. Почти то, что нужно. Осталось из этого соотношения найти матрицу перехода. Для этого запишем $$y_i=\sum_j (C^{-1})_{ij}x_j$$
Значит, элементы $(C^{-1})_{ij}$ должны стоять в $i$-ом столбце матрицы перехода из $\hat{e}$ в $\hat{e}^*$. Это значит, что эта матрица равна ${C^{-1}}^{\top}$.
\endproof
\ethrm

В особые отношения со своим двойственным пространством вступают евклидовы и унитарные пространства. 

\utv Пусть $V$ -- евклидово или унитарное пространство. Тогда любой линейный функционал имеет вид $\lan v, \_ \ran$ для единственного вектора $v$. 
\eutv
\proof Пусть $f$ -- линейный функционал. Рассмотрим $U=\Ker f^\bot$. Это одномерное пространство. Рассмотрим $v\in U$ отличный от нуля и подгоним при помощи константы так, чтобы  $f(v)=\lan v,v \ran$. Этого достаточно благодаря линейности каждого выражения.  
\endproof

\section{Немного про квантовую механику}

Вкратце напомню парадигму квантовой механики. Физическая система в квантовой механике задаётся при помощи некоторого унитарного пространства $V$. Каждая прямая этого унитарного пространства задаёт некоторое возможное физическое состояние системы. На каждой прямой есть вектор, по норме равный $1$. Итого, каждый вектор, равный по норме $1$ описывает некоторое физическое состояние. 

Квадрат модуля скалярного произведения двух таких нормированных векторов  $|\lan u,v \ran|^2$ интерпретируется как вероятность того, что  $v$ при измерении будет находится в состоянии $u$ (если вы можете померить, что что-то находится именно в состоянии $u$). Таким образом, каждый вектор $u\in V$ задаёт линейный функционал $\lan u, \_ \ran $ на $V$, который по состоянию $v$ выдаёт информацию о вероятности найти $v$ в состоянии $u$.

Каждой измеримой физической величине соответствует самосопряжённый оператор $T$ на $V$. Пусть $\psi_i$ -- это ортонормированный базис из собственных векторов $T$ с собственными числами $\lambda_i$. Тогда вероятность, что находясь в состоянии $v$ при измерении величины $T$ мы получим $\lambda_i$ есть вероятность найти $v$ в состоянии $\psi$, то есть $|\lan \psi_i, v \ran|^2$. Несложно заметить, что, как и должно быть, сумма по всем возможным $i$ этих вероятностей даёт $1$. Такая конструкция объясняет квантованность (дискретность) значений разных физических величин, которая возникает при измерении.

Типичным примером квантовой системы является нерелятивистская (без учёта теории относительности) модель одной частицы в $\mb R^3$. В этом случае роль унитарного пространства играет 
$$V= L_2(\mb R^3)=\left\{  f\colon \mb R^3 \to \mb C\, \Big| \, f - \text{ измерима и } \int_{\mb R^3} |f|^2<\infty \right\}.$$
Технически тут ещё понадобится отождествить функции отличающиеся друг от друга на множестве меры ноль, но я это опускаю. Скалярное произведение таких функций задаётся привычной формулой 
$$\lan f,g \ran = \int_{\mb R^3} \ovl{f}g\, dx.$$
Состояние квантовой системы, соответствующее нормированной функции $f\in V$ (т.е. $\|f\|^2=1$)  имеет следующую интерпретацию: $\int_{B} |f|^2$ есть вероятность для частицы оказаться в области $B$. 

 

В квантовых вычислениях основным объектом является квантовый бит или кубит (qubit) -- это двумерная квантовая система. Первый её базисный вектор обозначается $\left|0\ran$, а второй $ \left|1\ran$. Предполагается, что это собственные вектора оператора энергии т.е. два эти состояния различаются при измерении энергии. Произвольное состояние (нормированное) есть смесь 
$$c_1 \left|0\ran+ c_2 \left| 1\ran, \text{ где } |c_1|^2+|c_2|^2=1.$$
 

Допустим, у нас есть две независимые системы с пространствами $V_1$ и $V_2$. Какое пространство соответствует  объединению двух таких систем? Обозначим это пространство за $V_1\otimes V_2$. Посмотрим как должны выглядеть состояния этого пространства. Понятно что для каждой пары состояний $u_1\in V_1$ и $u_2\in V_2$ должно существовать своё состояние объединённой системы. Обозначим его за $u_1 \otimes u_2$. Другими словами должно быть задано отображение $i\colon V_1\times V_2\to V_1 \otimes V_2$.

Пусть есть одна пара $(u_1,u_2)$ и вторая пара $(v_1,v_2)$. Какова вероятность того, что при измерении система в состоянии $u_1\otimes u_2$ перейдёт  в состояние $v_1 \otimes v_2$? Логично, чтобы это было $|\lan u_1,v_1 \ran \lan u_2, v_2\ran|^2$.

Какому скалярному произведению на таких парах это соответствует? Должно быть $\lan u_1\otimes u_2, v_1\otimes v_2\ran = \lan u_1,v_1 \ran \lan u_2, v_2\ran$. То есть, скалярное произведение с состоянием $u_1\otimes u_2$ есть не линейная функция от пары $(v_1, v_2)$, а билинейная!



Линейные отображения можно складывать между собой. Сумме линейных отображений, заданных при помощи $u_1\otimes u_2$ на $V_1\otimes V_2$ должна соответствовать сумма билинейных форм на $V_1\times V_2$. Заметим, что любую билинейную форму можно представить в виде суммы форм заданных при помощи пар $(u_1,u_2)$. Таким образом, логично считать, что все линейные функционалы на $V_1\otimes V_2$ должны соответствовать билинейным формам на $V_1\times V_2$.





\section{Тензорное произведение}

Сейчас мы немного поговорили про пространство линейных функционалов, прошлом семестре мы подробно остановились на билинейных операциях. А квантовая механика дала нам необходимость в следующем определении:

\dfn Пусть дана пара пространств $U,V$ над полем $K$. Тогда их тензорным произведением называется пространство 
$U\otimes V$ вместе с билинейным отображением отображением
$$i \colon U \times  V \to U \otimes V,$$
удовлетворяющее условию что для любого билинейного отображения из $h\colon U \times V \to W$ существует единственное линейное отображение 
$$\hat{h}\colon U\otimes V \to W,$$
что 
$$\hat{h}\circ i=h.$$
Иными словами, отображение $i$ -- это <<универсальное>> билинейное отображение.
\edfn 


\lm Пусть $U\leq V$, а $\pi \colon V \to V/U$ -- это каноническая проекция на $V/U$. Пусть $L\colon V \to W$ -- линейное отображение. Тогда, для того, чтобы существовало $\hat{L}\colon V/U \to W$, что $L=\hat{L}\circ \pi$ необходимо и достаточно, чтобы $L(U)=\{0\}$.
\elm





\thrm Пусть $U,V$ -- пара векторных пространств. Тогда имеет место следующая конструкция тензорного произведения:
$$U \otimes V \cong K\lan U \times V \ran / Rel,$$
где $Rel$ -- это подпространство порождённое формальными суммами
$$(\lambda u_1+u_2, v) - \lambda (u_1, v) - ( u_2,v) \text{ и } (u,\lambda v_1+v_2) - \lambda (u,v_1) - (u,v_2).$$ 
\proof Для удобства обозначим пространство
$$T=K\lan U \times V \ran / Rel.$$ Будем обозначать образы элементов $(u,v)$ в $T$ как  $u\otimes v$. Отображение $$i \colon U\times V \to T$$
заданное правилом  $(u,v) \to u \otimes v$
билинейно по самому определению соотношений из $Rel$. Пусть теперь дано пространство $W$ и билинейное отображение $$h \colon U \times V \to W.$$
Построим отображение $\hat{h}$ следующим образом: сначала определим $\hat{\hat{h}}\colon K\lan U \times V \ran \to W$, а затем покажем, что оно пропускается через $T$. По самому своему определению $K\lan U \times V\ran$ имеет базисом элементы $(u,v)$. Отображение $\hat{\hat{h}}$ достаточно задать на них. Положим $$\hat{\hat{h}}((u,v))=h(u,v).$$
Покажем, что оно однозначно пропускается через $T$. Как всегда единственность очевидна. Для того чтобы показать, что $\hat{\hat{h}}$ пропускается через $T$ необходимо показать, что все соотношения лежат в ядре $\hat{\hat{h}}$. Но это так, потому что $h$ билинейно! 
\endproof
\ethrm




Мы показали, что тензорное произведение существует. Неплохо бы понять, что тензорное произведение однозначно определено с точностью до изоморфизма. 


\utv Если тензорное произведение существует, то оно единственно с точностью до изоморфизма. Конкретно, пусть $U,V$ -- векторные пространства и есть два пространства $T_1,T_2$ и $i_1 \colon U\times V \to T_1$ и $i_2\colon U\times V \to T_2$, играющие роль тензорного произведения, то существует единственный изоморфизм $h\colon T_1\to T_2$, что $h\circ i_1=i_2$.
\proof Это типичное <<категорное>> доказательство. Пусть есть два пространства $T_1$ и $T_2$ вместе с отображениями $i_1 \colon U\times V \to T_1$ и $i_2 \colon  U\times V \to T_2$, для которых выполнены аксиомы тензорного произведения. Заметим, что так как $i_2$ полилинейное, то есть такое $\hat{i_2} \colon T_1 \to T_2$, что $$\hat{i_2}\circ i_1= i_2.$$ 
Аналогично существует $\hat{i_1} \colon T_2 \to T_1$, что
$$\hat{i_1}\circ i_2= i_1.$$ 
Покажем, что $\hat{i_1} $ и $\hat{i_2}$ взаимно обратны. Действительно, имеем
$$\hat{i_1}\circ \hat{i_2}\circ i_1= \hat{i_1}\circ i_2= i_1,$$
что означает, что отображение $\hat{i_1}\circ \hat{i_2}$ есть то самое единственное отображение $T_1\to T_1$, которое гарантируется благодаря полилинейности $i_1$ и того, что само $T_1$ -- тензорное произведение. Но есть другой кандидат на эту роль -- это $\id_{T_1}$. По единственности 
$$\hat{i_1}\circ \hat{i_2}=\id_{T_1}.$$
Аналогично проверяется равенство для второй композиции.
\endproof
\eutv





Теперь необходимо посчитать что-то про тензорное произведение. Например, научиться считать размерность тензорного произведения и находить его базис.
\thrm Пусть $e_1,\dots,e_n$ базис $U$, а $f_1,\dots,f_m$ -- базис $V$. Тогда $e_i\otimes f_j$ базис $U \otimes V$. В частности, 
$$\dim U \otimes V= \dim U \cdot \dim V.$$ 
\proof Прежде всего заметим, что набор $e_i \otimes f_j$ является порождающей системой для тензорного произведения. Значит оно на самом деле конечномерно. Далее, по определению тензорного произведения,
$$\Hom(U;V, K) \simeq \Hom(U\otimes  V,K).$$
Размерность последнего пространства совпадает с размерностью $U\otimes V$. С другой стороны, полилинейное отображение $h \in \Hom(U,V, K)$ однозначно задаётся $\dim U \cdot \dim V$  параметрами $h(e_i,f_j)$. Комбинируя эти два факта получаем, что размерность $\dim U \otimes V$ есть $\dim U \cdot \dim V$. Отсюда, любая порождающая система такого размера есть базис. В частности, набор $e_i \otimes f_j$.
\endproof
\ethrm


\rm Пространство состояний квантовой системы из $n$ кубит имеет размерность $2^n$. Это ключевой факт, который проясняет потенциальную эффективность квантовых компьютеров: вместо $n$ бит мы имеем дело с $2^n$ чисел -- координатами вектора из $2^n$-мерного пространства.
\erm


Определим теперь тензорное произведение линейных отображений.

\dfn Пусть дана пара линейных отображений $L \colon U_1 \to V_1$ и $S\colon U_2 \to V_2 $. Определим отображение $$L\otimes S \colon U_1\otimes U_2 \to V_1\otimes V_2$$ по  правилу $$(L \otimes S) (u_1\otimes  u_2) = L(u_1)\otimes S(u_2).$$
Отображение с таким свойством единственно.
\edfn

\rm Указанное отображение существует и единственно. Действительно,  отображение $L\otimes S$ должно соответствовать билинейному отображению $L\times S$ заданному правилом $L\times S ((u_1,u_2)) = L(u_1)\otimes S(u_2)$. 
\erm

\rm Пусть заданы наборы линейных отображений $L_1, L_2$ и $S_1, S_2$, так что определены композиции $L_i\circ S_i$. Тогда
$$(L_1\otimes S_1) \circ (L_2 \otimes S_2)=(L_1\circ L_2)\otimes (S_1\circ S_2).$$
\erm 

А как устроена матрица тензорного произведения линейных отображений?


\lm Пусть $L_1 \colon V_1 \to U_1$, а $L_2 \colon V_2 \to U_2$. Пусть $e_1,\dots, e_{n_1}$ базис $V_1$,  $e_1',\dots, e_{n_2}'$ базис $V_2$,  и $f_1,\dots, f_{m_1}$ -- базис $U_1$, а $f_1',\dots, f_{m_2}'$ -- базис $U_2$. 
Упорядочим базисы тензорных произведений -- удобно это сделать, например, в лексикографическом порядке (номер первой координаты важнее).
Тогда матрица  $L_1\otimes L_2$  разобьётся на $n_1m_1$ блоков в каждом из которых будет стоять $ A_{ij} B$, где $i,j$ -- номер блока, а $A$ и $B$ матрицы $L_1$ и $L_2$ соответственно.
\proof Действительно, отображение $A\otimes B$ отправляет $e_i\otimes e'_j$ в 
$$Ae_i \otimes Be'_j = \sum_{k,l} A_{ki}B_{lj} \, f_k\otimes f'_l.$$
\endproof
\elm

\dfn Такая матрица называется кронекеровым или тензорным произведением матриц $A$ и $B$ и обозначается как $A\otimes B$.
\edfn

А что если стартовать с операторов, а не с линейных отображений?

\rm Если есть операторы $A\colon V \to V$ и $B \colon W \to W$. Тогда задан оператор $A\otimes B$ на $V\otimes W$.
\erm

\lm Собственные числа оператора $A\otimes B$  -- это попарные произведения собственных чисел для $A$ и $B$. 
\proof Перейдём к матрицам и, если нужно, будем считать, что мы находимся над алгебраически замкнутым полем. Рассмотрим жорданов базис для $A$ и $B$ -- $v_1,\dots,v_n$ и $u_1,\dots, u_m$. Тогда, рассмотрев базис $v_i\otimes u_j$, заметим, что под диагональю будут стоять нули, а на диагонали -- попарные произведения собственных чисел $A$ и $B$.
\endproof
\elm


 

\dfn[Произведение графов] Пусть $G$ и $H$ -- два графа (возможно ориентированных). Тогда их категорным произведением называется граф чьи вершины есть пары вершин $G$ и $H$ и ребро между парами $(u_1,v_1)$ и $(u_2,v_2)$ проводится только если есть рёбра $u_1 \to u_2$ и $v_1 \to v_2$.

Декартовым произведением графов $G$ и $H$ называется граф на тех же вершинах с ребром между парами если $u_1=u_2$ и есть ребро $v_1\to v_2$ или, симметрично, $v_1=v_2$ и есть ребро $u_1 \to u_2$. Разумеется для неориентированных графов эта конструкция снова выдаёт неориентированный граф.
\edfn


\crl Спектр категорного произведения графов состоит из всех возможных попарных произведений собственных чисел графов.
\proof Заметим, что матрица смежности категорного произведения графов -- это тензорное произведение матриц смежности исходных графов.
\endproof
\ecrl



\zd Чему равен спектр декартового произведения графов?
\ezd

\zd Чему равен спектр графа-решётки
\ezd

А можно ли как-то охарактеризовать тензорное произведение нескольких пространств?

\rm Если рассмотреть тензорное произведение $V_1\otimes \dots \otimes V_n$, то линейные отображения из него в $W$ будут соответствовать полилинейным отображениям $\Hom(V_1;\dots ;V_k, W)$.
\erm

С понятием тензорного произведения связан ряд канонических отождествлений между разными на первый взгляд пространствами в духе изоморфизма $V \simeq V^{**}$.

\thrm Имеют место следующие естественные изоморфизмы: 
$$(U \otimes V) \otimes W \simeq U \otimes V \otimes W \simeq U \otimes (V \otimes W)$$
$$ U \otimes V \simeq V \otimes U $$
$$ \Hom (U,V) \simeq  V \otimes U^*$$
$$(U \otimes V)^{*} \simeq U^{*}\otimes V^{*} $$
$$\Hom (U\otimes V,  W) \simeq \Hom (U, \Hom (V,W))$$
\proof Наиболее интересная часть этой теоремы состоит в бескоординатном построении этих отображений.

Построим отображение $V\otimes U^{*} \to \Hom (U,V)$ по правилу $$v\otimes f \to (u \to f(u)v).$$
Это соответствие полилинейно по $v,f$ поэтому задаёт корректное линейное отображение. Полезно посмотреть, как оно действует на базисных векторах. Пусть $e_i$ базис $V$, $f_j$ -- базис $U$, а $f^j$ базис $U^{*}$. Тогда $e_i\otimes f^j$ соответствует линейное отображение с матрицей 
$$ e_{ij}= \bordermatrix{
 & &j&& \cr
 &0&\cdots&\cdots&0\cr
 &\vdots&\ddots && \vdots\cr
i&\vdots& 1 & \ddots& \vdots\cr
 &0&\cdots& \cdots&0
}$$
Такие линейные отображения образуют базис $\Hom(U,V)$. Значит указанное отображение -- изоморфизм.

\endproof 
\ethrm


\subsection{Тензоры на пространстве и их классическое определение}

Понятие тензора появилось в классической механике для ответа на вопрос, как меняются те или иные величины при замене координат. Для того, чтобы обсудить этот аспект тензоров дадим определение:

\dfn Тензором валентности $(p,q)$ на пространстве $V$ называется элемент пространства ${V^{*}}^{\otimes p} \otimes V^{\otimes q}$. Так же будем говорить, что такие элементы -- это $p$ раз ковариантные и $q$ раз контравариантные тензоры. Тензорами валентности $(0,0)$ называются элементы поля $K$ -- скаляры.
\edfn

Теперь я утверждаю, что более менее все встречавшиеся нам структуры на векторном пространстве $V$ являются тензорами.



\exm\\
1) Вектор $v\in V$ является 1 раз контравариантным тензором.\\
2) Элемент двойственного пространства $f \in V^{*}$ является 1 раз ковариантным тензором. Вообще ковариантными называют тензоры, которые соответствуют полилинейным формам на пространстве $V$. Это историческая традиция. Точнее:\\
3) Так как пространство ${V^{*}}^{\otimes p} \simeq \left(V^{\otimes p}\right)^*\simeq \Hom(V;\dots;V,K)$, то тензор валентности $(p,0)$ соответствует полилинейному отображению $V\times\dots \times V \to K$.\\
4) В частности, тензор валентности $(2,0)$ -- это билинейная форма.\\
5) Линейный оператор -- это элемент $\Hom(V,V)\simeq V^{*}\otimes V$, то есть тензор валентности $(1,1)$.\\
6) Структура алгебры на $V$ (без требования ассоциативности) задаётся билинейным отображением $V \times V \to V$, то есть линейным отображением $V\otimes V \to V$ или же элементом $V^{*}\otimes V^* \otimes V$, то есть тензором типа $(2,1)$.\\

Как записать тензор в координатах? Выберем базис $e_1,\dots,e_n$ пространства $V$ и возьмём в двойственном пространстве двойственный базис $e^1,\dots,e^n$. Теперь построим базис тензорного произведения ${V^{*}}^{\otimes p}\otimes V^{\otimes q}$. Он имеет вид $e^{j_1}\otimes\dots\otimes e^{j_p}\otimes e_{i_1}\otimes \dots \otimes e_{i_q}$. Тогда произвольный тензор $T$ валентности $(p,q)$ имеет вид 
$$ T= \sum_{\substack{i_1,\dots,i_q \in \ovl{1,n}\\ j_1,\dots,j_p \in \ovl{1,n}} } \,T_{j_1,\dots,j_p}^{i_1,\dots,i_q}\,\, e^{j_1}\otimes\dots\otimes e^{j_p}\otimes e_{i_1}\otimes \dots \otimes e_{i_q}.$$
Элементы $T_{j_1,\dots,j_p}^{i_1,\dots,i_q}$ называются координатами тензора $T$. Как меняются координаты тензора при замене базиса? 

\thrm Пусть $e_1,\dots,e_n$ старый базис $V$, а $\hat{e}_1,\dots,\hat{e}_n$ -- новый. Пусть $C$ -- матрица перехода из нового базиса в старый, а $D={C^{\top}}^{-1}$. Тогда координаты тензора $T$ в базисе $\hat{e}$ выражаются через старые координаты следующим образом:
$$\hat{T}_{j_1,\dots,j_p}^{i_1,\dots,i_q}=\sum_{\substack{i'_1,\dots,i'_q \in \ovl{1,n}\\ j'_1,\dots,j'_p \in \ovl{1,n}}} \,\,
\prod_{t\in \ovl{1,p}} D_{j_t,j'_t} \prod_{s\in \ovl{1,q}} C_{i_s,i'_s}  \,\,T_{j'_1,\dots,j'_p}^{i'_1,\dots,i'_q}.$$
\ethrm

Важность тензоров в теоретической физике обуславливается тем, что практически все физические объекты -- это тензоры. Точнее: с точки зрения теории относительности пространство-время это некоторое четырёхмерное многообразие $M$ (в двумерной ситуации подошла бы обычная сфера или тор). С каждой точкой $x$ этого многообразия связано касательное пространство в этой точке -- некоторое четырёхмерное пространство $T_x$. Представим себе, что в каждой точке пространства задана плотность вещества (на самом деле не так, но допустим) -- это даёт вам функцию $f \colon M \to \mb R$ -- скаляр в каждой точке, то есть тензор типа $(0,0)$. 

Направление движения материи можно задать взяв в каждой точке касательный вектор, то есть тензор валентности $(0,1)$ на $T_x$. Дальше, у каждого такого вектора можно считать его <<длину>> и углы между векторами. Для этого надо задать для каждой точки $x$ билинейную форму на касательном пространстве, то есть элемент $T_x^{(2,0)}$. И т.д. Чаще всего такие объекты называют тензорными полями, если хочется подчеркнуть, что в разных точках это тензор вообще говоря на разных пространствах.

Важно, что уравнения в физике не должны зависеть от выбора координат. Можно, конечно, писать какие-то уравнения при помощи координат тензоров и каждый раз проверять, что выбрав новые координаты уравнение будет того же вида. Однако, чем сложнее наука тем сложнее становятся проверки. Становится важно работать с тензорами не рассматривая их координаты. Поэтому на тензорах вводят стандартные операции, которые заведомо не зависят от выбора координат.


\section{Ранг тензора}

Нам хорошо знакомо понятие ранга билинейной формы и ранга линейного отображения. Но и билинейная форма и линейное отображение тесно связаны с понятием тензорного произведения. Можно ли обобщить понятие ранга на произвольные тензоры? Оказывается, что да. 

\dfn Пусть $U_1,\dots, U_n$ пространства и дан $f\in U_1 \otimes \dots \otimes U_n$. Рангом тензора $f$ называется наименьшее такое $r$, что $f=f_1+\dots+f_r$, где $f_i$ -- элементарный тензор.
\edfn

\zd Это определение совпадает с определением ранга для билинейных форм (как элементов $U^*\otimes V^*$) и для линейных отображений (как элементов $U^* \otimes V$).
\ezd

Наибольшую популярность понятие ранга тензора приобрело после работ Штрассена по умножению матриц. А именно, рассмотрим конкретный тензор. Пусть $V$ -- это пространство квадратных матриц размера $k$. Тогда матричное умножение задаёт на $V$ тензор валентности $(2,1)$, то есть элемент $M\in V^*\otimes V^* \otimes V$. Представим себе, что ранг этого тензора равен $r$.

Это означает, что мы можем выбрать такие элементы $f_1,\dots,f_r, g_1, \dots, g_r \in V^*$, и $v_1,\dots,v_r \in V$, что
$$M= \sum f_i\otimes g_i \otimes v_i.$$
Что это означает с точки зрения произведения матриц? Две матрицы -- это два элемента $A,B \in V$. Тогда 
$$AB=\sum f_i(A)g_i(B)v_i$$
$f_i$ и $g_i$ -- это линейные выражения от коэффициентов матриц и значит  $f_i(A)$ и $g_i(B)$ могут быть вычислены при помощи сложения чисел и умножения чисел на фиксированные скаляры. Далее, мы вычисляем произведения $P_i=f_i(A)g_i(B)$. Для этого нужны полноценные операции произведения. После этого, умножаем $P_i$ на $v_i$. Так как коэффициенты $v_i$ постоянны, то для этой операции тоже не нужно честное умножение. Итого, реально используется $r$ настоящих умножений. 

На самом деле, верно и обратное: если если мы найдём формулу для умножения матриц, которая использует только $r$ честных умножений, то можно будет построить такое разложение тензора матричного умножения. 

Пример такого умножения построил Штрассен для матриц $2\times 2$. Пусть 
$$A=\pmat A_{1,1} & A_{1,2} \\ A_{2,1} & A_{2,2} \epmat \text{ а } B=\pmat B_{1,1} & B_{1,2} \\ B_{2,1} & B_{2,2} \epmat.$$
Определим вслед за Штрассеном
$$
\begin{aligned}
&f_1=A_{1,1}+ A_{2,2} &\quad & g_1= B_{1,1}+B_{2,2} &\quad & P_1=f_1\cdot g_1\\
&f_2=A_{2,1}+A_{2,2} &\quad & g_2=B_{1,1}&\quad & P_2=f_2\cdot g_2\\
&f_3=A_{1,1}&\quad & g_3=B_{1,2}-B_{2,2}  &\quad & P_3=f_3\cdot g_3\\
&f_4=A_{2,2}&\quad & g_4=B_{2,1}-B_{1,1} &\quad & P_4=f_4\cdot g_4\\
&f_5=A_{1,1}+A_{1,2}&\quad & g_5=B_{2,2} &\quad & P_5=f_5\cdot g_5\\
&f_6=A_{2,1}-A_{1,1}&\quad & g_6=B_{1,1}+B_{1,2} &\quad & P_6=f_6\cdot g_6\\
&f_7=A_{1,2}-A_{2,2}&\quad & g_7=B_{2,1}+B_{2,2} &\quad & P_7=f_7\cdot g_7.
\end{aligned}
$$


$$
v_1= \pmat 1 & 0 \\ 0 & 1 \epmat,  \quad
v_2=\pmat 0& 0\\0 & -1\epmat,  \quad
v_3=\pmat 0 & 1 \\ 0 & -1 \epmat,  \quad
v_4=\pmat 1& 0\\1 & 0 \epmat,  
$$
$$
v_5=\pmat -1& 1\\ 0& 0\epmat,  \quad
v_6=\pmat 0&0 \\0 & 1\epmat,  \quad
v_7=\pmat 1& 0\\ 0& 0\epmat,  \quad
$$
Элементы $f_i,g_i,v_i$ задают разложение тензора матричного умножения. Если $C=AB$, то для элементов $C$ справедливы формулы
$$ 
\begin{aligned}
&C_{1,1}=P_1+P_4-P_5+P_7\\
&C_{1,2}=P_3+P_5\\
&C_{2,1}=P_2+P_4\\
&C_{2,2}=P_1-P_2+P_3+P_6
\end{aligned}
$$

Элементы $f_i,g_i,v_i$ показывают, что ранг тензорного произведения матриц $2\times 2$ не больше $7$. На самом деле ранг умножения матриц $2\times 2$ действительно равен $7$.

Но как это поможет для умножения матриц больших размеров? Как обычно предположим, что $n=2^k$. Тогда матрицы $A$ и $B$ можно разбить на подматрицы размера $2^{k-1}$ которые мы обозначим как $A_{i,j}, B_{i,j}$ как и раньше. Заметим, что теперь мы снова перемножаем матрицы $2\times 2$, элементы которых на этот раз не числа, а матрицы. 

Если мы посмотрим процедуру умножения матриц, которая произошла из разложения тензора матричного умножения , то увидим, что в этой процедуре мы не использовали коммутативности умножения элементов поля. Действительно, элементы $A$ всегда находились слева в формуле по сравнению с элементами $B$, а элементы $A$ как и элементы $B$ между собой не перемножались.

Значит указанная формула справедлива и для умножения блочных матриц. Мы можем применить указанный способ рекуррентно. Тогда необходимое  число умножений в данном алгоритме будет удовлетворять рекурренте:
$$T(n)=7\cdot T(n/2).$$
То есть всего мы потратим $7^{k}=n^{\log_2 7}$ умножений.

\zd Оцените количество сложений в алгоритме как $6\cdot 7^k$.
\ezd

На текущий момент при помощи оценки рангов (правда не совсем тензора матричного умножения) получены оценки $O(n^{2.373})$ операций для умножений матриц $n\times n$.

Почему мы не знаем окончательного ответа на то, какой ранг у умножения матриц размера $k\times k$? Потому что ранг тензора тяжело считать. Прежде всего тут стоит отметить, что ранг тензора, зависит от того поля, над которым мы этот ранг считаем. 

Например, ранг умножения комплексных чисел над $\mb R$ равен $3$ (а не $4$, как вы могли бы подумать). Но ранг тензора умножения комплексных чисел над $\mb C$ равен $2$ (коэффициенты тензора вещественные, но мы их  рассматриваем как элементы из $\mb C$).  

Так вот. Вычисление ранга тензора над $\mb C$ и над $\mb R$ является NP-трудной задачей. А вычисление ранга тензора над $\mb Z$, то есть когда мы хотим, чтобы все коэффициенты были целочисленными, и вовсе алгоритмически не разрешим. Это есть следствие негативного решения 10 проблемы Гильберта. Вопрос алгоритмической неразрешимости над $\mb Q$ остаётся открытым (как и аналог 10 проблемы Гильберта).




\section{Внешняя и симметрическая алгебры}

В этом разделе мы будем рассматривать векторное пространство $V$ над полем характеристики $0$. Есть общая теория не только для полей, но и для произвольных колец, однако, даже базовые конструкции в этой теории сложнее и некоторые её утверждения просто неверны над полем ненулевой характеристики.

\dfn Определим пространство $\Lambda^k V$ как подпространство $V^{\otimes k}$. Это подпространство выделяется следующими условиями -- для любой перестановки из $\sigma \in S_k$ и любого тензора $a\in \Lambda^k V$ верно, что $\sigma(a)=\sgn(\sigma)a$. Под $\sigma(a)$ подразумевается действие перестановки $\sigma$ на тензор $a$ перестановкой его компонент. Аналогично определяется подпространство $\Sym^k V \leq V^{\otimes^k}$, чьи элементы удовлетворяют свойству: $\sigma(a)=a$.
\edfn

\lm Имеет место проектор $Alt \colon V^{\otimes k} \to \Lambda^k V$ (называется альтернированием) 
$$a \to Alt(a)=\frac{1}{k!} \sum_{\sigma \in S_k} \sgn (\sigma) \sigma(a).$$
Аналогично отображение  симметризации
$$ a \to S(a)= \frac{1}{k!} \sum_{\sigma \in S_k} \sigma(a)$$
есть проектор на подпространство $\Sym^k V$.
\proof Докажем только первую часть. Прежде всего заметим, что $Alt$ принимает значение в подпространстве кососимметричных тензоров. Действительно 
$$\tau(Alt(a))=\frac{1}{k!}\sum_{\sigma \in S_k}\sgn(\sigma) \tau(\sigma(a))= \sgn{\tau} \frac{1}{k!}\sum_{\tau\sigma \in S_k} \sgn(\tau\sigma) \tau(\sigma(a))=\sgn(\tau) Alt(a).$$
Далее, покажем, что для любого кососимметричного тензора $a$ верно, что $Alt(a)=a$. Это покажет, что $Alt$ -- есть проектор и в его образе лежат все элементы из $\Lambda^k(V)$, то есть ровно то, что осталось показать. Итак пусть $a\in \Lambda^k(V)$. Тогда 
$$Alt(a)=\frac{1}{k!} \sum_{\sigma \in S_k} \sgn (\sigma) \sigma(a)=\frac{1}{k!} \sum_{\sigma \in S_k} \sgn^2(\sigma) a=a.$$
\endproof
\elm

\dfn Пусть $e_1,\dots, e_k$ набор элементов из $V$. Определим элементы $e_1\wedge \dots \wedge e_k \in \Lambda^k V$ как образы при проекции $e_1\otimes \dots \otimes e_k$.
\edfn

\thrm Пусть $e_1,\dots, e_n$ базис пространства $V$. Тогда элементы $e_{i_1}\wedge \dots \wedge e_{i_k}$, где $i_1<i_2< \dots < i_k$ образуют базис пространства $\Lambda^k V$. Элемент $e_{i_1}\wedge \dots \wedge e_{i_k}$, где $i_1<i_2< \dots < i_k$  обозначим за $e_{\Gamma}$, где $\Gamma =\{i_1,\dots,i_k\}\subseteq \ovl{1,n}$ подмножество размера $k$. Это взаимооднозначное соответствие. В частности, размерность $\dim \Lambda^k V = C^k_n$. 
\proof Прежде всего заметим, что это действительно порождающая система. Для этого вспомним, что $e_{i_1,\dots,i_k}$ по всем возможным наборам $i_1,\dots,i_k$ порождают тензорное произведение $V^{\otimes k}$. Но раз они порождают тензорное произведение, то они порождают и его образ при проекции $Alt$ на пространство кососимметричных тензоров. Далее заметим, что $$Alt(e_{i_1,\dots i_k})= \sgn(\sigma) Alt(e_{i_{\sigma(1)},\dots i_{\sigma(k)}}).$$
В частности, если в наборе есть два повторяющихся индекса, то элемент проектируется в 0. Далее, это же соотношение даёт, что,  с точностью до знака $Alt$ от тензора для набора $i_1,\dots,i_k$ совпадает с проекцией для упорядочевания этого набора. Таким образом, из набора образующих можно исключить неупорядоченные наборы и наборы с повторениями, что и требовалось.

\noindent Покажем линейную независимость. Пусть  
$$\sum_{\Gamma} \alpha_{\Gamma} e_{\Gamma}=0.$$
Тогда расписывая эту сумму через $e_{i_1}\otimes \dots \otimes e_{i_k}$ -- базисные элементы $V^{\otimes k}$ получаем
$$\frac{1}{k!}\sum_{\Gamma} \alpha_{\Gamma} \sum_{\sigma \in S_{\Gamma}} \sgn(\sigma) e_{\sigma(i_1),\dots,\sigma(i_k)} =0 $$
Заметим, что все слагаемые соответствуют разным базисным элементам. Тогда, все коэффициенты равны нулю. В частности, коэффициенты при $ e_{i_1, \dots, i_k}$, которые равны $\frac{1}{k!}\alpha_{\Gamma}$. 

\endproof
\ethrm

\thrm Аналогично, пусть $e_1,\dots, e_n$ базис пространства $V$. Тогда элементы образы тензоров $e_{i_1}\otimes \dots \otimes e_{i_k}$, где $i_1\leq \dots \leq i_k$ образуют базис пространства $\Sym^k V$.
\ethrm

\dfn Определим $k$-ую внешнюю степень линейного отображения $L\colon V \to W$ -- отображение $\Lambda^{k} L  \colon \Lambda^k V \to \Lambda^k W$ заданное на тензорах по правилу $v_1\wedge \dots \wedge v_k \to L v_1 \wedge \dots \wedge L v_k$. 
\edfn

Для того, чтобы показать корректность такого определения покажем следующую теорему:

\thrm Рассмотрим отображение $g=Alt \circ i \colon V^{\times k} \to \Lambda^k(V)$. Тогда для любого полилинейного кососимметричного $h \colon V^{\times k} \to U$ существует единственное отображение $\hat{h} \colon \Lambda^k(V) \to U$, что $\hat{h} \circ g = h$.
\proof Зафиксируем подходящее $h \colon V^{\times k} \to U$. Так как это полилинейное отображение, то есть линейное $\hat{\hat{h}}\colon V^{\otimes k} \to U$, что $\hat{\hat{h}} \circ i =h$. Покажем, что ограничение $\hat{\hat{h}}$ на $\Lambda^k(V)$ есть искомое отображение. Действительно $$\hat{h}(v_1\wedge\dots\wedge v_k)=\hat{\hat{h}}(v_1\wedge\dots\wedge v_k)=\hat{\hat{h}} \left(\frac{1}{k!} \sum_{\sigma \in S_k} \sgn(\sigma) v_{\sigma(1)}\otimes \dots \otimes v_{\sigma(k)} \right) =$$
$$=\frac{1}{k!} \sum_{\sigma \in S_k} \sgn(\sigma) h(v_{\sigma(1)},\dots,v_{\sigma(k)})=\frac{1}{k!}k!h(v_1,\dots,v_k)=h(v_1,\dots,v_k).$$

Осталось показать единственность. Для этого заметим, что из условия  $\hat{h}$ однозначно задано на базисе $e_{\Gamma}$.
\endproof
\ethrm


\fct Полезно смотреть не на пространства $\Lambda^k (V)$ и $\Sym^k V$, а на пространства $\Lambda^k(V^*)$ и $\Sym^k(V^*)$, потому что они допускают привычную и наглядную интерпретацию --- их элементы это полилинейные функции со специальными свойствами.
\efct


\exm \\
1) Элемент $\Lambda^2(V^*)$ --- это просто кососимметрическая билинейная форма.\\
2) А элемент $\Sym^2 V^*$ -- это симметрическая билинейная форма или просто квадратичная форма.\\
3) Элемент $\Lambda^{\dim V} V^*$ -- это просто форма объёма на $V$.\\

Мы хотим ввести умножение на кососимметричных тензорах. Есть два подхода: первый из них -- потребовать, чтобы пара $v_1 \wedge \dots \wedge v_p , u_1\wedge \dots \wedge u_q$ переходила в $v_1 \wedge \dots \wedge v_p \wedge u_1\wedge \dots \wedge u_q$. С таким подходом возникает вопрос о корректности. С другой стороны, такое умножение удобно вычислять. Второй подход -- связать это умножение с формальным умножением тензоров. Проблема возникает в следующем -- если $T_1$ и $T_2$ -- кососимметрические тензоры, то $T_1\otimes T_2$, вообще говоря, не кососимметричный. Мы доведём до конца второй путь.

\thrm[Внешняя алгебра] Рассмотрим пространство $\Lambda(V)=\oplus_{k=0}^{\dim V} \Lambda^k(V)$ и введём на нём структуру ассоциативной алгебры по правилу $ f\wedge g= Alt(f\otimes g)$. Если $f\in \Lambda^p(V)$, а $g \in \Lambda^q(V)$, то $f\wedge g=(-1)^{pq}g \wedge f$. Такое свойство называется градуированной коммутативностью. Более того, пара $v_1 \wedge \dots \wedge v_p , u_1\wedge \dots \wedge u_q$ переходит при этом умножении в $v_1 \wedge \dots \wedge v_p \wedge u_1\wedge \dots \wedge u_q$. Такое умножение называется внешним произведением тензоров.
\proof Для этого удобно проверить тождество $Alt(Alt(T_1)\otimes T_2)= Alt(T_1\otimes T_2)= Alt(T_1 \otimes Alt(T_2))$, которое говорит, что внутри альтернирования можно свободно альтернировать сомножители не боясь ничего поменять. Действительно
$$\frac{1}{k!}\sum_{\sigma \in S_{k}}\sgn(\sigma) Alt(T_1^{\sigma}\otimes T_2)=\frac{1}{k!}\sum_{\sigma \in S_{k}} \sgn^2(\sigma) Alt(T_1\otimes T_2)=Alt(T_1 \otimes T_2).$$
Аналогично получается второе равенство. Теперь видно, что 
$$Alt(v_1 \wedge \dots \wedge v_p \otimes u_1\wedge \dots \wedge u_q)=Alt(v_1 \otimes \dots \otimes v_p \otimes u_1\wedge \dots \wedge u_q)=$$
$$=Alt( v_1 \otimes \dots \otimes v_p \otimes u_1\otimes \dots \otimes u_q) =v_1 \wedge \dots \wedge v_p  \wedge u_1\wedge \dots \wedge u_q .$$
Это показывает связь нашего определения умножения с ожидаемым определением. Ассоциативность теперь легко проверить на базисных элементах, как и градуированную коммутативность.
\endproof
\ethrm





\thrm[Симметрическая алгебра] Рассмотрим пространство $\Sym(V)=\oplus_k \Sym^k(V)$. Тогда на нём можно ввести структуру ассоциативной коммутативной алгебры задав умножение как $ f*g= S(f\otimes g)$. Более того, указанная алгебра изоморфна алгебре многочленов.
\ethrm



Изначально, внешняя алгебра была нужна для <<исчисления подпространств>> в пространстве $V$. А именно, подпространству $U\leq V$ размерности $k$ можно сопоставить прямую $\Lambda^k U$ в $\Lambda^k V$. Более того, задав на $U$ форму объёма можно выбрать на этой прямой определённую точку. Такие объекты теперь можно перемножать и складывать, хотя в общем случае может получиться и объект, не соответствующий никакому подпространству. 

Сейчас понятие внешней алгебры может служить удобным формализмом для определения интегрирования. А именно, по многообразию размерности $n$ можно проинтегрировать кососимметричное тензорное поле валентности $(n,0)$, то есть заданную в каждой точке многообразия форму объёма на касательном пространстве. В общем же виде кососимметричные тензорные поля типа $(k,0)$ называются дифференциальными формами порядка $k$. На таких дифференциальных формах задана операция взятия дифференциала, делающая из $k$-формы $k+1$-форму. Это ещё одна из канонических <<бескоординатных>> операций. Об этом вам расскажут в курсе анализа.

\subsection{Внешняя алгебра и определитель}

Покажем способ применения внешней степени для доказательства тождеств про определители. Введём обозначение.

\dfn Пусть $A$ -- матрица из $M_{m\times n}(K)$. Тогда если $\Gamma \subseteq \{1,\dots,n\}$. Тогда за $A_{\Gamma}$ обозначим матрицу состоящую из столбцов матрицы $A$ с элементами из $\Gamma$. Аналогично, если $\Gamma \subseteq \{1,\dots,m\}$ то за $A^{\Gamma}$ обозначим подматрицу $A$, из строк, чьи индексы лежат в $\Gamma$.
\edfn

Посмотрим, как устроены координаты внешнего произведения произвольного набора векторов. Пусть $e_1,\dots,e_n$ -- базис $V$, $v_1,\dots,v_k$ --  произвольный набор векторов. Пусть $A$ -- это матрица координат векторов $v_1,\dots,v_k$.
Рассмотрим $v_1 \wedge \dots \wedge v_k$. Это полилинейная кососимметрическая функция от $v_1,\dots,v_k$, а вместе с ней и координаты этого произведения. Ясно, что координаты при $e_{\Gamma}=e_{i_1}\wedge\dots\wedge e_{i_k}$ зависят только от строк матрицы $A$ с номерами из $\Gamma$. Если в этих строках стоит единичная матрица, то ясно, что координата при $e_{\Gamma}$ -- это единица. Вспоминая, что есть определитель, получаем, что в общем виде коэффициент при $e_{\Gamma}$ это определитель $A^{\Gamma}$. Итого 
$$v_1 \wedge \dots \wedge v_k= \sum_{\substack{\Gamma \subseteq \{1,\dots,n\}\\ |\Gamma|=k}} \det A^{\Gamma} e_{\Gamma}.$$

Несложно получить эту формулу непосредственно.

Пусть есть отображение $L \colon U \to V$, где $\dim U= \dim V = n$ и $A$ матрица $L$ в базисах $e_1,\dots e_n$ и $f_1,\dots,f_n$. Тогда $$\Lambda^n L(e_1\wedge \dots \wedge e_n) = \det A \,\,f_1 \wedge \dots \wedge f_n.$$
Из этого замечания уже легко получить мультипликативность определителя. Поступая аналогично можно доказать более общую теорему:



\thrm[Формула Бине-Коши] Рассмотрим две матрицы $A\in M_{m\times n}(K)$ и $B\in M_{n\times m}(K)$. Пусть $m\leq n$. Тогда
$$\det(AB)=\sum_{\substack{\Gamma \subseteq \{1,\dots,n\}\\ |\Gamma|=m}} \det A_{\Gamma} \det B^{\Gamma}.$$
\proof Рассмотрим линейные отображения, заданные матрицами $A\colon K^n \to K^m$ и  $B \colon K^m \to K^n$. Тогда $\Lambda^m (AB)$ есть оператор домножения на $\det AB$. С другой стороны $\Lambda^m(AB)=\Lambda^m(A) \Lambda^m(B)$. Вычислим матрицы этих отображений. Матрица $\Lambda^m(B)$ есть столбец высоты $C_n^m$, чьи элементы проиндексированы $\Gamma \subseteq \{1,\dots,n\}$ размера $m$. Аналогично матрица $\Lambda^m(A)$  есть строчка, чьи элементы проиндексированы аналогично.
Пусть $e_1,\dots,e_m$ -- стандартный базис $K^m$, $e=e_1\wedge \dots \wedge e_m$ единственный базисный элемент $\Lambda^m(K)$, а $f_1,\dots,f_n$ -- стандартный базис $K^n$. Тогда 
$$\Lambda^m(B)(e)=\sum_{\substack{\Gamma \subseteq \ovl{1,n} \\ |\Gamma|=m}} \det B^{\Gamma} f_{\Gamma}.$$
 С другой стороны, 
$$\Lambda^m(A)(f_{\Gamma})=\det(A_{\Gamma})e.$$
Осталось перемножить строчку на столбец.
\endproof
\ethrm

Покажем, как можно использовать формулу Бине-Коши. Вначале докажем общие факты про графы.

\dfn Определим матрицу оператора Лапласа для графа $G$ как $L(G)=D-A(G)$.
Ориентируем произвольным образом рёбра графа $G$. Тогда определим ориентированную матрицу инцидентности, как матрицу, строки которой соответствуют вершинам $G$, столбцы -- рёбрам $G$. В столбце соответствующем ребру стоит $1$ в позиции, конца этого ребра и $-1$ в позиции начала. 
\edfn

\lm Выполнено равенство $L(G)=B^\top B$ при любой ориентации рёбер графа.
\elm

Это сразу говорит нам, что матрица $L(G)$ неотрицательно определена. Однако у матрицы $L(G)$ всегда нетривиальное ядро. Действительно, столбец $(1,\dots,1)^\top$ лежит в ядре $L(G)$. Можно сказать точнее:

\lm Пусть у графа $G$ ровно $k$ компонент связности. Тогда $\dim \Ker L(G)\geq k$. На самом деле, выполнено равенство.   
\elm

\crl Если граф $G$ не связен, то алгебраическое дополнение любого элемента в матрице $L(G)$ равно $0$.
\ecrl

\lm Пусть граф $G$ -- дерево. Тогда алгебраическое дополнение любого элемента матрицы $L(G)$ равно 1.
\elm
\proof Пусть нам дан элемент с индексами $i,j$ в $L(G)$. Если $B$ -- ориентированная матрица инцидентности графа $G$, то этот определитель вычисляется как произведение  $\det B^{\ovl{i}}$ и $\det B^{\ovl{j}}$. Сведём вычисление каждого из этих определителей к ситуации, когда граф $G$ -- путь, а выкинута первая строка. Для того, чтобы разобраться с номером вершины просто поставим выкидываемую строчку на первое место. Теперь заметим, что оба определителя не меняются при элементарных преобразованиях столбцов $B$.
Теперь опишем процедуру <<выпрямления>> дерева на языке элементарных преобразований. 
\endproof

\crl[Теорема о деревьях] Количество остовных деревьев в графе $G$ есть алгебраическое дополнение любого элемента матрица $L(G)$.
\ecrl
\proof Прежде всего отметим, что если $G$ не связен, то и любой минор $L(G)$ равен $0$. $L(G)=BB^\top$, где $B$ -- ориентированная матрица смежности графа $G$. Найти какое-то алгебраическое дополнение $L$ -- это то же самое, что найти определитель $\hat{B}\hat{B}^\top$, где $\hat{B}$ -- матрица $B$ с одной выкинутой строкой. Определитель $\hat B \hat{B}^\top$ легко считается по формуле Бине-Коши. В этой формуле мы должны выбрать $\hat{B_{\Gamma}}$, то есть $n-1$ строк $\hat{B}$ и найти
$$(\det \hat{B}_{\Gamma})^2=\det(\hat{B}_{\Gamma} \hat{B}_{\Gamma}^\top)$$
Но $\det \hat{B}_{\Gamma} \hat{B}_{\Gamma}^\top$ -- это минор матрицы Лапласа графа, чьи рёбра соответствуют строкам матрицы $B$. Если этот граф  -- не дерево, то он не связен и этот определитель равен $0$. Если это дерево, то оно остовное и этот определитель равен единице. Так как по формуле Бине-Коши для вычисления определителя надо просуммировать такие слагаемые, то мы получаем ровно количество остовных деревьев.
\endproof


\crl[Формула Кэли] Количество различных помеченных деревьев на $n$ вершинах равно $n^{n-2}$.
\ecrl


\chapter{Многочлены}

Настала пора вернуться к незаконченной теме про делимость. В этой связи мы снова вернёмся к предположению, что все кольца коммутативны. На этот раз мы поговорим подробно о кольце многочленов от $n$ переменных. Мы знаем, что кольцо многочленов $K[x]$ над полем $K$ является областью главных идеалов и вывели из этого однозначность разложения на множители в $K[x]$. Есть ли надежда повторить тоже самое для многочленов от двух и более переменных? 

Ответ на этот вопрос даёт следующий пример: рассмотрим идеал, порождённый независимыми переменными $x,y$ в кольце $K[x,y]$. Этот идеал нельзя породить одним элементом.

Однако мы интуитивно представляем то, что разложение многочленов на множители однозначно. Математически такое свойство кольца называлось факториальностью.

\dfn
Область целостности $R$ называется факториальным кольцом, если для любого $a\in R$, что $a\neq 0$  существует представление $a=\eps p_1\dots p_k$, где $\eps \in R^*$, а $p_1,\dots,p_k$ -- простые элементы $R$.
\edfn

\rm Исходя из определение простоты, такое разложение единственно с точностью до ассоциированности. Действительно, если $f=\eps\prod p_i= \delta \prod q_j$, то $p_1 \di \prod q_j$ и благодаря простоте делит скажем $q_1$. Но тогда $p_1h=q_1$, откуда, благодаря неприводимости $q_1$ получаем, что $h$ обратим, то есть, что $p_1 \sim q_1$. Тогда можно сократить на $p_1$ и продолжить по индукции.
\erm


\rm В факториальном кольце есть НОД любых двух элементов (естественно, с точностью до ассоциированности).
\erm


Итак, наша ближайшая цель поговорить о факториальности колец многочленов. Однако, для приложений к теории чисел нам будет необходимо разработать теорию в достаточной общности, чтобы применить её и над $\mb Z$, а не только над полем. Заметим, что $\mb Z$ и поле $K$ являются факториальными кольцами. Мы покажем, что факториальность кольца влечёт факториальность кольца многочленов над ним, что полностью ответит на наши вопросы.

Для этого доказательства нам понадобится конструкция факторкольца, важность которой мы почувствуем позднее.

\dfn Пусть $R$ кольцо, а $I\leq R$ -- идеал. Тогда на факторгруппе $R/I$ можно ввести структуру кольца определив умножение по формуле $\ovl{a}\ovl{b}=\ovl{ab}$. 
\edfn

\dfn Идеал $I$ называется простым, если выполнено, что $ab\in I$, то $a\in I$ или $b\in I$.
\edfn

\rm Элемент $p\in R$ отличный от нуля прост тогда и только тогда, когда идеал $(p)$ прост, тогда и только тогда, когда $R/(p)$ -- область целостности.
\erm


\section{Многочлены над факториальным кольцом}

Наша задача обсудить, что происходит с кольцом многочленов от многих переменных.


\lm[Гаусс] Пусть $R$ -- кольцо. Тогда любой простой элемент $p$ из $R$ остаётся простым в $R[x]$.
\proof
Теоретически удобно воспользоваться следующим соображением: чтобы показать, что элемент прост надо показать, что идеал $(p)$ в $R[x]$ прост, а для этого необходимо и достаточно установить, что $R[x]/(p)$ есть область целостности. Как же описать $R[x]/(p)$? Я утверждаю, что оно изоморфно $(R/p)[x]$. Действительно, из $R[x]$ есть отображение в $(R/p)[x]$, которое берёт все коэффициенты по модулю $p$. Очевидно, в его ядре лежат ровно те многочлены, все коэффициенты которых делятся на $p$, то есть многочлены кратные $p$ в $R[x]$. Но ровно они и образуют идеал $(p)$. Осталось заметить, что кольцо $R/p$ и, вслед за ним, кольцо $R/p[x]$ являются областями целостности.

У этого доказательства есть другая, более элементарная реинкарнация. А именно, формально нам надо доказать, что если произведение двух многочленов $f(x)g(x)$ делится на $p$ (то есть все коэффициенты кратны $p$), то тогда какой-то из них делится на $p$. Пусть это не так. Возьмём тогда у $f$ и у $g$ самые младшие коэффициенты $a_i$ и  $b_j$, которые не делятся на $p$. Тогда посмотрим на коэффициент с номером $i+j$  в произведении. Он имеет вид $c_{i+j}= a_ib_j + \sum_{k \neq i} a_k b_{i+j -k}$. Я утверждаю, что $c_{i+j}$ не делится на $p$. Для этого заметим, что любое слагаемое в сумме делится на $p$, так как либо $k<i$ и тогда $a_i \di p$, либо $k>i$, то есть $i+j-k<j$ и следовательно $b_j \di p$. Противоречие с тем, что $c_{i+j}$ должен делиться на $p$.   
\endproof
\elm

\upr Поясните, почему оба доказательства одинаковы.
\eupr

\dfn Пусть $f(x)$ -- многочлен над факториальным кольцом $R$. Тогда содержанием $f$ называется $\cnt(f)=\Nod (a_i)$, где $a_i$ коэффициенты $f$. 
\edfn

Следующее следствие тоже называют леммой Гаусса.

\crl Если $f(x)=g(x)h(x)$, где $f,g,h \in R[x]$, то $\cnt(f)=\cnt(g)\cnt(h)$
\proof Для начала, упростим задачу, то есть сведём задачу к случаю $\cnt g= \cnt h =1$. Для этого надо рассмотреть многочлены $\frac{g}{\cnt g}$ и $\frac{h}{\cnt h}$. Их произведение есть $\frac{f}{\cnt{g}\cnt{h}}$ имеет содержание $\frac{\cnt f}{\cnt g \cnt h}$ и если показать его единичность, то мы добьёмся требуемого. Итак считаем, что $\cnt g= \cnt h=1$. Если $\cnt f$ не обратим, то $\cnt f \di p$, где $p$ простой элемент из $R$. Но тогда один из $g$ или $h$ делится на $p$ благодаря простоте $p$. 
\endproof
\ecrl


\lm Пусть для многочлена $f(x) \in R[x]$  имеет место разложение $f(x)=g(x)h(x)$, где  $g(x), h(x) \in Q(R)[x]$. Пусть $c \in Q(R)^*$, такая что $cg \in R[x]$ и $\cnt(cg)=1$. Тогда $c^{-1}h \in R[x]$, что означает, что $f(x)=cg(x)c^{-1}h(x)$ -- есть произведение двух многочленов из $R[x]$ пропорциональных исходным.
\proof Для начала отметим, что такая константа $c$ существует. Заменяя $g$ на $cg$ можно считать, что $c=1$. В этом предположении нам надо доказать, что $h\in R[x]$.
Домножим $h$ на $d\in R$, так что $dh \in R[x]$. Тогда $df=g dh$ и значит
$$d\cnt f = \cnt(g) \cnt(dh)=\cnt(dh).$$
Таким образом, коэффициенты $dh$ делятся на $d$, а значит исходный $h$ был из $R[x]$.
\endproof
\elm

Заметим, что для любого ненулевого многочлена $g(x)$ указанная в лемме константа всегда существует. Теперь нам легко доказать теорему.


\thrm Пусть $R$ -- факториальное кольцо. Тогда кольцо $R[x]$ факториально. Более того, имеет место следующее описание простых элементов кольца $R[x]$ с точностью до ассоциированности:\\
1) $f\in R[x]$ такой, что $cont(f)=1$ и $f$ неприводим в $Q(R)[x]$.\\
2) $f=p \in R$ -- простой в $R$.
\proof 
Для начала покажем, что все указанные ситуации приводят к простым элементам в кольце $R[x]$.
Итак, пусть $f \in R[x]$ неприводим в $Q(R)[x]$ и $cont(f)=1$. Если $gh\di f$ в $R[x]$, то это же верно в $Q(R)$. По условию $f$ неприводимый, а значит простой в $R[x]$ и можно считать, например, что $g\di f$ в $Q(R)[x]$. Тогда $g= fh$. Тогда $h\in R[x]$, по лемме. Значит, $g \di f$ в $R[x]$. Второй случай непосредственно следует из леммы Гаусса.


Теперь покажем, что любой элемент $R[x]$ раскладывается в произведение указанных простых. Для этого сначала разложим $f$ в $Q(R)[x]$ в произведение неприводимых $f=\prod g_i$, $g_i \in Q(R)[x]$. Далее сделаем из $g_i$ элементы $\hat{g}_i$ из $R[x]$ с $cont(g_i)=1$. Тогда $f=a\prod \hat{g}_i$, где $a\in Q(R)$. Заметим, что $a\in R$ по лемме. Осталось разложить $a$ на простые из $R$.
\endproof
\ethrm








\section{Признаки неприводимости для многочленов}

Теперь наша задача поговорить про неприводимость многочленов над целыми числами или над $\mb Q$. 
Прежде всего отметим, что обе задачи тесно связаны. А именно, если взять многочлен с рациональными коэффициентами, то домножив его на подходящую рациональную константу мы получим многочлен с целыми коэффициентами и содержанием 1, который по доказанному ранее неприводим тогда и только тогда, когда неприводим исходный. Обратно, неприводимость целочисленных многочленов интересна только в случае, когда содержание этих многочленов равно единице. А в этом случае это эквивалентно рациональной неприводимости. Однако все теоремы я буду формулировать в общем контексте.



\thrm[Редукционный критерий] Пусть $R$ факториальное кольцо, $f \in  R[x]$ многочлен, а $p$ -- простой элемент. Тогда, если старший коэффициент $f$ не делится на $p$ и $\ovl{f}$ неприводим в кольце $R/p[x]$, то он неприводим над $Q(R)$. 
\proof Прежде всего перейдём от многочлена $f$ к $\frac{f}{cont(f)}$ с содержанием равным 1. Достаточно доказать неприводимость  последнего над $Q(R)$, которая эквивалентна его неприводимости над $R$. Итак пусть $cont(f)=1$ и пусть $f=gh$, где $g,h$ --  не константы. Старшие коэффициенты $g$ и $h$ тоже не делятся на $p$. Имеем $\ovl{f}= \ovl{g}\ovl{h}$ и $\deg g = \deg \ovl{g}$ и $\deg h = \deg \ovl{h}$, что даёт нетривиальное разложение $\ovl{f}$ и приводит к противоречию.
\endproof
\ethrm

Вот примеры о том, как пользоваться этим критерием и что не надо забывать про условие со старшим коэффициентом. 


\exm\\
1) Многочлен $x^3+x+1$ неприводим над $\mb F_2=\mb Z/2$, потому что у него нет корней. Следовательно многочлены $3x^3+8x^2+5x+7$ и скажем, $5x^3-4x^2+x+15$ неприводимы над $\mb Q$.\\
2) Рассмотрим многочлен $px^2+x$. Он приводим, но по модулю $p$ -- неприводим.\\
3) Критерий из теоремы сформулирован не в самом сильном виде. А именно, представим себе, например, что по модулю 2 многочлен степени пять разложился в произведение двух неприводимых степени 2 и 3, а по модулю 3 -- в виде произведения степени 4 и 1. Ясно, что он неприводим.\\
4) Не стоит забывать, что если многочлен неприводим над $\mb R$, то он так же неприводим над $\mb Q$. Это, правда, очень слабый критерий, но в комбинации с пунктом 3) может что-то дать.\\
5) Есть, однако, такие многочлены, которые неприводимы, но раскладываются по модулю любого простого. Например, $x^4+1$. Действительно,
$$x^4+1=(x-e^{\frac{i\pi}{8}})(x-e^{\frac{3i\pi}{8}})(x-e^{\frac{5i\pi}{8}})(x-e^{\frac{7i\pi}{8}})= (x^2+i)(x^2-i)=(x^2+\sqrt{2}x+1)(x^2-\sqrt{2}x+1)=(x^{2}+\sqrt{-2}x+1)(x^{2}-\sqrt{-2}x+1).$$
Он не имеет рациональных корней, а любые множители степени 2 имеют нерациональный коэффициент. Значит он неприводим.

С другой стороны, по любому нечётному простому модулю либо из $-1$, либо из $2$ либо из $-2$ извлекается корень. Случай $p=2$ легко проверяется руками.
6) Но не всё так плохо. Если мы зафиксируем степень $d$ и рассмотрим множество многочленов $f(x)\in \mb Z[x]$ с коэффициентами, ограниченными некоторой константой $M$, то при $M$ стремящемся к бесконечности доля неприводимых многочленов будет стремиться к $1$, а среди них, доля многочленов, неприводимость которых можно проверить при помощи редукции так же стремится к $1$.\\


Покажем теперь некоторый критерий неприводимости, который применим в случае, если разложение по модулю $p$ получилось очень неудачное. А именно, представим себе, что $f(x) \equiv c x^n \mod p$. То есть многочлен развалился в произведение максимально возможного числа одинаковых множителей. Оказывается, что в этом случае неприводимость многочлена $f$ зависит от его класса по модулю $p^2$. Точнее:

\thrm[Признак Эйзенштейна] Пусть $R$ -- факториальное кольцо и $f(x)= a_0 + \dots + a_n x^n$. Если $a_n \ndi p$, все $a_i \di p$ при $i<n$, но $a_0\ndi p^2$, то многочлен $f(x)$ неприводим.
\proof
Предположим, что $f=gh$. Тогда $c x^n=\ovl{f}=\ovl{g}\ovl{h}$ в $R/p[x]$ и значит в $Q(R/p)[x]$. Но в поле разложение на неприводимые однозначно. Отсюда $\ovl{g}=ax^k$ и $\ovl{h}=b x^l$. Но тогда их младшие члены делятся на $p$ и, значит, $a_0\di p^2$. Противоречие. 
\endproof
\ethrm 

\upr Распишите это доказательство на языке элементов.
\eupr

Всё, что мы пока обсуждали не говорит ничего о том, как же разложить многочлен на неприводимые множители. Первое, что мы обсудим -- вопрос, почему эта задача в принципе разрешима.

Итак, пусть есть целочисленный многочлен $f(x)$ и мы хотим разложить его на множители. Мы будем искать разложение на целочисленные многочлены. Заметим, что хотя бы один из них обязан иметь степень меньшую, чем $[\frac{n}{2}]$. Вспомним о задаче интерполяции. Если $g$ -- искомый делитель $f$, то $g$ определяется своими значениями в $[\frac{n}{2}]+1$ точке, например в точках $0,1,\dots, [\frac{n}{2}]$. Более того, $f(i) \di g(i)$. Таким образом, набор $g(0),\dots, g([\frac{n}{2}])$ состоит из делителей $f(0),\dots,f([\frac{n}{2}])$. Найти все такие наборы -- конечный перебор. По каждому набору кандидат на делитель $g$ восстанавливается однозначно.

Прежде чем продвинуться дальше в исследовании разложения многочленов от одной переменной на множители стоит немного поговорить о задаче разложения многочленов от нескольких переменных. Сейчас мы увидим ещё один трюк от Кронекера, который позволит свести эту задачу к предыдущей.

\thrm[Трюк] Пусть $R$ -- кольцо. Тогда различным разложениям $f(x_1,\dots,x_n)\in R[x_1,\dots,x_n]$   соответствуют различные разложения $\hat{f}=f(x, x^d, x^{d^2}, \dots, x^{d^{n-1}})$ для $d$ больших $\max_{i=1}^n \{\deg_{x_i} f\}$.
\proof Пусть $f=g_1h_1=g_2h_2$ и пусть $g_1\neq g_2$. Покажем, что $\hat{g_1}\neq \hat{g_2}$. Для этого посмотрим что происходит с мономом $x^{\alpha}$ при указанном преобразовании если $\alpha_i < d$. Этот моном переходит в многочлен $x^{\alpha_1+\alpha_2d+\dots+\alpha_n d^{n-1}}$. Так как по условию все $\alpha_i<d$, то такая степень  $x^{\alpha_1+\alpha_2d+\dots+\alpha_n d^{n-1}}$ может быть получена при подстановке только из монома $x^{\alpha}$. Заметим теперь, что $\deg_{x_i} g_j \leq \deg_{x_i} f <d$. Следовательно мономы многочленов $g_j(x)$ однозначно восстанавливаются по мономам $\hat{g_j}$.
\endproof
\ethrm

Заметим так же, что в теореме указан и метод по которому из многочлена $\hat{g}$ можно восстановить многочлен $\hat h$,
К сожалению, не стоит ожидать взаимооднозначного соответствия между разложениями многочленов $f$ и $\hat{f}$. Например, многочлен $x_2^2$ раскладывается на два множителя одним способом. При $d=3$ его образ есть $x^6$ у которого 3 различных разложения.

Это очень неэффективный алгоритм разложения многочлена на множители. Он был предложен Кронекером ещё в 19-ом веке. В настоящее время известен полиномиальный алгоритм решения этой задачи (см. \href{http://www.math.leidenuniv.nl/%7Ehwl/PUBLICATIONS/1982f/art.pdf}{LLL-алгоритм}). Обсудим, как этот алгоритм работает.

Для проверки неприводимости мы с успехом использовали информацию, полученную из разложения многочлена по модулю $n$. Вопрос -- нельзя ли эту же информацию использовать и в задаче разложения на множители? Оказывается можно.

Во-первых, если взять достаточно большой модуль $n$, заметно больший, чем коэффициенты в целочисленном разложении, то разложение $f$ по модулю $n$ с маленькими коэффициентами однозначно будет определять кандидата на целочисленное разложение. Это соображение встречается сразу с двумя проблемами -- первая -- не ясно какие есть ограничения на коэффициенты сомножителей, вторая -- разложений по модулю $n$ может быть много и нам не известно способа эффективно искать их.



Продвинемся в решении второго вопроса. Как же  выбрать достаточно большое число, по модулю которого удобно раскладывать многочлен $f$ на множители? Наибольшим удобством в решении задачи разложения обладают поля. В этом смысле возможно стоило бы искать разложение $f$ по модулю очень большого простого. Однако найти большое простое число довольно тяжело. Смотреть по модулю маленьких простых а потом пытаться склеивать разложение в духе китайской теоремы об остатках может банально не получиться (как в примере 3 -- неясно во что склеить два разных разложения). Оказывается наиболее оптимальный вариант такой: взять небольшое простое число $p$, разложить $f$ над $\mb Z/p$ а затем <<поднять>> это разложение по модулю $p^k$ для достаточно большого $k$. Как находить разложение многочлена $f$ на неприводимые над $\mb Z/p$ мы обсудим позже. А пока поясним как делать подъём такого разложения по модулю $p^k$.

\lm[Гензеля] Пусть $f \in \mb Z[x]$, со старшим коэффициентом 1. Пусть $\ovl{f}=gh$ в кольце $\mb Z/p[x]$, причём $(g,h)=1$ и у $g,h$ тоже единичные старшие коэффициенты. Тогда  для любого $k\geq 1$ существуют единственные по модулю $p^k$ многочлены $\hat{g}, \hat{h} \in \mb Z[x]$, cо старшим коэффициентом $1$, что
$$\ovl{f}=\hat{g} \hat{h} \mod p^k,\quad  \hat{g}\equiv g \mod{p}, \quad \hat{h}\equiv h \mod{p} \quad \text{и} \quad \deg h= \deg \hat{h}, \quad \deg g= \deg \hat{g}.$$
\proof Докажем это индукцией по $k$. Пусть по модулю $p^{k}$ уже построены подходящие многочлены $\hat{h}$ и $\hat{g}$ и мы хотим построить $\ovl{h}$ и $\ovl{g}$. Заметим, что благодаря единственности по модулю $p^k$, такие $\ovl{g}$ и $\ovl{h}$ обязаны совпадать с $\hat{h}$ и $\hat{g}$ по модулю $p^k$. Это означает, что по модулю $p^{k+1}$ 
$$\ovl{h} \equiv \hat{h}+p^ka(x)\pmod{p^{k+1}} \text{\,\, и\quad } \ovl{g} \equiv \hat{g} + p^kb(x)\pmod{p^{k+1}}.$$
Заметим, что многочлены $a(x)$ и $b(x)$  однозначно определяются по модулю $p$,  если известны $\ovl{g}$ и $\ovl{h}$ и по модулю $p$ должны иметь степени меньше чем степени $h(x)$ и $g(x)$ соответственно, для того, чтобы не изменить старший коэффициент. Покажем, что такие $a(x), b(x)$ существуют и единственны по модулю $p$. Заметим, что необходимо проверить лишь условие $f \equiv \ovl{g}\ovl{h} \pmod{p^{k+1}}$. Распишем
$$f\equiv \hat{g}\hat{h} + p^{k}(a(x)g + b(x)h) \pmod{p^{k+1}}.$$
Здесь мы заменили $\hat{h}$ и $\hat{g}$ по модулю $p$ и получили исходные многочлены $g$ и $h$ из $\mb Z/p[x]$. Заметим, что есть единственный такой многочлен $c(x)\in\mb Z/p[x]$, что $f-\hat{g}\hat{h}=p^kc(x) \pmod{p^{k+1}}$. Теперь для выполнения сравнения выше необходимо, чтобы  $$c(x)=a(x)g(x)+b(x)h(x)$$
У такого сравнения есть единственное решение в $\mb Z/p[x]$ при условии $\deg a(x)<\deg h(x)$ и $\deg b(x)< \deg g(x)$. Что и требовалось.
\endproof
\elm

Частным случаем разложения на множители служит разложение вида $f(x)=(x-x_1)g(x)$, соответствующее наличию корня. Именно его мы и разбирали раньше. 

\rm Стоит отметить, что условие на старший коэффициент $f$ не является обременительным, так как его легко изменить при помощи линейной замены переменных над $\mb Q$ и домножения на подходящую константу.
\erm

\zd Покажите, что не существует критерия неприводимости, который бы зависел только от остатков коэффициентов $f(x)$ по модулю фиксированной степени простого $p^k$ и работал бы для многочленов $f(x)$, у которых есть два различных неприводимых множителя по модулю $p$ 
\ezd


\section{Дополнительно: оценка на коэффициенты делителя}

Заведём  на пространстве многочленов скалярное произведение
$$\lan f(x), g(x)\ran = \sum a_ib_i,$$
где $a_i$ и $b_i$ -- коэффициенты $f$ и $g$. Теперь докажем лемму:

\lm Пусть $f\in \mb C[x]$ имеет вид $f=(x-\alpha)h$. Тогда $|f|=|(\alpha x-1)h|$.
\proof
Обозначим коэффициенты $h$ за $c_0,\dots, c_{n-1}$. Тогда 
$$|f|^2= |-c_0\alpha|^2+|c_0-c_1\alpha|^2+\dots+ |c_{n-1}|^2.$$
С другой стороны имеем
$$|(\alpha x-1)h|^2=|c_0|^2+|\alpha c_0-c_1|^2+\dots + |\alpha c_{n-1}|^2.$$
Распишем отдельно модуль $|\alpha c_i - c_{i+1}|^2$ и $|c_i-\alpha c_{i+1}|^2$:
$$|\alpha c_i - c_{i+1}|^2= |\alpha c_i|^2 + |c_{i+1}|^2 - 2\re \alpha c_i \ovl{c_{i+1}} \text{ и } |c_i-\alpha c_{i+1}|^2= |\alpha c_{i+1}|^2 + |c_{i}|^2 - 2\re \alpha c_i \ovl{c_{i+1}}.$$
Осталось заметить, что все слагаемые вида $|\alpha c_i|^2$, $|c_i|^2$ и $-2\re \alpha c_i \ovl{c_{i+1}}$ встречаются в первой и второй сумме ровно по одному разу.
\endproof
\elm

Сформулируем теорему:

\thrm
Пусть $f=a_0 + a_1x+\dots + a_n x^n \in \mb Z[x]$. Тогда для коэффициентов целочисленного делителя $f$ степени $m$ имеет место оценка
$$|b_j| \leq C_{m-1}^j |f| + C_{m-1}^{j-1}|a_n|.$$
\proof Пусть $g(x)$ -- некоторый многочлен. Имеем разложение $g(x)=b_m \prod_{i=1}^m (x-\alpha_i)$. Тогда рассмотрим многочлен 
$$h(x)=\prod_{|\alpha_i|\geq 1} (x-\alpha_i) \prod_{|\alpha_i|<1}(\alpha_ix-1).$$
Мы знаем по предыдущей лемме, что $|g|=|h|$. Определим величины
$$M(g)=\prod_{|\alpha_i|\geq 1} |\alpha_i|, \,\,\, m(g)=\prod_{|\alpha_i|<1}|\alpha_i|.$$
Тогда имеет место
$$|g|^2=|h|^2\geq |b_m|^2 (M(g)^2+m(g)^2).$$
Для этого заметим, что старший коэффициент $h$ по модулю есть $|b_n|m(g)$, а младший -- $|b_n|M(g)$, что и даёт неравенство. В частности применяя это к многочлену $f$ получаем, что
$$M(f) \leq \frac{|f|}{a_m},$$
То есть мы оценили некоторое выражение от корней многочлена $f$. Вернёмся пока к произвольному многочлену $g$. Имеем следующую оценку на его коэффициент:
$$|b_j| = |b_m| \left|\sum \alpha_{i_1}\dots \alpha_{i_{m-j}}\right| \leq |b_m| \left|\sum \beta_{i_1}\dots \beta_{i_{m-j}}\right|, $$
где $\beta=\max(1,|\alpha|)$.

Покажем лемму

\lm Пусть есть набор вещественных чисел $x_1,\dots,x_m\geq 1$, что $x_1\dots x_m=M$. Тогда для всех $0<j\leq n$ имеем $$\sigma_j(x_1,\dots,x_m) \leq C_{m-1}^j M+ C_{m-1}^{j-1},$$
где $\sigma_i(x_1,\dots,x_n)$ -- элементарный симметрический многочлен.
\proof Покажем, что максимум модуля $\sigma_j$ достигается, если $x_1=\dots=x_{m-1}=1$ и $x_m=M$. Рассмотрим, например, пару $x_1,x_2$. Если $x_1,x_2\neq 1$, то заменим её на пару $1,x_1x_2$. Покажем, что при этом значение $\sigma_j$ увеличилось. Действительно, в новой сумме изменились только слагаемые в которые входили только $x_1$ или только $x_2$. Выпишем их 
$$\sum_{2<i_2 \dots< i_j} x_1 x_{i_2}\dots x_{i_j}  + \sum_{2<i_2\dots} x_2 x_{i_2}\dots x_{i_j}= (x_1+x_2)\sigma_{j-2}(x_3,\dots,x_m)$$
и сделаем в них замену $x_1=1$ и $x_2=x_1x_2$. Получим
$$(1+x_1x_2)\sigma_{j-2}(x_3,\dots,x_m).$$
Осталось заметить, что $0< x_1x_2 -x_1 -x_2 + 1= (x_1-1)(x_2-1)$ в наших предположениях. Аналогично для других пар переменных.
Теперь 
$$\sigma_j(1,\dots,1,M)= C_{m-1}^{j-1}M + C_{m-1}^j.$$
\endproof
\elm

\noindent Заметим теперь, что произведение $\beta_i = M(g)$. Тогда по лемме
$$|b_j|\leq |b_m| (C_{m-1}^{m-j-1}M(g) + C_{m-1}^{m-j})=|b_m| (C_{m-1}^{j}M(g) + C_{m-1}^{j-1}).$$
Теперь пусть $f \di g $ в $\mb Z[x]$. Тогда $a_n \di b_m$ и $M(g)\leq M(f)$ так как корни $g$ являются корнями $f$. Отсюда
$$|b_j|\leq |b_m| (C_{m-1}^{j}M(g) + C_{m-1}^{j-1})\leq |a_n|(C_{m-1}^{j}M(f) + C_{m-1}^{j-1})\leq C_{m-1}^{j}|f| + C_{m-1}^{j-1}|a_n|.$$

\endproof
\ethrm



Это теорема показывает, что размер записи коэффициентов делителя полиномиально зависит от размера записи многочлена $f$.







\section{Результант и дискриминант}

Попробуем решить следующую задачу: как определить по коэффициентам многочлена, что они имеют общий множитель? Если имеет место нетривиальное разложение $f=hk_1$, $g=hk_2$, то степень $k_1$ меньше $\deg f=n$, а степень $k_2\leq \deg g=m$. Заметим, что тогда $fk_2-gk_1=0$. Обратно, если найдены такие $k_1$ и $k_2$, то у $f$ и $g$ есть общий множитель. Рассмотрим отображение $K[x]_{\leq m-1}\times K[x]_{\leq n-1} \to K[x]_{\leq n+m-1}$, заданное по правилу
$$(a(x),b(x)) \to a(x)f(x)+b(x)g(x).$$ 
Когда это отображение вырождено? Тогда и только тогда, когда есть многочлены маленьких степеней, что $a(x)f(x)=-b(x)g(x)$. Это происходит тогда и только тогда, когда у многочленов $f$ и $g$ есть общий множитель. С другой это происходит, если определитель матрицы этого линейного отображения в стандартных базисах обнуляется. Транспонирую эту матрицу и переставляя строки и столбцы приходим к определению:

\dfn Пусть многочлен $f(x)=a_0+\dots+a_nx^n$, а $g(x)=b_0+\dots+b_mx^m$. Тогда результантом многочленов $f$ и $g$ называется $$Res(f,g)=  \det 
\begin{pmatrix}
a_n & a_{n-1} & \cdots & a_0 & 0 & \cdots & 0 \\
0 & a_n & a_{n-1} & \cdots & a_0 & \cdots & 0 \\
\\
0 & \cdots &  a_n & a_{n-1} & a_{n-2} & \cdots &  a_0 \\
b_m & \cdots & b_1 & b_0 & 0 & \cdots & 0 \\
 \\
0 & \cdots & 0 & b_m & \cdots & b_1 & b_0 
\end{pmatrix}.$$
Эта матрица называется матрицей Сильвестра. 
\edfn

Результант двух многочленов может быть определён над любым кольцом. Посмотрим, что из этого можно вытащить. Что значит равенство нулю результанта по $y$ для двух многочленов $f(x,y) $ и $g(x,y)$ из $K[x,y]$? Их результант это многочлен $h(x)$. Рассмотрим точку $x_0$. Допустим, что старшие коэффициенты $f$ и $g$ не обращаются в 0 в точке $x_0$. Тогда равенство нулю результанта $h(x_0)$ -- это равенство нулю результанта многочленов $f(x_0,y)$ и $g(x_0,y)$, что означает, что у последних есть общий корень $y_0$. То есть у системы $f=g=0$ есть корень $(x_0,y_0)$. Таким образом корни результанта -- это  просто $x$-координаты решений системы, или точки, в которых старший коэффициент многочленов обращается в 0.


А что можно вывести из того факта, что у $Res(f,g)=n$ для двух многочленов из $\mb Z[x]$? Разложим $n$ на простые множители. Получим $n=p_1^{\alpha_1} \dots p_k^{\alpha_k}$. Допустим, что $p_i$ не делит старшие коэффициенты $f$ и $g$. Тогда $0=Res(f,g) \mod p_i $ есть $Res(\ovl{f}, \ovl{g})$ и следовательно по модулю $p_i$ у многочленов есть общий корень. Обратно, если у $f$ и $g$ есть общий корень по модулю $p_i$, то $Res(f,g)\di p_i$.

\dfn Дискриминантом многочлена $f=a_0+\dots +a_nx^n$ называется выражение 
$$D(f)=(-1)^{\frac{n(n-1)}{2}} a_n^{-1} Res(f,f').$$
Это полином от коэффициентов $f(x)$.
\edfn

\rm Над полем  дискриминант обнуляется тогда и только тогда, когда у многочлена есть есть общий делитель с его производной. Заметим, что в если у многочлена $f$ были кратные множители, то это условие выполнено. Это, как мы узнаем позднее, эти условия равносильны над любым конечным полем характеристики $p$ (это не всегда верно над бесконечным полем $K$). Правильная формулировка в этом случае такая: дискриминант многочлена над полем $K$ обнуляется тогда и только тогда, когда существует расширение поля $K$, в котором у этого многочлена есть кратные множители.  
\erm

Дискриминант даёт ответ на вопрос, когда многочлен не имеет кратных корней по модулю $p$. Действительно это происходит только тогда, когда $D(\ovl{f})=0$ (как мы скоро узнаем). Это происходит тогда и только тогда, когда $D(f)\ndi p$ или, если $a_n\di p$. Заметим, что это условие может нарушаться только в конечном числе $p$, если $D(f)\neq 0$. Таким образом, либо у целочисленного многочлена есть кратный множитель над $\mb Q$, либо у него нет кратных множителей по модулю почти всех простых $p$. Это обосновывает, что для применения леммы Гензеля для подъёма всегда можно выбрать подходящее простое, если сам многочлен $f\in \mb Z[x]$ был бесквадратный.


\subsection{Дополнительно: свойства результанта и дискриминанта}

\thrm Пусть многочлен $f(x)=a_0+\dots+a_nx^n$, а $g(x)=b_0+\dots+b_mx^m$ из кольца $K[x]$, где $K$ -- поле. Пусть так же в поле $K$ имеются разложения $f(x)=a_n\prod(x-x_i)$, а $g(x)=b_m\prod (x-y_j)$. Тогда
$$Res(f,g)=a_n^mb_m^n \prod_{i,j} (x_i-y_j),$$
\ethrm

\lm Пусть так же в поле $K$ имеются разложения $f(x)=a_n\prod(x-x_i)$, а $g(x)=b_m\prod (x-y_j)$. Тогда результант можно найти по формуле:
$$a_n^mb_m^n \prod_{i,j} (x_i-y_j)=(-1)^{mn}b_m^n \prod f(y_j)=a_n^m \prod g(x_i).$$ 
\elm

\upr Кроме того, если $f=gq+r$, где $\deg r=k$, то 
 $$Res(f,g)=(-1)^{(n-k)m}b_m^{n-k} Res(r,g).$$
\eupr

\lm Пусть $f(x)\in K[x]$ -- это многочлен вида $f(x)=a_n(x-x_1)\dots(x-x_n)$. Тогда дискриминант можно найти по формуле:
$$D(f)=a_n^{2n-2}\prod_{i< j} (x_i-x_j)^2.$$
\elm

\exm\\
1) $D(x^2+ax+b)=a^2-4b$.\\
2) $D(x^3+ax+b)=-4a^3-27b^2$.\\






\chapter{Конечные поля}

\section{Общие факты теории полей}

Мы с вами уже встречались с понятием расширения полей, то есть ситуацией, когда одно поле $K$ является подкольцом в поле $L$. В этой ситуации $L$ автоматически является векторным пространством над $K$ и более того $K$-алгеброй. Тогда у $L$ можно посчитать размерность над $K$, а у любого элемента $\alpha \in L$ можно искать минимальный многочлен. Вокруг этих двух понятий и будет идти разговор в этом разделе.  


\dfn[Степень расширения] Пусть $L$ расширение поля $K$ (в этой ситуации часто пишут $L/K$). Тогда $\dim_K L$ называется степенью $L$ над $K$ и обозначается как $[L:K]$. Если $[L: K]$ конечно, то говорят, что $L$ -- конечное расширение поля $K$. 
\edfn

\thrm[О башне полей] Пусть дана башня расширений $K\leq L \leq M$. Тогда 
$$[M: K]=[M: L][L: K].$$
В частности, если $M$ конечно над $L$, а $L$ конечно над $K$, то $M$ конечно над $K$.


\proof Пусть $u_1\dots,u_n$ -- базис $L/K$, а $v_1,\dots,v_m$ -- базис $M/L$. Утверждается, что набор $u_iv_j$ базис $M/K$.
Прежде всего заметим, что это порождающая система. Действительно, любой элемент $y\in M$ равен 
$$y=\sum_{j=1}^m \lambda_j u_j. $$
Здесь $\lambda_j \in L$, что значит, что для них есть разложение $\lambda_j=\sum_{i=1}^n \mu_{ij} u_i$, где $\mu_{ij}\in K$. Подставляя, получаем 
$$ y=\sum_{j=1}^m\sum_{i=1}^n \mu_{ij} u_jv_i.$$
Покажем теперь независимость этого набора. Пусть
$$\sum_{j=1}^m\left(\sum_{i=1}^n \mu_{ij}u_i\right)v_j=\sum_{ij}\mu_{ij} u_i v_j=0.$$
Тогда, так как набор $v_j$ образует базис $M/L$, то необходимо
$$\sum_{i=1}^n \mu_{ij}u_i=0 \text{ для всех j}.$$
Но так как $u_i$ -- базис $L/K$, получаем, что $\mu_{ij}=0$, что и требовалось.
\endproof
 
\ethrm

\crl Пусть $[L: K]$ -- конечное расширение степени $n$, а $[M:K]$ -- степени $d$. Тогда, если $d \ndi n$, то $M$ не может быть подрасширением $L/K$.
\ecrl

\rm Тут стоит быть осторожным, потому что одно и тоже поле может быть по разному реализовано как расширение базового. Рассмотрим простой пример: $\mb Q(x)$ содержит в качестве подполя $\mb Q(x^2)$, которое само изоморфно $\mb Q(x)$. В этой ситуации $\mb Q(x)$ реализовано как расширение самого себя двумя разными способами.
\erm

\dfn Пусть $L/K$ расширение полей, а $\alpha \in L$. Тогда наименьшее подрасширение $L$, содержащее $\alpha$, будем обозначать $K(\alpha)$, а наименьшую подалгебру, содержащую $\alpha$, будем обозначать $K[\alpha]$. Если есть несколько элементов $\alpha_1,\dots,\alpha_n\in L$, то аналогичные объекты будем обозначать как $K[\alpha_1,\dots,\alpha_n]$ и $K(\alpha_1,\dots,\alpha_n)$.
\edfn



Может показаться, что такое обозначение не естественно, потому что никак не включает в себя объемлющее поле $L$. Я покажу, что это не так страшно. Для этого нам понадобится определение:

\dfn Элемент $\alpha \in L$ называется алгебраическим над $K$, если существует многочлен $0\neq p(x)\in K[x]$, что $p(\alpha)=0$. Не алгебраические элементы называются трансцендентными.
\edfn 

Например, элемент $\sqrt{2} \in \mb R$ является алгебраическим над $\mb Q$, а элемент $\pi\in \mb R$ является трансцендентным.

Нам понадобится лемма:

\lm Пусть $f(x) \in K[x]$, а $L$ -- какая-то алгебра над $K$. Тогда задание  гомоморфизма $K$-алгебр $K[x]/f \to L$ равносильно нахождению элемента $\alpha \in L$, что $f(\alpha)=0$.
\elm
\proof Класс $\ovl{x}$ является корнем $f(x)$ в алгебре $K[x]/f$. При гомоморфизме он должен перейти в корень $f$ в $L$. Так как алгебра $K[x]/f$ порождена $\ovl{x}$, образ $\ovl{x}$ однозначно задаёт гомоморфизм. 
Осталось показать, что если найдётся подходящее $\alpha\in L$, то гомоморфизм существует. Для этого сначала построим гомоморфизм $K[x] \to L$ по правилу $h(x) \to h(\alpha)$. А потом заметим, что он продолжается на фактор. Заметим, что всё сказанное работает и при $f=0$.
\endproof


\thrm Пусть $L/K$ расширение полей, а $\alpha \in L$. Тогда если $\alpha$ алгебраический над $K$, то 
$$K(\alpha)=K[\alpha]\cong K[x]/p(x),$$
 где $p(x)$ минимальный многочлен для $\alpha.$
Если же $\alpha$ трансцендентное над $K$, то $$K[\alpha]\cong K[x] \text{ и } K(\alpha) \cong K(x).$$
\ethrm


\proof Итак, пусть $\alpha$ -- алгебраический над $ K$. Тогда минимальный многочлен $\alpha$ однозначно определён. Покажем, что он неприводим. Пусть $p(x)=h(x)q(x)$. Тогда $h(\alpha)q(\alpha)=0$. Но $L$ -- поле. Откуда либо $h(\alpha)=0$ либо $q(\alpha)=0$. Но тогда $p(x)$ не минимальный.

Существует единственный гомоморфизм $\ffi \colon K[x]/p(x) \to L$ переводящий $x \to \alpha$.  Это даёт гомоморфизм $K[x]/p(x) \to L$. Он инъективен, так как $K[x/p(x)$ -- поле. Значит  образ $K[x]/p(x)$ тоже поле. Оно состоит из линейных комбинаций $1,\alpha,\dots,\alpha^{n-1}$, где $n$ -- степень $p(x)$. Понятно, что любая подалгебра, содержащая $\alpha$ содержит такие элементы. Значит образ -- это наименьшая подалгебра содержащая $\alpha$. Отсюда
$$K[x]/p(x) \cong \im \ffi = K[\alpha]=K(\alpha).$$
Пусть $\alpha$ не алгебраический, то есть трансцендентный. Тогда отображение $K[x] \to L$ переводящее $x\to\alpha$ инъективно. Ясно, что его образ это $K[\alpha]$. Далее заметим, что это отображение продолжается до отображения $K(x) \to L$, потому что образы всех элементов $K[x]$, кроме 0 в $L$ обратимы. Ясно, что образ этого отображения есть подполе и изоморфен $K(x)$. С другой стороны, меньше чем образ этого отображения быть ничего не может. Тогда образ и есть $K(\alpha)$. 
\endproof

\crl Пусть $\alpha$ -- алгебраическое. Тогда $ [K[\alpha]:K]= [K[x]/p(x):K]= \deg p(x)$, где $p(x)$ -- минимальный многочлен $\alpha$.
\ecrl

\crl Все расширения, порождённые над $K$ корнем одного и того же неприводимого многочлена изоморфны. Часто я буду говорить, про расширение $K[\alpha]$, где $\alpha$ корень многочлена $p(x)$. Это корректно, так как такое расширение определено однозначно с точностью до изоморфизма.
\ecrl

Так же напомню вам факт, известный ещё с прошлого года:

\utv Пусть $K$ -- поле, $f(x)$ -- многочлен над $K$. Тогда существует такое конечное расширение $L/K$, что в $L$ многочлен $f$ раскладывается на линейные множители.
\eutv
\proof Индукция по степени многочлена. Рассмотрим многочлен $f$. Пусть у $f$ есть неприводимый множитель $g$. Построим расширение $L=K[x]/g$. В этом расширении у $g$, а значит и у $f$ есть корень $\alpha$. Посмотрим на многочлен $f_1=f/(x-\alpha) \in L[x]$. По индукции построим для $L$ расширение $M$ в котором $f_1$ раскладывается на линейные множители. Но тогда в $M$ и многочлен $f$ раскладывается на линейные множители.
\endproof

На самом деле построенное при помощи этой конструкции расширение есть <<наименьшее>> расширение, которое содержит все корни многочлена и можно показать, что оно единственно с точностью до изоморфизма. Такое расширение называется полем разложения многочлена.


\subsection{Дополнительно: построение при помощи циркуля и линейки}
Попробуем применить это следствие для доказательства невозможности определённых  построений, например при помощи циркуля и линейки. Напомню, что при построении циркулем и линейкой можно поставить пару начальных точек (задать масштаб), соединять две построенные  точки прямой и строить окружность с центром в построенной точке и с расстоянием, равным расстоянию между уже построенными двумя точками. Точка построена, если она есть точка пересечения построенных прямых и окружностей. 

Вещественное число $x$ называется построимым, если, стартуя с точек $(0,0)$ и $(1,0)$, можно построить отрезок $(x,0)$. 

\thrm Если вещественное число $x$ построимо, то оно алгебраическое и лежит в расширении $L/\mb Q$ степени $2^m$.
\proof Доказательство идёт индукцией по числу построений. Пусть уже построены прямые $l_i$ и окружности $O_j$. Заметим, что коэффициенты в уравнениях $O_i$ и $l_j$ по индукционному предположению лежат в подполе $L\subseteq \mb R$ степени $2^m$ над $\mb Q$. Это же касается и новой прямой $l$ (или окружности $O$). Посмотрим на пересечение окружности $O_j$ и новой прямой $l$. Оно задано системой уравнений $(x-a)^2+(y-b)^2=r^2$ и $cx+dy=f$. Пусть $c\neq 0$. Тогда первое уравнение переписывается в виде $$(f-dy)^2+c^2(y-b)^2=c^2r^2$$
Его коэффициенты из $L$, а решение $y$ лежит либо в $L$ либо в расширении степени 2 над $L$. Случай пересечения двух окружностей сводится к пересечению окружности и прямой.  Действительно, если написаны два уравнения окружности c разными центрами
$$(x-a_1)^2+(y-a_2)^2=r^2_1 \text{ и } (x-b_1)^2+(y-b_2)^2=r^2_2$$
то вычитая их получим уравнение прямой
$$2(a_1-b_1)x+2(a_2-b_2)y=r^2_2-r^2_1+a_1^2-b_1^2+a_2^2-b_2^2.$$

\endproof
\ethrm

\crl
Нельзя разбить произвольный угол на три части при помощи циркуля и линейки.
\proof Например, угол $\frac{\pi}{3}$ нельзя, потому что угол $\frac\pi 9$ не построить. Действительно, построимость угла и его косинуса равносильны. Косинус $\frac{\pi}{9}$ удовлетворяет уравнению $4x^3-3x=\frac{1}{2}$. Это неприводимый над $\mb Q$ многочлен степени 3 и его корни не могут лежать в расширении степени $2^m$. Следовательно, построение невозможно. 
\endproof
\ecrl

\section{Строение конечных полей}

В качестве затравки мы ограничим возможное число элементов в конечном поле.

\lm Пусть $K$ --- поле, $p=\chr K$ --- простое число. Тогда в $K$ есть подполе изоморфное $\mb Z/p$. Если к тому же $K$ --- конечное, то число элементов $|K|=p^n$ для некоторого натурального $n$. 
\elm


\proof Рассмотрим гомоморфизм $f\colon \mb Z \to K$. Ядро этого отображения это $p\mb Z$. Тогда $\im f\cong \mb Z/p$. Пусть теперь $K$ конечно. Тогда $K$ -- конечномерное векторное пространство над $\mb Z/p$ и в нём $p^n$ элементов.
\endproof
 
Теперь сформулируем основной результат про конечные поля, который мы и будем в дальнейшем доказывать.

\thrm Существует и единственно (с точностью до изоморфизма) поле из $p^n$ элементов. Такое поле будем обозначать $\mb F_{p^n}$.
\ethrm

Начнём с леммы:
\lm Пусть $K$ поле из $p^n$ элементов. Тогда все элементы $K$ удовлетворяют уравнению $x^{p^n}=x$.
\elm
\proof Группа $K^*$ состоит из $p^n-1$ элементов. Тогда все элементы из $K^*$ удовлетворяют уравнению $x^{p^n-1}-1=0$. Домножая на $x$ добавляем неприкаянный 0.
\endproof


\lm Пусть $L$ --- кольцо характеристики $p$, где $p$ -- простое. Тогда отображение $x\to x^{p}$ является эндоморфизмом $L$. Это отображение называется эндоморфизмом Фробениуса. Если $L$ --- конечное поле, то эндоморфизм Фробениуса является автоморфизмом. 
\elm
\proof Очевидно произведение переходит в произведение. Для суммы имеем $$(x+y)^p=\sum_{i+j=p} C_p^i x^iy^j= x^p+y^p,$$ т.к. все промежуточные биномиальные коэффициенты делятся на $p$. Пусть теперь $L$ -- поле. Тогда заметим, что отображение $\Frob$ инъективно, так как в поле не бывает нильпотентов и, следовательно, по принципу Дирихле, биективно.
\endproof

\rm Условие конечности поля в этой ситуации важно. Рассмотрим, например, поле $\mb Z/p(x)$. Тогда возведение в $p$-ую степень в качестве образа имеет $\mb Z/p(x^p)$.
\erm

\lm Пусть $L$ --- поле характеристики $p$. Тогда множество элементов из $L$ удовлетворяющих уравнению $x^{p^n}=x$ образует подполе в $L$.
\elm
\proof Обозначим рассматриваемое множество за $K$. Тогда $0,1\in K$. Очевидно, что $K$ замкнуто относительно умножения. Замкнутость относительно сложения следует из того, что $x^{p^n}$ есть композиция $n$ раз эндоморфизма Фробениуса. Значит $K$ --- подкольцо. Обратный к $x\neq 0$ имеет вид $x^{p^n-2}$, что следует из уравнения.
\endproof
 

\proof[{\color{red!80!black} Доказательство теоремы. Существование}]
Рассмотрим поле $\mb F_p=\mb Z/p$ и $x^{p^n}-x$ --- многочлен над ним. Тогда есть поле $L$ в котором   $x^{p^n}-x$ раскладывается на линейные множители. Рассмотрим $K$ --- подполе в $L$ состоящее из элементов удовлетворяющих уравнению $x^{p^n}=x$. В $K$ ровно $p^n$ элементов т.к. многочлен $x^{p^n}-x$ не имеет кратных корней.

\proof[{\color{red!80!black} Доказательство теоремы. Единственность}]
Пусть есть два поля $K$ и $L$ из $p^n$ элементов. Рассмотрим их мультипликативные группы. Они циклические порядка $p^n-1$. Пусть группа $K^*$ порождена элементом $\xi$. Тогда любой элемент заведомо является многочленом от $\xi$. Пусть $f$ -- минимальный многочлен $\xi$. Значит $K\cong\mb F_p[x]/f(x)$. Многочлен $f$ неприводим. $\xi$ --- его корень. Многочлен $x^{p^n}-x$ делится на $f$, так как $\xi$ есть корень $x^{p^n}-x$, а $f$ -- минимальный многочлен.

Тогда у $f$ есть корни в любом поле из $p^n$ элементов, в частности в $L$. Тогда у нас есть гомоморфизм  $K\cong\mb F_p[x]/f(x)\to L$ переводящий $\xi$ в некоторый корень $f$ в $L$. Этот гомоморфизм инъективен, так как $K$ -- поле и, по принципу Дирихле, является биекцией. 
\endproof
 
\rm В частности, мы увидели, что любое конечное поле $\mb F_{p^n}$ может быть построено как $\mb F_p[x]/f(x)$, где $f$ -- неприводимый многочлен степени $n$.
\erm

\noindent{\bf Пример:}\\
Построим поле из $4=2^2$ элементов. Для этого нам нужно найти неприводимый многочлен степени $2$ над $\mb F_2$. Это $x^2+x+1$. Тогда построим поле из четырёх элементов как
$$\mb F_4= \mb F_2[x]/x^2+x+1.$$

Когда одно конечное поле может быть подполем в другом и сколько может быть вариантов для выбора такого подполя?

\thrm Поле $\mb F_{p^n}$ подполе $\mb F_{p^m}$ тогда и только тогда, когда $m\di n$. Такое подполе единственно.
\ethrm 
\proof
Если $\mb F_{p^n}$ подполе $\mb F_{p^m}$, то сравнивая степени расширения получаем, что $m \di n$. Обратно, возьмём в $\mb F_{p^m}$ подполе $\{x \in \mb F_{p^m} \,|\, x^{p^n}-x=0\}$. Очевидно, что любое подполе из $p^n$ элементов там содержится. Это даёт единственность. 


Для того, чтобы доказать существование, покажем, что в указанном подполе $p^n$ элементов. Для этого заметим, что многочлен $x^{p^m}-x \di x^{p^n}-x$, если $m \di n$. Первый многочлен раскладывается на линейные множители над $\mb F_p$, откуда аналогичное свойство выполнено для второго многочлена. То есть у многочлена $x^{p^n}-x$ есть все $p^n$ корней в $\mb F_{p^m}$. Что и требовалось. 
\endproof
 



\crl Элемент $\alpha\in \mb F_{p^m}$ лежит в подполе из $p^n$ элементов тогда и только тогда, когда $\alpha^{p^n}-\alpha=0$.
\ecrl

Так же, если внимательно посмотреть на доказательство основной теоремы, то можно увидеть ещё несколько закономерностей.

\utv Пусть $f(x) \in \mb F_p[x]$ -- неприводимый многочлен степени $n$. Многочлен $f(x)$ раскладывается над $\mb F_{p^n}$ на линейные множители. Кроме того $x^{p^m}-x \di f(x)$ тогда и только тогда, когда $m\di n$. Кроме того, если $\alpha$ --  корень $f$, то все остальные его корни имеют вид $\alpha^{p^k}$ при $0\leq k<n$. 
\eutv
\proof Рассмотрим многочлен $f$ и поле $\mb F_p[x]/f$ из $p^n$ элементов. Корень $f$ в этом поле удовлетворяет уравнению $x^{p^n}-x=0$ и потому  $x^{p^m}-x \di f$. Тогда $f$ раскладывается в $\mb F_{p^n}$ на линейные множители. 

Если $x^{p^m}-x \di f$, то все корни $f$, которые порождают поле из $p^n$ элементов, лежат в $\mb F_{p^m}$. Но тогда $m \di n$. Обратно, если $m\di n$, то $x^{p^m}-x\di x^{p^n}-x\di f$.

Так как возведение в $p$-ую степень автоморфизмом поля $\mb F_{p^n}$ над $\mb F_p$, то если $\alpha$ корень $f$, то $\alpha^p$ тоже корень $f$. Почему таким образом получаются все корни? Для этого достаточно показать, что корни $\alpha$ и $\alpha^{p^k}$ не склеиваются при всех $k<n$. Но они не могут быть одинаковыми, так как тогда возведение в степень $p^k$ и тождественное отображение $\mb F_{p^n} \to \mb F_{p^n}$ совпадали бы (ведь $\mb F_{p^n}$ порождается $\alpha$), а это противоречит описанию всех автоморфизмов.
\endproof


Кроме того, посмотрим, как устроены все автоморфизмы конечных полей.

\utv Все автоморфизмы $\mb F_{p^n}$  имеют вид $\Frob_p^{\circ i}$, где $0\leq i \leq n-1$. Все указанные автоморфизмы различны.
\proof Обозначим $q=p^n$. Заметим, что поле $\mb F_q$ порождено одним элементом $\mb F_q =\mb F_p[\alpha]$. Минимальный многочлен $\alpha$ над $\mb F_p$ обозначим за $f$, его степень равна $n$. 

Теперь, гомоморфизмы $\mb F_p[\alpha]$ в себя определяются образами элемента $\alpha$, которые обязаны быть корнями того же многочлена $f$. Но таких корней в $\mb F_p[\alpha]$ не более $n$. Тогда и автоморфизмов не более $n$. Осталось показать, что мы нашли все $n$ возможных. Для этого надо показать, что автоморфизмы $\Frob_p^{\circ i}$ различны для всех $0\leq i\leq n-1$. Предположим, что для всех элементов из $\mb F_q$ выполнено, что $\Frob_p^{\circ l} - \Frob_p^{\circ k}=0$, для $k<l<n$. Но это уравнение степени меньше $p^n$ и оно не может иметь $p^n$ решений в поле $\mb F_q$. 
\endproof
 
\eutv


\subsection{Расширения конечных полей}

Говоря про конечные поля характеристики $p$, мы рассматриваем их как расширения поля $\mb F_p$. Но что происходит, с расширениями больших конечных полей $\mb F_q$, где $q=p^n$? Оказывается, что все те свойства расширений, которые мы сформулировали над $\mb F_p$, в  подходящем виде верны и над $\mb F_q$. Сформулируем их. 



\thrm Все конечные расширения поля $\mb F_q$, где $q=p^n$ имеют $q^m$ элементов. Два расширения $\mb F_q$ из $q^m$ элементов изоморфны между собой над $\mb F_q$. Внутри поля $\mb F_{q^m}$ есть подполе $\mb F_{q^l}$ только если $l|m$.
\proof
Если $L$ расширение $\mb F_q$, то оно имеет $q^{[L:\mb F_q]}$ элементов. Покажем существование. Возьмём поле из $q^m=p^{nm}$ элементов и рассмотрим в нём подполе $\mb F_q$ из $q=p^n$ элементов. Такое есть по предыдущей теореме. Так как все поля из $q$ элементов изоморфны, то мы можем отождествить  и даёт необходимое расширение. 

Покажем, что все расширения $\mb F_q$ из $q^m$ элементов изоморфны над $\mb F_q$. Применим ту же логику что и в ситуации над $\mb F_p$. А именно, рассмотрим некоторое расширение $K$ из $q^m$ элементов. Оно порождено одним элементом $\alpha$ над $\mb F_q$. Минимальный многочлен $f$ для $\alpha$ над $\mb F_q$ имеет общий корень с $x^{q^m}-x$ и, значит, делит его. Значит в любом другом расширении из $q^m$ элементов есть корень $f$. В него и надо отправить $\alpha$.

Теперь рассмотрим поле из $q^m$ элементов. Тогда в нём есть подполе из $q^l$ элементов только если $nm \di nl$. Но это происходит только если $m \di l$. Такое подполе единственно и автоматически снабжается структурой $\mb F_q$ расширения, так как содержит образ последнего при его вложении в $\mb F_{q^m}$.
\endproof
\ethrm

Теперь рассмотрим свойства неприводимых многочленов над конечным полем $\mb F_q$.

\crl Пусть $f(x)$ -- это неприводимый многочлен из $\mb F_q[x]$. Тогда $x^{q^m}-x \di f(x)$ тогда и только тогда, когда $\deg f(x) | m$. Если многочлен $f$ имеет корень $\alpha$ в $\mb F_q^m$, то он раскладывается над этим полем на линейные множители. Все корни $f$ в этой ситуации можно найти как $\alpha^{q^k}$. 
\proof Пусть $x^{q^m}-x$ делится на $f(x)$. Тогда в поле $\mb F_q^m$ многочлен $f(x)$ имеет корень $\alpha$ (на самом деле там лежат все его корни). Теперь $\mb F_q[\alpha]$ подполе $\mb F_{q^m}$. Но тогда $\deg f(x) = [\mb F_q[\alpha]: \mb F_q] \di m $. 

Обратно, пусть $k=\deg f(x) | m$. Тогда в $\mb F_q^m$ есть подполе $\mb F_{q^k}$. Но такое подполе изоморфно $\mb F_q[x]/f$ и имеет внутри корень $\alpha$ многочлена $f(x)$. Но тогда $f(x)$ и $x^{q^m}-x$ не взаимно просты, откуда следует, что $x^{q^m}-x \di f(x)$, благодаря неприводимости последнего. 
\endproof
\ecrl


\utv Все автоморфизмы $\mb F_{q^m}$ над $\mb F_q$ есть композиции отображения $x \to x^q$ с самим собой.
\eutv
\proof Для начала стоит заметить, что отображение $x\to x^q$ является $\mb F_q$-линейным и, значит, автоморфизмом над $\mb F_q$. Остальное повторяет рассуждения над $\mb F_p$.
\endproof

\section{Алгоритм Берлекэмпа}


Я опишу здесь некоторый набор соображений и алгоритмов касательно разложения многочленов на множители над конечным полем. 

Мы помним, что над полями характеристики 0 всегда легко выделить все  кратные множители многочлена просто взяв отношение $f$ и $\Nod(f,f')$. Однако, над конечными полями всё немного не так. Точнее

\lm Пусть $f= \prod g_i^{n_i}\in \mb F_q[x]$, где  $q=p^n$, $g_i$ неприводимы над $\mb F_q$. Тогда
$$\Nod(f,f')=\prod_{n_i \not\di p} g_i^{n_i-1} \prod_{n_i \di p}g_i^{n_i}.$$
\proof
Рассмотрим неприводимый множитель $g_i$. Пусть $f(x)=g_i(x)^{n_i}g(x)$. Продифференцируем. Имеем $f'(x)= n_ig_i'(x)g_i^{n_i-1}g(x)+ g_i^{n_i}g'(x)$. Если $n_i\di p$, то $f'(x)=g_i^{n_i}g'(x)$, что показывает, что степень вхождения $g_i$ в $f'(x)$ не менее $n_i$. Но в $f(x)$ многочлен $g_i$ входит с кратностью ровно $n_i$. А значит с такой кратностью он входит и в $\Nod(f,f')$.

Если же $n_i\ndi p$, то кратность вхождения $g_i(x)$ в $f'(x)$ равна $n_i-1$, что следует из следующей леммы.
\endproof
\elm

\lm Многочлен $h$ над конечным полем характеристики $p$ имеет нулевую производную тогда и только тогда, когда он является $p$-ой степенью. Извлечение степени можно провести эффективно.
\proof Как мы уже знаем с прошлого семестра, если $h'=0$, то $h=g(x^p)$. Посмотрим на коэффициенты $g$ -- $a_0, \dots, a_l\in \mb F_q$. Вспомним, что эндоморфизм Фробениуса $\Frob \colon \mb F_q \to  \mb F_q $ -- биекция. Иными словами из каждого элемента можно извлечь корень степени $p$. Пусть $b_i^p=a_i$. Тогда $f=b_0+b_1x+\dots+b_lx^l$ обладает свойством $f^p=g(x^p)=h$. Как вычислить корень степени $p$ из элемента? Для этого заметим, что обратное отображение к $\Frob \colon \mb F_q \to \mb F_q$ это $\Frob^{\circ n-1}$. 
\endproof
\elm 


Это позволяет свести задачу разложения произвольного многочлена над конечным полем к разложению на множители многочлена без кратных множителей. Действительно $\frac{f}{\Nod(f,f')}$ без кратных множителей. В свою очередь $\Nod(f,f')$ состоит из множителей двух типов -- чьи степени кратны $p$ и не кратны $p$. Первые встречаются как сомножители в  $\frac{f}{\Nod(f,f')}$ и легко находятся после получения его разложения. Из оставшихся множителей можно извлечь корень степени $p$ и перейти к разложению многочлена заведомо меньшей степени. 



Прежде чем мы перейдём к, собственно, к разложению на неприводимые множители. Для того, чтобы разложить многочлен на неприводимые множители достаточно научиться получать его нетривиальный делитель. Теперь вспомним факт про многочлены.

\fct[Китайская теорема об остатках] Пусть $K$ -- поле и в $K[x]$ выполнено равенство $f(x)=g(x)h(x)$, где $g,h$ взаимно простые многочлены. Тогда
$$K[x]/f \simeq K[x]/g \times K[x]/h.$$
\efct


\thrm[Алгоритмы Берлекэмпа] Пусть $f(x)\in \mb F_q$ без кратных множителей. Тогда существуют детерминированный полиномиальный по $n$ (но не по $\log q$)  алгоритм раскладывающий $f$ на множители. 


\proof Первое соображение, которое мы применим, будет состоять в том, что мы переформулируем  задачу факторизации многочлена $f$ как задачу про некоторое кольцо. Точнее, пусть $f=h_1\dots h_l$ разложение на неприводимые. Тогда по Китайской теореме об остатках 
$$R= \mb F_q[x]/f\cong \mb F_q[x]/h_1 \times \dots \times \mb F_q[x]/h_l.$$ 
Заметим, что нахождение нетривиального делителя нуля в $R$ равносильно нахождению делителя $f$. Заметим, что, в свою очередь, $\mb F_q[x]/h_i$ -- поле из $q^{\deg h_i}$ элементов. Делителем нуля является любой элемент с хотя бы одним нулём в компоненте.


В каждом таком поле есть единственное подполе из $q$ элементов, состоящее из решений уравнения $x^q-x=0$. Если рассмотреть множество решений этого уравнения в $R$, то оно будет состоять из $l$-ек покомпонентных решений. Иными словами множество решений уравнения $x^q-x$ в $R$ есть подалгебра $R'$, изоморфная $\mb F_q\times \dots \times \mb F_q$, взятое $l$ раз. Если мы найдём делитель нуля в этой подалгебре, то найдём и в исходной. Заметим, что удельно, делителей нуля в этой подалгебре больше чем в исходной. 

Как найти $R'$? Для этого надо найти все решения уравнения $x^q-x=0$ в $R$. Второе соображение состоит в том, что это уравнение линейно (над $\mb F_q$). Чтобы решить это линейное уравнение надо составить его матрицу. У отображения $x \to -x$ матрица $-E_n$, где $n=\deg f$. У оператора $x \to x^q$ матрица легко считается. Далее достаточно применить любой из методов для решения систем линейных уравнений. Заметим, что если алгебра $R'$ одномерна (она не менее чем одномерна, так как константа всегда решение), то многочлен $f$ неприводим.

Теперь мы нашли $R'$. Построим детерминированный алгоритм нахождения разложения. Напомню, что нам надо получить делитель нуля, то есть элемент, у которого хоть одна компонента равна 0, но сам он не ноль. Возьмём произвольный не константный элемент $h$ из $R'$.  Тогда $h$ соответствует $l$-ка $(a_1,\dots,a_{l})$.  Переберём все константы $c$ из $\mb F_q$. Их $q$ штук (это и даёт неполиномиальность алгоритма по $\log q$). Тогда $h-c$ для, например, $c=a_1$ есть нетривиальный делитель 0 (он не ноль, потому что $h$ не константа).

Делитель $f$ теперь можно найти как $\Nod(f,h-c)$.

\endproof
\ethrm

\rm Несмотря на то, что алгоритм Берлекэмпа является неполиномиальным по размеру входных данных он даёт полиномиальный способ проверки неприводимости многочлена. А именно, многочлен неприводим тогда и только тогда, когда размерность подалгебры $R'$ над $\mb F_q$ равна 1.

С другой стороны, во многих приложениях в качестве базового поля берётся $\mb F_2$ и проблема с неполиномиальностью по размеру поля отпадает.
\erm


\subsection{Дополнительно: алгоритм Кантора-Цассенхауза}

Рассмотрим полиномиальный, но вероятностный алгоритм нахождения делителей:

\thrm[Алгоритмы Кантора-Цассенхауза] Пусть $f(x)\in \mb F_q$ без кратных множителей, $q\neq 2^d$. Тогда существуют вероятностный полиномиальный по $n\log q$  алгоритм раскладывающий $f$ на множители.
\proof
Будем предполагать, что $f(x)$ имеет в качестве неприводимых делителей многочлены степени ровно $d$. Тогда алгебра $R$ имеет вид
$$R= \mb F_q[x]/f(x)\cong \mb F_{q^d}\times \dots \times \mb F_{q^d}.$$ 
Наша задача придумать вероятностный алгоритм находящий делитель нуля в таком произведении.

Для упрощения обозначений я заменю $q^d$ на $l$. Посмотрим отдельно на один сомножитель $\mb F_{l}$. Заметим, что любой элемент поля $\mb F_l$ удовлетворяет условию, что $x^{\frac{l-1}{2}}$ либо 0, либо 1, либо $-1$. Ноль реализуется только в случае $x=0$, а $1$ и $-1$, если $x$ квадрат и не квадрат соответственно. Из этого стоит пояснить, что, если $x$ не квадрат, то $x^{\frac{l-1}{2}}$ элемент порядка 2 (и следовательно равен $-1$). Действительно, любой элемент $\mb F_l^*$ есть степень первообразного корня $\alpha$. Тогда элемент квадрат  только если он есть $\alpha^{2d}$. В свою очередь, элемент $\alpha^{2d+1}$ не может быть тривиальным, потому что порядок $\alpha$ чётен. В частности, $(\alpha^{2k+1})^{\frac{l-1}{2}}$ с одной стороны имеет порядок либо 2, либо 1 и при этом не тривиален, то есть имеет порядок 2.


Возьмём теперь случайный элемент $a$ из $R$. Если $a$ делитель нуля всё и так хорошо. Это можно проверить взяв $\Nod(f,a)$, который заодно вычислит делитель $f$. Иначе с вероятностью больше чем  $\frac{1}{2}$ одна из компонент $a$ в одном из сомножителей $\mb F_l$ является квадратом, а ещё одна не является квадратом. Не умоляя общности пусть это первая и вторая компоненты. Тогда $a^{\frac{l-1}{2}}$ имеет вид $(1,-1,\dots)$ и $a-1$ является нетривиальным делителем нуля.  
\endproof
\ethrm

Этот алгоритм не работает для полей характеристики 2. Это не страшно, потому что над $\mb F_2$ итак хорошо работает алгоритм Берлекэмпа. А если вы хотите что-то над расширением $\mb F_2$ то есть подход, использующий не $x^{l-1/2}-1$, а другой многочлен (вычисляющий след). 

В алгоритме Кантора-Цассенхайза есть условие, что многочлен $f$ должен раскладываться на неприводимые множители одинаковой степени. Может показаться, что это обременительное условие, но на самом деле этого легко добиться, если заметить, что $(f,x^{q^d}-x)$ легко вычисляется и вспомнить, какие у этого многочлена могут быть неприводимые делители.


\section{Коды исправляющие ошибки}

Одно из применений конечные поля находят при решении задачи о кодах исправляющий ошибки. Постановка вопроса следующая: Алиса хочет передать Бобу сообщение, но канал связи может искажать часть передаваемого. Задача состоит в том, чтобы так закодировать сообщение, что, даже если оно было немного изменено по дороге, тем не менее, можно было бы восстановить исходный текст.

Дадим математическую постановку задачи. Пусть мы работаем с некоторым конечным алфавитом $\mc A$. Часто -- это двухэлементное множество $\{0,1\}$. Но если вы передаёте байты целиком и не лезете в их потроха, то ваш алфавит состоит из  $2^8$ символов.  Сообщение -- это строка фиксированной длины из элементов $\mc A$. Что означает, что при передаче сообщения возникает не более чем  сколько-то ошибок? Одна ошибка -- это изменение в одном символе. Не более $r$ ошибок -- изменение не более $r$ символов. Это удобно выражать на следующем языке:

\dfn[Расстояние Хемминга] Пусть дан некоторый алфавит $\mc A$ и два слова $x,y \in \mc A^n$. Тогда расстоянием Хемминга между ними называется число позиций, в которых эти слова различаются
$$d_H(x,y)=|\{i \in \ovl{1, n} \, |\, x_i \neq y_i \}|.$$
\edfn

Итак, у нас происходит не более чем $r$ ошибок, если сообщение до передачи $x$ находится от сообщения после передачи $y$ на расстоянии не более чем $e$.

Что такое кодирование? Пусть исходные сообщения, которые надо передать, были длины $k$. Никто не говорил, что передавать надо именно их. Вместо них мы можем передавать слова другой длины, или даже слова в другом алфавите. Впрочем, менять алфавит мы не собираемся, особенно, когда речь идёт о передаче электронных данных. 

А вот размер сообщения мы можем поменять. Зафиксируем $n\in \mb N$. Тогда кодированием (блочным) назовём инъективное  отображение $K\colon \mc A^k \to \mc A^n$.

Итак, мы кодируем сообщения длины $k$ в сообщения блины $n$. Что значит, что мы можем исправить $r$ ошибок? Пусть $x\in \mc A^k$. Если при передаче произошло не более $r$ ошибок, то переданное сообщение $y \in \mc A^n$ обладает тем свойством, что $d_H(K(x),y)\leq r$. Для того, чтобы мы могли однозначно восстановить по $y$ кодовое слово $K(x)$, должно выполняться свойство, что для всех других $z\in \mc A^k$ верно, что $d_H(K(z),y) > r$.

Если мы потребуем, чтобы восстановление было возможно всегда, то  это равносильно условию, что все шары радиуса $r$ с центрами в точках вида $K(x)$ не пересекаются. Заметим, что это условие за висит не столько от отображения $K$, сколько от его образа. Это приводит к определению

\dfn Пусть дан алфавит $\mc A$ из $q$ символов. Тогда $[n,k]_q$-кодом назовём  $C \subseteq A^n$ размера $|C|=q^k$.  Если $q=2$, то говорят, что код бинарный.
\edfn

\dfn Будем говорить, что такой код исправляет $r$ ошибок, если для любых двух слов $x\neq y \in C$ верно, что $B_r(x) \cap B_r(y)= \varnothing$. 
\edfn

Попробуем немного переформулировать это определение. Что значит, что два шара радиуса $r$ с центрами в двух точках не пересекаются? Это значит, что расстояние между этими точками больше $2r$. И наоборот, если расстояние между двумя точками больше $2r$, то два таких шара не пересекаются. Введём определение:

\dfn Пусть $C$ -- код. Тогда кодовым расстоянием называется величина
$$d(C)= \min_{\substack{x,y\in C \\ x \neq y}} d_H(x,y).$$
\edfn

Тогда, если $d=2t$ или $d=2t-1$, то код $C$ исправляет  $r=t-1$ ошибок. Но число $d$ не только определяет число исправляемых ошибок. Оно имеет свой смысл. А именно, если совершено меньше чем $d$ ошибок, то мы с уверенностью можем сказать, что ошибки в принципе были. Это полезно, если вы хотите не восстанавливать ошибки, а, например, запросить тот же кусок повторно в надежде, что он придёт без ошибок. В дальнейшем нас будет интересовать именно параметр $d$.

\dfn $[n,k,d]_q$-кодом называется $[n,k]_q$-код $C$ с кодовым расстоянием $d$.
\edfn

\section{Линейные коды}

Откуда брать такие коды $C$? Понятно, что можно просто брать и повторять сообщение несколько раз, но это крайне не эффективно. С другой стороны отображение $K \colon \mc A^k \to \mc A^n$ тоже играет свою роль, ведь от скорости его вычисления будет зависеть итоговая скорость передачи сообщения. Кроме того, процесс декодирования, особенно в ситуации когда известно, что допущена ошибка, тоже должен проходить быстро.

Для того, чтобы решить эти задачи нам нужно представить себе алфавит $\mc A$ и код $C$ не просто как множества. Нам нужно завести на них максимум возможных структур. А именно, мы будем считать, что  $q=p^n$ -- степень простого, $\mc A = \mb F_q$ -- конечное поле. В такой ситуации естественно потребовать, чтобы отображение $K$ было линейным над $\mb F_q$, а $C$, следовательно, было векторным подпространством в $\mb F_q^n$.

\dfn Линейным $[n,k]_q$-кодом называется $k$-мерное подпространство в $\mb F_q^n$.
\edfn

Если кодирование линейно, то оно задаётся матрицей размера $n\times k$ и ранга $k$, которая обозначается $G$ и называется {\it порождающей матрицей}. Одному коду могут соответствовать разные отображения кодирования и, следовательно, разные матрицы $G$. В столбцах матрицы $G$ записаны вектора, порождающие код $C$. 

Отметим, что в книжках по теории кодирования кодовые слова обычно являются строчками. В этом случае кодирующее отображение есть умножение на матрицу размера $k\times n$ справа. Именно эта матрица в такой интерпретации и будет называться порождающей. Перейти от одной конвенции к другой можно при помощи операции транспонирования.

\dfn Процедура кодирования называется систематической, если первая часть кодового слова состоит из исходного сообщения. Для порождающей матрицы это накладывает следующее ограничение на её вид: 
$$G= \pmat E_k\\ G' \epmat.$$
Такое кодирование заметно облегчает декодирование, если ошибок нет. В этой ситуации, оставшиеся $n-k$ символов кодового слова называются проверочными. Иногда сообщение помещают в конец, но это вопрос соглашения.
\edfn

Как узнать, есть ли ошибки и раскодировать обратно сообщение? Для этого заметим, что всякое подпространство $C$ размерности $k$ есть ядро матрицы $H$ размера $n-k\times n$ и ранга $n-k$. Такая матрица называется {\it проверочной матрицей кода} $C$. Часто коды удобно задавать при помощи проверочной матрицы. Любая матрица $H\in M_{n-k\times n}{\mb F_q}$ ранга $n-k$ задаёт линейный $[n,k]_q$ код. 

Посмотрим, как связаны порождающая $G$ и проверочная $H$ матрицы одного и того же кода $C$. Несложно заметить, что они удовлетворяют равенству $HG=0$. Обратно, если есть матрица $H$, такая что $HG=0$ и $\rk H=n-k$, то $H$ есть проверочная матрица для $C$.

Как можно построить проверочную матрицу? Если $G$ имеет вид
$$G= \pmat E_k\\ G' \epmat,$$
то $H$ всегда можно взять 
$$H=(-G'\,|\,E_{n-k}).$$
Заметим, что матрица $H$ является по совместительству порождающей матрицей $[n,n-k]_q$ кода. Это приводит к понятию двойственного кода к данному. Мы не будем говорить про это подробно.

Линейность кода позволяет упростить многие вычисления, например, нахождение кодового расстояния.



\lm Пусть $C$ -- линейный $[n,k]_q$ код. Тогда кодовое расстояние $d(C)$ вычисляется по правилу 
$$d(C)=\min_{\substack{x \in C \\ x\neq 0} } d_H(0,x).$$
Так же минимальное расстояние можно вычислить как наименьшее число линейно зависимых столбцов проверочной матрицы $H$.
\proof
Действительно, пусть минимальное расстояние достигается на паре $(x,y)$. Но тогда оно же достигается на паре $(0,y-x)$. Далее, кодовые слова и только они являются элементами ядра $H$, то есть коэффициентами в линейной комбинации столбцов, дающей в результате ноль. Но тогда, если бы было меньше чем $d$ линейно зависимых столбцов, то было бы  ненулевое кодовое слово с менее чем $d$ ненулевыми символами и наоборот. 
\endproof
\elm

\rm Если матрица $H$ не является проверочной, но выполнено, что код $C$ лежит в ядре $H$, то изложенное доказательство может дать оценку на кодовое расстояние. А именно, если любые $d-1$ столбцов матрицы $H$ линейно независимы, то кодовое расстояние больше или равно $d$. 
\erm 

\rm Расстояние Хэмминга от $x$ до $0$ есть просто количество ненулевых компонент в $x$. Эту величину часто называют весом вектора и обозначают $w(x)$ или $\|x\|$.
\erm 

Общий алгоритм декодирования систематических линейных кодов следующий: полученное сообщение $v= u+e$ ($u\in C$ -- исходное сообщение, а $e$ -- ошибка) подставляем в проверочную матрицу. Имеем 
$$Hv= He=s.$$
Вектор $s\in \mb F_q^{n-k}$ обычно называется синдромом. Если $s=0$, то ошибок нет и мы всего лишь выбрасываем проверочные символы. Если ошибки есть, но их можно исправить (то есть $w(e)\leq r$), то вектор $e$ однозначно определяются синдромом $s$. Действительно, пусть для двух векторов $e$ и $e'$ веса меньше или равно $r$ два синдрома совпадают $He=He'$. Тогда $e-e'\in \Ker H$ и $w(e-e')\leq 2r$ чего не может быть.

Далее, есть два способа исправить ошибки. Либо мы заранее посчитали для всех возможных $e$ значения $He$ и тогда мы просто находим $e$ по этим предварительным вычислениям. Это не так долго если кодовое расстояние маленькое. 

Либо, можно рассмотреть общее решение системы $He=s$. Оно имеет вид $v-Gx$, где $x$ -- произвольный вектор из $\mb F_q^k$. Тогда переберём все значения $x$ и найдём ближайший к нулю вектор вида $v-Gx$. Тогда $v-Gx$ есть вектор ошибки, а $x$ есть раскодированное сообщение.

У нас пока не было ни одного примера кодов. Как можно строить линейные коды? Предложим один вариант построения линейных кодов при помощи многочленов. 

Пусть дан произвольный многочлен $g(x)$ над $\mb F_q$, степени $s=\deg g < n$, то по нему можно построить код при помощи отображения $\mb F_q[x]_{\leq n-s-1} \to \mb F_q[x]_{\leq n-1}$, заданное правилом:
$$m(x) \to g(x)m(x).$$
Такое отображение линейно и инъективно. В его образе лежат все многочлены степени меньше $n$ делящиеся на $g(x)$ и они образуют $[n,n-s]_q$-код. Такие коды я буду называть полиномиальными. 

Почему такие коды удобно использовать? Прежде всего их использование позволяет ускорить процесс кодирования, так как домножить один многочлен на другой можно быстрее чем умножить матрицу на столбец. Кроме того, можно подобрать многочлен в котором много нулевых коэффициентов.

Правда указанный способ кодирования не является систематическим. Несложно построить пример систематического кодирования:
$$m(x) \to m(x)x^s-r(x), \text{ где } r(x)=x^s m(x) \mod g(x).$$
Здесь, строго говоря, $m(x)$ записан в последние биты.

\upr Как выглядит порождающая матрица для естественного кодирования? А как для систематического?
\eupr

Так же, мы получаем некие бонусы в вопросах проверки наличия ошибок. А именно, в качестве проверки того, лежит $v(x)$ в коде или нет, достаточно найти остаток от деления $v(x)$ на $g(x)$.   

Если же нам известны все корни $\alpha_i$ многочлена $g(x)$ и они не кратные, то делимость $v(x)\di g(x)$ равносильна условию $v(\alpha_i)=0$. Более того, от одного неприводимого множителя $g(x)$ достаточно взять по одному корню.

Примерами применения таких кодов являются \href{https://ru.wikipedia.org/wiki/%D0%A6%D0%B8%D0%BA%D0%BB%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B8%D0%B7%D0%B1%D1%8B%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D0%B9_%D0%BA%D0%BE%D0%B4}{CRC}.
Название CRC расшифровывается как {\it Cyclic Redundancy Check}. Слово {\it Check} подчёркивает то, что эти коды используются, прежде всего, не для восстановления ошибок, а для их обнаружения. А что же в этих кодах циклического?

\subsection{Дополнительно:  циклические коды}

\dfn Код $C\leq \mb F_q^n$ называется циклическим, если для всякого слова $(a_0,\dots,a_{n-1})\in C$ слово $(a_{n-1},a_0,\dots,a_{n-2})$ тоже из $C$. 
\edfn

\rm Забавно, но не все CRC-коды на самом деле циклические. Но все они полиномиальные.
\erm


Встаёт вопрос: а как цикличность кода связана с полиномиальностью. Оказывается, что напрямую -- любой циклический код обязан быть полиномиальным. Для этого мы посмотрим на следующее соображение: удобно рассматривать пространство $\mb F_q^n \cong \mb F_q[x]_{\leq n-1}$ не просто как векторное пространство над $\mb F_q$, а как алгебру. Например, отождествив это пространство с $\mb F_q[x]/x^n-1$. А в качестве кодов будем смотреть только идеалы $C \subseteq \mb F_q[x]/x^n-1$. Если расписать условие, что $C$ идеал, то получим следующее утверждение

\thrm Пусть $C$ подпространство в $\mb F_q[x]/x^n-1$. Тогда $C$ идеал в том и только том случае, когда $C$ является циклическим кодом.
\ethrm
\proof Домножение на $x$ в этой алгебре соответствует сдвигу, а вся алгебра порождаетcя элементом $x$.
\endproof

Многочлены уже появились на арене. На вопрос, откуда вязть многочлен $g(x)$ отвечает следующий факт, дающий описание всех идеалов в $\mb F_q[x]/x^n-1$.

\fct Пусть $K$ -- поле. Делителю $g(x)$ многочлена $f(x)$ можно сопоставить главный идеал в $K[x]/f(x)$. Идеалы в кольце $K[x]/f(x)$ однозначно соответствуют делителям $f$ со старшим коэффициентом $1$.
\efct

Итого, все идеалы в $\mb F_q[x]/x^n-1$ главные и соответствуют делителям многочлена $x^n-1$. Чтобы задать идеал необходимо задать многочлен $g(x)$, такой что $ x^n-1 \di g(x)$. Это даёт линейный $[n, n-\deg g]_q$ циклический код.

Определение циклического кода появилось в самом начале прикладного использования кодов, исправляющих ошибки. Его важность была обусловлена простотой аппаратной реализации проверки на принадлежность коду. А именно, рассмотрим многочлен $\hat{g}=f/g$. Тогда элемент $v \in \mb F_q[x]/x^n-1$ делится на $g$ тогда и только тогда, когда $\hat g v \equiv 0 \mod x^n-1$. 
Произведение многочленов и взятие по модулю $x^n-1$ удачно реализовывались аппаратно при помощи {\it сдвиговых регистров с обратной связью}.



\section{Коды БЧХ}

Мы пока не научились двум вещам о полиномиальных кодах: оценивать кодовое расстояние у полиномиальных кодов и строить эффективный алгоритм исправления ошибок. Займёмся расстоянием.

Для оценки кодового расстояния мы воспользуемся некоторой информацией про порождающий полином $g(x)\in \mb F_q[x]$. Итак, пусть мы строим код над $\mb F_q$ длины $n$ и так получилось, что все корни многочлена $g(x)$ не кратны, лежат в $\mb F_{q^m}$ и являются степенями одного и того же элемента $\beta\in \mb F_q^*$ порядка $r$. Построим  множество степеней $T=\{i\in\ovl{0,r-1} \,|\, g(\beta^i)=0\}$, отвечающих корням многочлена $g(x)$. Немедленно замечаем, что $|T|=\deg g \leq r$.  

Чтобы оценить кодовое расстояние, нам необходима проверочная матрица или что-то вроде того. Можем ли мы предъявить проверочную матрицу для кода, заданного $g(x)$?

И да и нет. Нам будет удобнее думать не про матрицу, а про линейное отображение. Заметим, что для $f(x)\in \mb F_q[x]$ верно, что $f(x) \di g(x)$ тогда и только тогда, когда $f(\beta^i)=0$ для $i\in T$. Это приводит к следующей <<проверочной матрице>> $H$:
$$H=\pmat 1& \beta^{i_1}& \dots& \beta^{i_1(n-1)}\\
\vdots &&\dots&\vdots\\
1& \beta^{i_k}& \dots & \beta^{i_k(n-1)}
\epmat.$$
Слова <<проверочная матрица>> стоят в кавычках, потому что $H$ матрица не над $\mb F_q$, а над $\mb F_{q^m}$. Впрочем, легко сделать из неё матрицу над $\mb F_q$ переписав $\beta^i$ через базис $\mb F_{q^m}$. Докажем теперь основную теорему:

\thrm Пусть корни порождающего многочлена $g(x)$ кода длины $n$ есть степени элемента $0\neq \beta \in \mb F_{q^m}$ и $g(x)$ не имеет кратных корней. Пусть $\ord \beta \geq n$. Пусть в множестве $T$ есть $d-1$ идущие подряд индексов. Тогда минимальное расстояние кода длины $n$ заданного $g(x)$ больше или равно $d$.
\ethrm
\proof
Пусть подряд идущие $d-1$ элементов $T$ имеют следующий вид $l_0, l_0+1,\dots,l_0+d-2$. Нам надо показать, что у матрицы $H$ любые $d-1$ столбцов линейно независимы над $\mb F_q$. Нам удобно проверить независимость её столбцов не над $\mb F_q$, а над $\mb F_{q^m}$.

Возьмём столбцы с номерами $j_1,\dots,j_{d-1}$ и оставим только строки с номерами $l_0, l_0+1,\dots,l_0+d-2$. Получим матрицу 
$$ \pmat 
\beta^{l_0 j_1}& \dots &\beta^{l_0 j_d}\\
\vdots & & \vdots\\
\beta^{(l_0+d-2)j_1} & \dots & \beta^{(l_0+d-2)j_d} 
\epmat.$$
Нам достаточно показать, что её определитель не ноль. Найдём его. Из $s$-го столбца вынесем $\beta^{l_0j_s}$. Имеем
$$ \det \pmat 
\beta^{l_0 j_1}& \dots &\beta^{l_0 j_{d-1}}\\
\vdots & & \vdots\\
\beta^{(l_0+d-2)j_1} & \dots & \beta^{(l_0+d-2)j_{d-1}} 
\epmat = \beta^{l_0(j_1+\dots+j_{d-1})} \det  \pmat 
1& \dots &1\\
\vdots & & \vdots\\
\beta^{(d-2)j_1} & \dots & \beta^{(d-2)j_{d-1}} 
\epmat.$$
Но определитель последней матрицы есть определитель Вандермонда для элементов $\beta^{j_1}, \dots, \beta^{j_{d-1}}$. Этот определитель не обращается в ноль так как $\beta^{j_k}\neq \beta^{j_l}$, при $0\leq k< l\leq n-1< \ord \beta -1$.
\endproof

Перейдём к основной конструкции кодов, для которых применима эта лемма --  кодам Боуза -- Чоудхури -- Хоквингема.

Зафиксируем числа $q=p^s$ степень простого, натуральные числа $n$  и $m$, такие, что $(q^m-1)\di n$, а так же число $2\leq d\leq n$ и $l_0 \leq n$. $m$ обычно минимально возможное при данном $n$. Из условия делимости $q^m-1\di n$ следует, что в поле $\mb F_q^m$ есть элемент порядка $n$. Его несложно найти зная первообразный корень $\alpha$ в $\mb F_{q^m}$. Действительно, можно взять 
$$\beta=\alpha^{(q^m-1)/n}.$$ 

Рассмотрим элементы $\beta^{l_0},\beta^{l_0+1},\dots, \beta^{l_0+d-2}$ и рассмотрим $g(x)$ -- многочлен наименьшей степени, корнями которого являются эти элементы. Тогда кодом БЧХ длины $n$ c конструктивным расстоянием $d$ назовём циклический код длины $n$, порождённый полиномом $g(x)$.

\rm
Заметим, что $g(x)$ делит $x^n-1$ и поэтому код действительно циклический.
\erm

\noindent {\bf Пример:}\\
Пусть $q=2$. Возьмём $n=2^4-1=15$ (то есть $m=4$). Для того, чтобы построить поле из 16 элементов рассмотрим многочлен $x^4+x^3+1$. Он неприводим над $\mb F_2$. Его корень $\alpha$ -- первообразный корень степени $15$ из единицы. Возьмём $l_0=1$ и $d=5$. Тогда необходимо найти минимальные многочлены для элементов $\alpha,\alpha^2,\alpha^3,\alpha^4$. Заметим, что минимальные многочлены для $\alpha,\alpha^2,\alpha^4$ одинаковы и равны $x^4+x^3+1$ так как два последних элемента есть образы предыдущих при автоморфизме Фробениуса. Минимальный многочлен для $\alpha^3$ равен $x^4+x^3+x^2+x+1$. 

В качестве многочлена, задающего соответствующий код БЧХ с расстоянием $5$, берём $$g(x)=(x^4+x^3+1)(x^4+x^3+x^2+x+1).$$
Итого, получили $[15,7,d\geq 5]_2$-код.

\upr Постройте проверочную матрицу для этого кода.
\eupr

Частным случаем кодов БЧХ являются коды Рида-Соломона. Обобщение, использующее многочлены от нескольких переменных называется кодами Рида-Мюллера.

\subsection{Декодирование БЧХ-кодов}

Поговорим о декодировании кодов БЧХ. Опишем простейший алгоритм декодирования -- алгоритм Питерсона-Горенштейна-Цирлера.

Пусть нам дан БЧХ-код длины $n$ с конструктивным расстоянием $d$. Корни порождающего многочлена этого кода есть $\beta^{l_0},\dots, \beta^{l_0+d-2}$.
Пусть на вход мы получили многочлен $v(x)=u(x)+e(x)$, где $u(x)$ -- это пересылаемое закодированное сообщение, а $e(x)$ -- ошибка. Предположим, что $e(x)=e_{i_1}x^{i_1}+\dots +e_{i_t}x^{i_t}$ состоит из $t$ мономов, где $t\leq [(d-1)/2]$, то есть мы теоретически можем раскодировать сообщение. Для того чтобы узнать, что ошибки есть, мы вычисляем $v(\beta^{i})$, где $i\in \ovl{l_0, l_0+d-2}$. Но так как $u(x) \di g(x)$, то
$$v(\beta^{i})=u(\beta^i)+e(\beta^i)=e(\beta^i).$$
Итого мы знаем значения $e(\beta^i)$. Обозначим за
$$S_k= e(\beta^{l_0+k-1}), \text{ при } k\in \ovl{1,d-1}, \,\, X_s=\beta^{i_s} \text{ и } \eps_s=e_{i_s} \text{ при } s\in \ovl{1,t}.$$
Заметим, что эти определения эти элементы связаны следующим соотношением 
$$S_k=\sum_{s=1}^t \eps_s X_s^{l_0+k-1}.$$

Если известны $X_s$, то из указанных выше уравнений легко найти $\eps_s$. Определитель матрицы этой системы при $k\in\ovl{1,t}$ есть,  определитель Вандермонда, что гарантирует однозначность решения.

Итого, необходимо найти элементы $X_k$. Уравнения на $X_k$ не линейны. Наша задача ввести новые величины, однозначно определяющие $X_k$, на которые уже можно написать линейные уравнения. Для этого рассмотрим многочлен 
$$\chi(x)=(x-X_1)\dots(x-X_t)= x^t+\sigma_1x^{t-1}+\dots+\sigma_t.$$
Корни этого уравнения -- это величины $X_1,\dots,X_t$. Если мы найдём $\sigma_i$, то сможем найти $X_i$.

Заметим, что последовательность $S_k$ есть сумма геометрических прогрессий с частными $X_1,\dots,x_t$. Каждая из таких прогрессий является решением линейного рекуррентного соотношения с постоянными коэффициентами у которого характеристический многочлен в точности $\chi(x)$. Это означает, что у нас есть система уравнений 
$$\left\{ \begin{array}{rcl}
-S_{t+1}&=& \sigma_t S_1+\dots + \sigma_1 S_t\\
&\vdots&\\
-S_{2t}&=& \sigma_t S_t+\dots + \sigma_1 S_{2t-1}\\
\end{array} \right.$$
Теоретически, можно написать выражения для всех элементов вплоть до $S_{d-1}$, но нам это не понадобится. Разрешимость этой системы зависит от её матрицы, которая имеет вид 
$$ \Sigma_t =\pmat
S_1 & \dots & S_t\\
\vdots & & \vdots\\
S_t & \dots & S_{2t-1}
\epmat.
$$
 

Заметим, однако, что кроме того, что нам надо решить систему нам надо найти её размер, то есть число ошибок $t$. Для того, чтобы ответить на оба эти вопроса, напишем аналогичные матрицы для всех $\tau$  от $1$ др $[(d-1)/2]$ 
$$ \Sigma_\tau=\pmat
S_1 & \dots & S_\tau\\
\vdots & & \vdots\\
S_\tau & \dots & S_{2\tau-1}
\epmat =  \pmat
1 & \dots & 1\\
\vdots & & \vdots\\
X_1^{\tau-1} & \dots & X_t^{\tau-1}
\epmat
\pmat
\eps_1X_1^{l_0} & \dots & 0\\
\vdots & \ddots& \vdots\\
0 & \dots & \eps_t X_t^{l_0}
\epmat
\pmat
1& \dots & X_1^{\tau-1}\\
\vdots & & \vdots\\
1 & \dots & X_t^{\tau-1}\\
\epmat .
$$
Теперь, если $\tau=t$, то определитель этой матрицы не равен 0 и значит система однозначно разрешима. Если же $\tau>t$, то ранг первой матрицы меньше $\tau$. Значит и $\rk \Sigma_{\tau}<\tau$. В этом случае ясно, что определитель матрицы $\Sigma_{\tau}$ равен 0. Итого мы получаем следующий алгоритм исправления ошибок:
\enm 
\item Запускаем цикл по $\tau$ от 1 до $[(d-1)/2]$. Вычисляем $S_1,\dots,S_{2\tau}$ и вычисляем определители матриц $\Sigma_{\tau}$. Находим последний $\tau$ для которого этот определитель не ноль. Это и есть $t$. Решаем соответствующую систему и находим $\sigma_i$.
\item По $\sigma_i$ находим $X_l$ после чего находим позиции $i_l$. Это можно сделать подставив все возможные $\beta^i$ в $\chi(x)$.  
\item Далее, решив систему линейных уравнений можно найти $e_{i_l}$. Осталось  найти ответ по формуле $u(x)=v(x)-e(x)$.
\eenm

\subsection{Дополнительно: алгоритм Берлекэмпа-Мэсси}
Однако указанная матрица системы имеет очень регулярную структуру. Это наводит на мысль, что есть и более эффективные алгоритмы декодирования. Опишем алгоритм декодирования Берлекэмпа-Мэсси. Для этого нам надо проинтерпретировать указанную систему. Заметим, что элементы $S_1,\dots,S_d$ образуют кусок последовательности, заданной линейным реккурентным соотношением с характеристическим многочленом $x^t+\sigma_1x^{t-1}+\dots + \sigma_t= x^t \sigma(x^{-1})$.

При этом, данный многочлен является минимальным возможным для этой последовательности. Действительно, так как при $\tau =t$ определитель системы не ноль, то получаем, что есть единственный такой многочлен степени $\leq t$, который годится для элементов $S_1,\dots,S_{2t}$, а значит и для последовательности $S_1,\dots,S_{d-1}$. 

В общем виде, алгоритм Берлекэмпа-Мэсси по данной конечной последовательности $S_0,\dots, S_{N-1}$ ищет наименьшее линейное рекуррентное соотношение, которому удовлетворяет данная последовательность. 

Прежде всего перепишем условие, что последовательность $S_0,\dots, S_{N-1}$ удовлетворяет линейному рекуррентному соотношению  с коэффициентами $c_0,\dots, c_{k-1}, 1=c_k$. Рассмотрим многочлены $S(x)=S_0+\dots+S_{N-1}x^{N-1}$ и многочлен $\sigma(x)=c_0x^k+\dots + c_{k-1}x+1$. Тогда получаем, что 
$$S(x)\sigma(x)\equiv D(x) \mod x^N, \text{ где } \deg D(x) < k.$$
нам придётся отдельно говорить про степень $k$ так как её нельзя восстановить по $\sigma(x)$. Кроме того, при данном $k$ подходящий  $\sigma(x)$ не всегда единственный.


Будем искать $\sigma(x)$ и $k$ индуктивно. На $n$-ом шаге найдём наименьшее число $l_n$ и многочлен $\sigma_n(x)$ степени меньше $l_n$, которые решают задачу для $S_0,\dots, S_{n-1}$, где $n\leq N$. Иными словами, будет выполнено 
$$ S(x)\sigma_n(x) \equiv D_n(x) \mod x^n, \text{ где } \deg D_n(x) < l_n.$$
Заметим, что $l_n$ определено однозначно и всегда $l_n\leq n$ (если $l_n=n$, то это значит, что никаких соотношений в принципе нет). А  вот $\sigma_n(x)$ определено не всегда однозначно.



Посмотрим, как работает алгоритм. Если в последовательности $S_0,\dots,S_{n-1}$ одни нули, то будем считать степень $l_n$ соответствующей рекурренты равной $0$, а $\sigma_n=1$. Если же $S_{n-1}\neq 0$, но все предыдущие элементы нулевые, то очевидно на роль минимума годятся $l_n=n$ и $\sigma_n(x)=1= 1+0x+\dots+0x^n$.


Рассмотрим общую ситуацию. Пусть уже построено минимальное $l_n$ и соответствующее $\sigma_n$. Если $\sigma_n$ подходит и при добавлении $S_n$, то можно взять $l_n=l_{n+1}$ и $\sigma_{n+1}=\sigma_n$. 

Если же $\sigma_n$ не подходит, то
$$ S(x)\sigma_n(x) \equiv D_n(x)+d_nx^n \mod x^{n+1}, \text{ где } \deg D_n(x) < l_n$$
и $d_n\neq 0$. Если расписать явно, то $d_n=S_n+\sum_{k=0}^{l_n-1} c_k S_{n-l_n+k} \neq 0$, отвечает за то, что рекуррентное соотношение не выполнено для $S_n$. Посмотрим на наибольшее $m<n$, что $\sigma_m(x)\neq \sigma_n(x)$, то есть на предыдущее место изменения при построении $\sigma(x)$. Это даёт нам элемент $d_m\neq 0$, кроме того случая, когда было выполнено $S_0=\dots=S_{m-1}=0$, но $S_m\neq 0$. В этой ситуации $l_m=0$ и $d_m$ просто не вычислить. Будем считать, тогда, что $d_m=1$. Теперь, как только мы нашли $m,\sigma_m,d_m$ утверждается, что надо взять 
$$\sigma_{n+1}(x)= \sigma_n(x) - d_n d_m^{-1} x^{n-m} \sigma_m(x).$$
$$l_{n+1}=\max(l_n,n+1-l_n).$$

Для того, чтобы показать корректность этого алгоритма докажем вспомогательную лемму.

\lm[Ключевая] Пусть понадобилось поменять рекуррентное соотношение на шаге $n+1$. Тогда имеет место неравенство $l_{n+1}\geq n+1-l_n$. 
\elm
\proof  Предположим противное. Пусть $l_{n+1}\leq n-l_n$, то есть $l_{n+1}+l_n\leq n$. Распишем условие на $\sigma_n$ и $\sigma_{n+1}$ по модулю $x^{n+1}$.

$$\sigma_n S(x) \equiv D_n+d_nx^n \mod x^{n+1}$$
$$\sigma_{n+1}S(x)\equiv D_{n+1} \mod x^{n+1}$$
Так как $\sigma_n$ не подходит на роль $\sigma_{n+1}$, то $d_n\neq 0$. Домножая верхнее равенство на $\sigma_{n+1}$ получаем
$$ \sigma_{n+1}\sigma_n S(x) \equiv \sigma_{n+1}(D_n+d_nx^n) \equiv \sigma_n D_{n+1}\mod x^{n+1}$$
Заметим, что из неравенства, выражение, содержащее $d_nx^n$ имеет степень ровно $n$ после взятия остатка по модулю $x^{n+1}$, что не так для $\sigma_{n+1}D_n$ по тому же самому неравенству.
\endproof


\crl Пусть нам понадобилось поменять рекуррентное соотношение. Тогда $l_{n+1}\geq \max (l_n, n+1-l_n)$.
\ecrl

\proof[Корректность алгоритма]
Будем доказывать корректность алгоритма вместе со следующим утверждением: в предыдущем следствии при каждой смене $\sigma_i$ в алгоритме достигается равенство. 

Итак, пусть построены $\sigma_1(x),\dots, \sigma_n(x)$ и мы хотим построить $\sigma_{n+1}$.
В случае $d_n=0$ всё ясно. Пусть $d_n \neq 0$ и $m$ такое, что $l_m<l_n$, но $l_{m+1}=l_n$. Тогда по индукционному предположению имеем 
$$l_m<l_n = l_{m+1}=\max (l_m,m+1-l_m) $$
Отсюда получаем, что $l_n=m+1-l_m$. Возьмём
$$l_{n+1}=\max (l_n,n+1-l_n)=\max (l_n,n-m+l_m)$$
Условия следствия выполнены автоматически. Взятый нами $\sigma_{n+1}$ имеет степень меньшую или равную этого числа. Осталось проверить, что выполнено сравнение. 

$$\sigma_{n+1}S(x)\equiv d_n x^n+ 
D_n(x)+ d_nd_m^{-1}x^{n-m}(d_mx^m+ D_m(x)) \equiv D_n(x)-d_nd_m^{-1}x^{n-m}D_m(x) \mod x^{n+1}
$$
Оставшийся многочлен нужной степени. Отдельно стоит разобраться с базой индукции и началом работы алгоритма.
 

\endproof



\end{document}
